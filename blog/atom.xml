<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://chaos-mesh.org/blog</id>
    <title>Chaos Mesh Blog</title>
    <updated>2021-12-27T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://chaos-mesh.org/blog"/>
    <subtitle>Chaos Mesh Blog</subtitle>
    <icon>https://chaos-mesh.org/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[Share your #ChaosMeshStory!]]></title>
        <id>/share-your-chaos-mesh-story</id>
        <link href="https://chaos-mesh.org/blog/share-your-chaos-mesh-story"/>
        <updated>2021-12-27T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Share your #ChaosMeshStory!]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-story.jpeg" alt="Share your #ChaosMeshStory!"/></p><p>Hey community,</p><p>ü•≥ Chaos Mesh will turn 2 on 2021.12.31! We&#x27;re grateful for every contribution from you that helped this project grow. And we&#x27;d like to hear your Chaos Mesh story! How did you hear about the project? How did you get involved? Are you an adopter or a contributor? What do you think of it? It can be anything! Share your <strong><a href="https://twitter.com/intent/tweet?text=%23ChaosMeshStory">#ChaosMeshStory</a></strong> over on Twitter and win a Chaos Mesh Tee!</p><h2>üçº #ChaosMeshStory Entry via Twitter</h2><h3>Rules</h3><ul><li>Eligibility: anyone with a Twitter account</li><li>Event Period: December 27, 2021, at 9:00 AM - December 31, 2021, at 11:59 PM (PT)</li><li>How to participate:<ol><li>Follow <a href="https://twitter.com/chaos_mesh">@chaos_mesh</a>.</li><li>Add the <strong><a href="https://twitter.com/intent/tweet?text=%23ChaosMeshStory">#ChaosMeshStory</a></strong> hashtag.</li><li>Share your experience with Chaos Mesh!</li></ol></li><li>Judging Criteria: all qualified entries will be eligible to receive a Chaos Mesh Tee. The link to collect your contact information will be available on January 1st, 2022. Stay tuned with <a href="https://twitter.com/chaos_mesh">@chaos_mesh</a> on Twitter!</li><li>Rules: please comply with the <a href="https://github.com/chaos-mesh/chaos-mesh/blob/master/CODE_OF_CONDUCT.md">Code of Conduct</a>, otherwise you will be ineligible to participate.</li></ul><p>If you have any questions regarding the event, please DM <a href="https://twitter.com/chaos_mesh">@chaos_mesh</a>.</p><p>Have fun!</p><p>Yours truly,</p><p>Chaos Mesh community</p>]]></content>
        <author>
            <name>Chaos Mesh Community</name>
            <uri>https://github.com/chaos-mesh</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Deploy Chaos Mesh on KubeSphere]]></title>
        <id>/deploy-chaos-mesh-on-kubesphere</id>
        <link href="https://chaos-mesh.org/blog/deploy-chaos-mesh-on-kubesphere"/>
        <updated>2021-12-22T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Deploy Chaos Mesh on KubeSphere]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-kubesphere-banner.png" alt="Deploy Chaos Mesh on KubeSphere"/></p><p><a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a> is a cloud-native Chaos Engineering platform that orchestrates chaos in Kubernetes environments. With Chaos Mesh, you can test your system&#x27;s resilience and robustness on Kubernetes by injecting various types of faults into Pods, network, file system, and even the kernel.</p><p><img src="/img/chaos-mesh-architecture-2.0.png" alt="Chaos Mesh architecture"/></p><h2>What‚Äôs KubeSphere</h2><p><a href="https://kubesphere.io/">KubeSphere</a> is a distributed operating system for cloud-native application management, using Kubernetes as its kernel. It provides a plug-and-play architecture, allowing third-party applications to be seamlessly integrated into its ecosystem.</p><p>KubeSphere 3.2.0 adds the feature of dynamically loading community-developed Helm charts into the <a href="https://kubesphere.io/docs/pluggable-components/app-store/">KubeSphere App Store</a>. Thanks to this new feature, Chaos Mesh is now available on KubeSphere. In this tutorial, you will learn how to deploy Chaos Mesh on KubeSphere to conduct chaos experiments.</p><h2>Enable App Store on KubeSphere</h2><ol><li><p>Make sure you have installed and enabled the <a href="https://kubesphere.io/docs/pluggable-components/app-store/">KubeSphere App Store</a>.</p></li><li><p>You need to create a workspace, a project, and a user account (project-regular) for this tutorial. The account needs to be a platform regular user and to be invited as the project operator with the operator role. For more information, see <a href="https://kubesphere.io/docs/quick-start/create-workspace-and-project/">Create Workspaces, Projects, Users and Roles</a>.</p></li></ol><h2>Chaos experiments with Chaos Mesh</h2><h3>Step 1: Deploy Chaos Mesh</h3><ol><li><p>Login KubeSphere as <code>project-regular</code>, search for <strong>chaos-mesh</strong> in the <strong>App Store</strong>, and click on the search result to enter the app. </p><p><img src="/img/chaos-mesh-app.png" alt="Chaos Mesh app"/>
</p></li><li><p>In the <strong>App Information</strong> page, click <strong>Install</strong> on the upper right corner.</p><p><img src="/img/install-chaos-mesh.png" alt="Install Chaos Mesh"/>
</p></li><li><p>In the <strong>App Settings</strong> page, set the application <strong>Name,</strong> <strong>Location</strong> (as your Namespace), and <strong>App Version</strong>, and then click <strong>Next</strong> on the upper right corner.</p><p><img src="/img/chaos-mesh-basic-info.png" alt="Chaos Mesh basic information"/></p></li><li><p>Configure the <code>values.yaml</code> file as needed, or click <strong>Install</strong> to use the default configuration.</p><p><img src="/img/chaos-mesh-config.png" alt="Chaos Mesh configurations"/></p></li><li><p>Wait for the deployment to be finished. Upon completion, Chaos Mesh will be shown as <strong>Running</strong> in KubeSphere. </p><p><img src="/img/chaos-mesh-deployed.png" alt="Chaos Mesh deployed"/></p></li></ol><h3>Step 2: Visit Chaos Dashboard</h3><ol><li><p>In the <strong>Resource Status</strong> page, copy the <strong>NodePort </strong>of <code>chaos-dashboard</code>.</p><p><img src="/img/chaos-mesh-nodeport.png" alt="Chaos Mesh NodePort"/></p></li><li><p>Access the Chaos Dashboard by entering <code>${NodeIP}:${NODEPORT}</code> in your browser. Refer to <a href="https://chaos-mesh.org/docs/manage-user-permissions/">Manage User Permissions</a> to generate a Token and log into Chaos Dashboard. </p><p><img src="/img/login-to-dashboard.png" alt="Login to Chaos Dashboard"/></p></li></ol><h3>Step 3: Create a chaos experiment</h3><p>Before creating a chaos experiment, you should identify and deploy your experiment target, for example, to test how an application works under network latency. Here, we use a demo application <code>web-show</code> as the target application to be tested, and the test goal is to observe the system network latency. You can deploy a demo application <code>web-show</code> with the following command: <code>web-show</code>.   </p><pre><code class="language-bash">curl -sSL https://mirrors.chaos-mesh.org/latest/web-show/deploy.sh | bash
</code></pre><blockquote><p>Note: The network latency of the Pod can be observed directly from the web-show application pad to the kube-system pod.</p></blockquote><ol><li><p>From your web browser, visit <code>${NodeIP}:8081</code> to access the <strong>Web Show</strong> application.</p><p><img src="/img/web-show-app.png" alt="Chaos Mesh web show app"/></p></li><li><p>Log in to Chaos Dashboard to create a chaos experiment. To observe the effect of network latency on the application, we set the <strong>Target </strong>as &quot;Network Attack&quot; to simulate a network delay scenario. </p><p><img src="/img/chaos-dashboard-networkchaos.png" alt="Chaos Dashboard"/></p><p>The <strong>Scope</strong> of the experiment is set to <code>app: web-show</code>.</p><p><img src="/img/chaos-experiment-scope.png" alt="Chaos Experiment scope"/><br/>
</p></li><li><p>Start the chaos experiment by submitting it. </p><p><img src="/img/start-chaos-experiment.png" alt="Submit Chaos Experiment"/>  </p></li></ol><p>Now, you should be able to visit <strong>Web Show</strong> to observe experiment results:    </p><p><img src="/img/experiment-result.png" alt="Chaos Experiment result"/>  </p><h2>To summarize</h2><p>KubeSphere makes cloud-native application deployments and maintenance easy. Thanks to the App Store, users can easily deploy Chaos Mesh on KubeSphere with just a few clicks, enabling you to quickly start your own chaos experiments.</p><p>To learn more about Chaos Mesh, refer to the <a href="https://chaos-mesh.org/docs/">Chaos Mesh docs</a> or join the community Slack (<a href="https://slack.cncf.io/">CNCF</a>/#project-chaos-mesh).</p>]]></content>
        <author>
            <name>Cwen Yin</name>
            <uri>https://github.com/cwen0</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chaos Mesh + SkyWalking: Better Observability for Chaos Engineering]]></title>
        <id>/better-observability-for-chaos-engineering</id>
        <link href="https://chaos-mesh.org/blog/better-observability-for-chaos-engineering"/>
        <updated>2021-12-16T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos Mesh + SkyWalking: Better Observability for Chaos Engineering]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-skywalking-banner.png" alt="Chaos Mesh + SkyWalking: Better Observability for Chaos Engineering"/></p><p><a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a> is an open-source cloud-native <a href="https://en.wikipedia.org/wiki/Chaos_engineering">chaos engineering</a> platform. You can use Chaos Mesh to conveniently inject failures and simulate abnormalities that might occur in reality, so you can identify potential problems in your system. Chaos Mesh also offers a Chaos Dashboard which allows you to monitor the status of a chaos experiment. However, this dashboard cannot let you observe how the failures in the experiment impact the service performance of applications. This hinders us from further testing our systems and finding potential problems. </p><p><a href="https://github.com/apache/skywalking">Apache SkyWalking</a> is an open-source application performance monitor (APM), specially designed to monitor, track, and diagnose cloud native, container-based distributed systems. It collects events that occur and then displays them on its dashboard, allowing you to observe directly the type and number of events that have occurred in your system and how different events impact the service performance. </p><p>When you use SkyWalking and Chaos Mesh together during chaos experiments, you can observe how different failures impact the service performance. </p><p>This tutorial will show you how to configure SkyWalking and Chaos Mesh. You‚Äôll also learn how to leverage the two systems to monitor events and observe in real time how chaos experiments impact applications‚Äô service performance. </p><h2>Preparation</h2><p>Before you start to use SkyWalking and Chaos Mesh, you have to:</p><ul><li>Set up a SkyWalking cluster according to <a href="https://github.com/apache/skywalking-kubernetes#install">the SkyWalking configuration guide</a>.</li><li>Deploy Chao Mesh <a href="https://chaos-mesh.org/docs/production-installation-using-helm/">using Helm</a>.</li><li>Install <a href="https://jmeter.apache.org/index.html">JMeter</a> or other Java testing tools (to increase service loads).</li><li>Configure SkyWalking and Chaos Mesh according to <a href="https://github.com/chaos-mesh/chaos-mesh-on-skywalking">this guide</a> if you just want to run a demo.</li></ul><p>Now, you are fully prepared, and we can cut to the chase. </p><h2>Step 1: Access the SkyWalking cluster</h2><p>After you install the SkyWalking cluster, you can access its user interface (UI). However, no service is running at this point, so before you start monitoring, you have to add one and set the agents.</p><p>In this tutorial, we take Spring Boot, a lightweight microservice framework, as an example to build a simplified demo environment.</p><ol><li>Create a SkyWalking demo in Spring Boot by referring to <a href="https://github.com/chaos-mesh/chaos-mesh-on-skywalking/blob/master/demo-deployment.yaml">this document</a>.</li><li>Execute the command <code>kubectl apply -f demo-deployment.yaml -n skywalking</code> to deploy the demo. </li></ol><p>After you finish deployment, you can observe the real-time monitoring results at the SkyWalking UI. </p><p><strong>Note:</strong> Spring Boot and SkyWalking have the same default port number: 8080. Be careful when you configure the port forwarding; otherise, you may have port conflicts. For example, you can set Spring Boot‚Äôs port to 8079 by using a command like <code>kubectl port-forward svc/spring-boot-skywalking-demo 8079:8080 -n skywalking</code> to avoid conflicts. </p><h2>Step 2: Deploy SkyWalking Kubernetes Event Exporter</h2><p><a href="https://github.com/apache/skywalking-kubernetes-event-exporter">SkyWalking Kubernetes Event Exporter</a> is able to watch, filter, and send Kubernetes events into the SkyWalking backend. SkyWalking then associates the events with the system metrics and displays an overview about when and how the metrics are affected by the events.</p><p>If you want to deploy SkyWalking Kubernetes Event Explorer with one line of commands, refer to <a href="https://github.com/chaos-mesh/chaos-mesh-on-skywalking/blob/master/exporter-deployment.yaml">this document</a> to create configuration files in YAML format and then customize the parameters in the filters and exporters. Now, you can use the command <code>kubectl apply</code> to deploy SkyWalking Kubernetes Event Explorer. </p><h2>Step 3: Use JMeter to increase service loads</h2><p>To better observe the change in service performance, you need to increase the service loads on Spring Boot. In this tutorial, we use JMeter, a widely adopted Java testing tool, to increase the service loads. </p><p>Perform a stress test on <code>localhost:8079</code> using JMeter and add five threads to continuously increase the service loads. </p><p><img src="/img/jmeter-1.png" alt="JMeter Dashboard 1"/></p><p><img src="/img/jmeter-2.png" alt="JMeter Dashboard 2"/></p><p>Open the SkyWalking Dashboard. You can see that the access rate is 100%, and that the service loads reach about 5,300 calls per minute (CPM). </p><p><img src="/img/skywalking-dashboard.png" alt="SkyWalking Dashboard"/></p><h2>Step 4: Inject failures via Chaos Mesh and observe results</h2><p>After you finish the three steps above, you can use the Chaos Dashboard to simulate stress scenarios and observe the change in service performance during chaos experiments. </p><p><img src="/img/chaos-dashboard-stresschaos.png" alt="StressChaos on Chaos Dashboard"/></p><p>The following sections describe how service performance varies under the stress of three chaos conditions:</p><ul><li><p>CPU load: 10%;  memory load: 128 MB</p><p>  The first chaos experiment simulates low CPU usage. To display when a chaos experiment starts and ends, click the switching button on the right side of the dashboard. To learn whether the experiment is Applied to the system or Recovered from the system, move your cursor onto the short, green line. </p><p>  During the time period between the two short, green lines, the service load decreases to 4,929 CPM, but returns to normal after the chaos experiment ends. </p><p>  <img src="/img/cpuload-1.png" alt="Test 1"/></p></li><li><p>CPU load: 50%; memory load: 128 MB</p><p>  When the application‚Äôs CPU load increases to 50%,  the service load decreases to 4,307 CPM.</p><p>  <img src="/img/cpuload-2.png" alt="Test 2"/></p></li><li><p>CPU load: 100%; memory load: 128 MB</p><p>  When the CPU usage is at 100%, the service load decreases to only 40% of what it would be if no chaos experiments were taking place. </p><p>  <img src="/img/cpuload-3.png" alt="Test 3"/></p><p>  Because the process scheduling under the Linux system does not allow a process to occupy the CPU all the time, the deployed Spring Boot Demo can still handle 40% of the access requests even in the extreme case of a full CPU load.</p></li></ul><h2>Summary</h2><p>By combining SkyWalking and Chaos Mesh, you can clearly observe when and to what extent chaos experiments affect application service performance. This combination of tools lets you observe the service performance in various extreme conditions, thus boosting your confidence in your services. </p><p>Chaos Mesh has grown a lot in 2021 thanks to the unremitting efforts of all PingCAP engineers and community contributors. In order to continue to upgrade our support for our wide variety of users and learn more about users‚Äô experience in Chaos Engineering, we‚Äôd like to invite you to take<a href="https://www.surveymonkey.com/r/X77BCNM"> this survey</a> and give us your valuable feedback. </p><p>If you want to know more about Chaos Mesh, you‚Äôre welcome to join <a href="https://github.com/chaos-mesh">the Chaos Mesh community on GitHub</a> or our <a href="https://slack.cncf.io/">Slack discussions</a> (#project-chaos-mesh). If you find any bugs or missing features when using Chaos Mesh, you can submit your pull requests or issues to our <a href="https://github.com/chaos-mesh/chaos-mesh">GitHub repository</a>.</p>]]></content>
        <author>
            <name>Ningxuan Wang</name>
            <uri>https://github.com/FingerLeader</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Implementing Chaos Engineering in K8s: Chaos Mesh Principle Analysis and Control Plane Development]]></title>
        <id>/implement-chaos-engineering-in-k8s</id>
        <link href="https://chaos-mesh.org/blog/implement-chaos-engineering-in-k8s"/>
        <updated>2021-12-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Implementing Chaos Engineering in K8s]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/implement-chaos-engineering-in-k8s.png" alt="Implementing Chaos Engineering in K8s"/></p><p><a href="https://chaos-mesh.org/docs/">Chaos Mesh</a> is an open-source, cloud-native Chaos Engineering platform built on Kubernetes (K8s) custom resource definitions (CRDs). Chaos Mesh can simulate various types of faults and has an enormous capability to orchestrate fault scenarios. You can use Chaos Mesh to conveniently simulate various abnormalities that might occur in development, testing, and production environments and find potential problems in the system.</p><p>In this article, I&#x27;ll explore the practice of Chaos Engineering in Kubernetes clusters, discuss important Chaos Mesh features through analysis of its source code, and explain how to develop Chaos Mesh&#x27;s control plane with code examples.</p><p>If you&#x27;re not familiar with Chaos Mesh, please review the <a href="https://chaos-mesh.org/docs/#architecture-overview">Chaos Mesh documentation</a> to get a basic knowledge of Chaos Mesh&#x27;s architecture.</p><p>For the test code in this article, see the <a href="https://github.com/mayocream/chaos-mesh-controlpanel-demo">mayocream/chaos-mesh-controlpanel-demo</a> repository on GitHub.</p><h2>How Chaos Mesh creates chaos</h2><p>Chaos Mesh is a Swiss army knife for implementing Chaos Engineering on Kubernetes. This section introduces how it works.</p><h3>Privileged mode</h3><p>Chaos Mesh runs privileged containers in Kubernetes to create failures. Chaos Daemon&#x27;s Pod runs as <code>DaemonSet</code> and adds additional <a href="https://kubernetes.io/docs/concepts/policy/pod-security-policy/#capabilities">capabilities</a> to the Pod&#x27;s container runtime via the Pod&#x27;s security context.</p><pre><code class="language-yaml">apiVersion: apps/v1
kind: DaemonSet
spec:
 template:
   metadata: ...
   spec:
     containers:
       - name: chaos-daemon
         securityContext:
           {{- if .Values.chaosDaemon.privileged }}
           privileged: true
           capabilities:
             add:
               - SYS_PTRACE
           {{- else }}
           capabilities:
             add:
               - SYS_PTRACE
               - NET_ADMIN
               - MKNOD
               - SYS_CHROOT
               - SYS_ADMIN
               - KILL
               # CAP_IPC_LOCK is used to lock memory
               - IPC_LOCK
           {{- end }}
</code></pre><p>The Linux capabilities grant containers privileges to create and access the <code>/dev/fuse</code> Filesystem in Userspace (FUSE) pipe. FUSE is the Linux userspace filesystem interface. It lets non-privileged users create their own file systems without editing the kernel code.</p><p>According to <a href="https://github.com/chaos-mesh/chaos-mesh/pull/1109">pull request #1109</a> on GitHub, the <code>DaemonSet</code> program uses cgo to call the Linux <code>makedev</code> function to create a FUSE pipe.</p><pre><code class="language-go">// #include &lt;sys/sysmacros.h&gt;
// #include &lt;sys/types.h&gt;
// // makedev is a macro, so a wrapper is needed
// dev_t Makedev(unsigned int maj, unsigned int min) {
//   return makedev(maj, min);
// }
// EnsureFuseDev ensures /dev/fuse exists. If not, it will create one

func EnsureFuseDev() {
   if _, err := os.Open(&quot;/dev/fuse&quot;); os.IsNotExist(err) {
       // 10, 229 according to https://www.kernel.org/doc/Documentation/admin-guide/devices.txt
       fuse := C.Makedev(10, 229)
       syscall.Mknod(&quot;/dev/fuse&quot;, 0o666|syscall.S_IFCHR, int(fuse))
   }
}
</code></pre><p>In <a href="https://github.com/chaos-mesh/chaos-mesh/pull/1453">pull request #1453</a>, Chaos Daemon enables privileged mode by default; that is, it sets <code>privileged: true</code> in the container&#x27;s <code>SecurityContext</code>.</p><h3>Killing Pods</h3><p><code>PodKill</code>, <code>PodFailure</code>, and <code>ContainerKill</code> belong to the <code>PodChaos</code> category. <code>PodKill</code> randomly kills a Pod. It calls the API server to send the kill command.</p><pre><code class="language-go">import (
   &quot;context&quot;
   v1 &quot;k8s.io/api/core/v1&quot;
   &quot;sigs.k8s.io/controller-runtime/pkg/client&quot;
)

type Impl struct {
   client.Client
}

func (impl *Impl) Apply(ctx context.Context, index int, records []*v1alpha1.Record, obj v1alpha1.InnerObject) (v1alpha1.Phase, error) {
   ...
   err = impl.Get(ctx, namespacedName, &amp;pod)
   if err != nil {
       // TODO: handle this error
       return v1alpha1.NotInjected, err
   }
   err = impl.Delete(ctx, &amp;pod, &amp;client.DeleteOptions{
       GracePeriodSeconds: &amp;podchaos.Spec.GracePeriod, // PeriodSeconds has to be set specifically
   })
   ...
   return v1alpha1.Injected, nil
}
</code></pre><p>The <code>GracePeriodSeconds</code> parameter lets Kubernetes <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination-forced">forcibly terminate a Pod</a>. For example, if you need to delete a Pod immediately, use the <code>kubectl delete pod --grace-period=0 --force</code> command.</p><p><code>PodFailure</code> patches the Pod object resource to replace the image in the Pod with a wrong one. Chaos only modifies the <code>image</code> fields of <code>containers</code> and <code>initContainers</code>. This is because most of the metadata about a Pod is immutable. For more details, see <a href="https://kubernetes.io/docs/concepts/workloads/pods/#pod-update-and-replacement">Pod update and replacement</a>.</p><pre><code class="language-go">func (impl *Impl) Apply(ctx context.Context, index int, records []*v1alpha1.Record, obj v1alpha1.InnerObject) (v1alpha1.Phase, error) {
   ...
   pod := origin.DeepCopy()
   for index := range pod.Spec.Containers {
       originImage := pod.Spec.Containers[index].Image
       name := pod.Spec.Containers[index].Name
       key := annotation.GenKeyForImage(podchaos, name, false)
       if pod.Annotations == nil {
           pod.Annotations = make(map[string]string)
       }
       // If the annotation is already existed, we could skip the reconcile for this container
       if _, ok := pod.Annotations[key]; ok {
           continue
       }
       pod.Annotations[key] = originImage
       pod.Spec.Containers[index].Image = config.ControllerCfg.PodFailurePauseImage
   }
   for index := range pod.Spec.InitContainers {
       originImage := pod.Spec.InitContainers[index].Image
       name := pod.Spec.InitContainers[index].Name
       key := annotation.GenKeyForImage(podchaos, name, true)
       if pod.Annotations == nil {
           pod.Annotations = make(map[string]string)
       }
       // If the annotation is already existed, we could skip the reconcile for this container
       if _, ok := pod.Annotations[key]; ok {
           continue
       }
       pod.Annotations[key] = originImage
       pod.Spec.InitContainers[index].Image = config.ControllerCfg.PodFailurePauseImage
   }
   err = impl.Patch(ctx, pod, client.MergeFrom(&amp;origin))
   if err != nil {
       // TODO: handle this error
       return v1alpha1.NotInjected, err
   }
   return v1alpha1.Injected, nil
}
</code></pre><p>The default container image that causes failures is <code>gcr.io/google-containers/pause:latest</code>.</p><p><code>PodKill</code> and <code>PodFailure</code> control the Pod lifecycle through the Kubernetes API server. But <code>ContainerKill</code> does this through Chaos Daemon that runs on the cluster node. <code>ContainerKill</code> uses Chaos Controller Manager to run the client to initiate gRPC calls to Chaos Daemon.</p><pre><code class="language-go">func (b *ChaosDaemonClientBuilder) Build(ctx context.Context, pod *v1.Pod) (chaosdaemonclient.ChaosDaemonClientInterface, error) {
   ...
   daemonIP, err := b.FindDaemonIP(ctx, pod)
   if err != nil {
       return nil, err
   }
   builder := grpcUtils.Builder(daemonIP, config.ControllerCfg.ChaosDaemonPort).WithDefaultTimeout()
   if config.ControllerCfg.TLSConfig.ChaosMeshCACert != &quot;&quot; {
       builder.TLSFromFile(config.ControllerCfg.TLSConfig.ChaosMeshCACert, config.ControllerCfg.TLSConfig.ChaosDaemonClientCert, config.ControllerCfg.TLSConfig.ChaosDaemonClientKey)
   } else {
       builder.Insecure()
   }
   cc, err := builder.Build()
   if err != nil {
       return nil, err
   }
   return chaosdaemonclient.New(cc), nil
}
</code></pre><p>When Chaos Controller Manager sends commands to Chaos Daemon, it creates a corresponding client based on the Pod information. For example, to control a Pod on a node, it creates a client by getting the <code>ClusterIP</code> of the node where the Pod is located. If the Transport Layer Security (TLS) certificate configuration exists, Controller Manager adds the TLS certificate for the client.</p><p>When Chaos Daemon starts, if it has a TLS certificate it attaches the certificate to enable gRPCS. The TLS configuration option <code>RequireAndVerifyClientCert</code> indicates whether to enable mutual TLS (mTLS) authentication.</p><pre><code class="language-go">func newGRPCServer(containerRuntime string, reg prometheus.Registerer, tlsConf tlsConfig) (*grpc.Server, error) {
   ...
   if tlsConf != (tlsConfig{}) {
       caCert, err := ioutil.ReadFile(tlsConf.CaCert)
       if err != nil {
           return nil, err
       }
       caCertPool := x509.NewCertPool()
       caCertPool.AppendCertsFromPEM(caCert)
       serverCert, err := tls.LoadX509KeyPair(tlsConf.Cert, tlsConf.Key)
       if err != nil {
           return nil, err
       }
       creds := credentials.NewTLS(&amp;tls.Config{
           Certificates: []tls.Certificate{serverCert},
           ClientCAs:    caCertPool,
           ClientAuth:   tls.RequireAndVerifyClientCert,
       })
       grpcOpts = append(grpcOpts, grpc.Creds(creds))
   }
   s := grpc.NewServer(grpcOpts...)
   grpcMetrics.InitializeMetrics(s)
   pb.RegisterChaosDaemonServer(s, ds)
   reflection.Register(s)
   return s, nil
}
</code></pre><p>Chaos Daemon provides the following gRPC interfaces to call:</p><pre><code class="language-go">// ChaosDaemonClient is the client API for ChaosDaemon service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.

type ChaosDaemonClient interface {

   SetTcs(ctx context.Context, in *TcsRequest, opts ...grpc.CallOption) (*empty.Empty, error)
   FlushIPSets(ctx context.Context, in *IPSetsRequest, opts ...grpc.CallOption) (*empty.Empty, error)
   SetIptablesChains(ctx context.Context, in *IptablesChainsRequest, opts ...grpc.CallOption) (*empty.Empty, error)
   SetTimeOffset(ctx context.Context, in *TimeRequest, opts ...grpc.CallOption) (*empty.Empty, error)
   RecoverTimeOffset(ctx context.Context, in *TimeRequest, opts ...grpc.CallOption) (*empty.Empty, error)
   ContainerKill(ctx context.Context, in *ContainerRequest, opts ...grpc.CallOption) (*empty.Empty, error)
   ContainerGetPid(ctx context.Context, in *ContainerRequest, opts ...grpc.CallOption) (*ContainerResponse, error)
   ExecStressors(ctx context.Context, in *ExecStressRequest, opts ...grpc.CallOption) (*ExecStressResponse, error)
   CancelStressors(ctx context.Context, in *CancelStressRequest, opts ...grpc.CallOption) (*empty.Empty, error)
   ApplyIOChaos(ctx context.Context, in *ApplyIOChaosRequest, opts ...grpc.CallOption) (*ApplyIOChaosResponse, error)
   ApplyHttpChaos(ctx context.Context, in *ApplyHttpChaosRequest, opts ...grpc.CallOption) (*ApplyHttpChaosResponse, error)
   SetDNSServer(ctx context.Context, in *SetDNSServerRequest, opts ...grpc.CallOption) (*empty.Empty, error)
}
</code></pre><h3>Network failure injection</h3><p>From <a href="https://github.com/chaos-mesh/chaos-mesh/pull/41">pull request #41</a>, we know that Chaos Mesh injects network failures this way: it calls <code>pbClient.SetNetem</code> to encapsulate parameters into a request and send the request to the Chaos Daemon on the node for processing.</p><p>The network failure injection code is shown below as it appeared in 2019. As the project developed, the functions were distributed among several files.</p><pre><code class="language-go">func (r *Reconciler) applyPod(ctx context.Context, pod *v1.Pod, networkchaos *v1alpha1.NetworkChaos) error {
   ...
   pbClient := pb.NewChaosDaemonClient(c)
   containerId := pod.Status.ContainerStatuses[0].ContainerID
   netem, err := spec.ToNetem()
   if err != nil {
       return err
   }
   _, err = pbClient.SetNetem(ctx, &amp;pb.NetemRequest{
       ContainerId: containerId,
       Netem:       netem,
   })
   return err
}
</code></pre><p>In the <code>pkg/chaosdaemon</code> package, we can see how Chaos Daemon processes requests.</p><pre><code class="language-go">func (s *Server) SetNetem(ctx context.Context, in *pb.NetemRequest) (*empty.Empty, error) {
   log.Info(&quot;Set netem&quot;, &quot;Request&quot;, in)
   pid, err := s.crClient.GetPidFromContainerID(ctx, in.ContainerId)
   if err != nil {
       return nil, status.Errorf(codes.Internal, &quot;get pid from containerID error: %v&quot;, err)
   }
   if err := Apply(in.Netem, pid); err != nil {
       return nil, status.Errorf(codes.Internal, &quot;netem apply error: %v&quot;, err)
   }
   return &amp;empty.Empty{}, nil
}

// Apply applies a netem on eth0 in pid related namespace

func Apply(netem *pb.Netem, pid uint32) error {
   log.Info(&quot;Apply netem on PID&quot;, &quot;pid&quot;, pid)
   ns, err := netns.GetFromPath(GenNetnsPath(pid))
   if err != nil {
       log.Error(err, &quot;failed to find network namespace&quot;, &quot;pid&quot;, pid)
       return errors.Trace(err)
   }
   defer ns.Close()
   handle, err := netlink.NewHandleAt(ns)
   if err != nil {
       log.Error(err, &quot;failed to get handle at network namespace&quot;, &quot;network namespace&quot;, ns)
       return err
   }
   link, err := handle.LinkByName(&quot;eth0&quot;) // TODO: check whether interface name is eth0
   if err != nil {
       log.Error(err, &quot;failed to find eth0 interface&quot;)
       return errors.Trace(err)
   }
   netemQdisc := netlink.NewNetem(netlink.QdiscAttrs{
       LinkIndex: link.Attrs().Index,
       Handle:    netlink.MakeHandle(1, 0),
       Parent:    netlink.HANDLE_ROOT,
   }, ToNetlinkNetemAttrs(netem))
   if err = handle.QdiscAdd(netemQdisc); err != nil {
       if !strings.Contains(err.Error(), &quot;file exists&quot;) {
           log.Error(err, &quot;failed to add Qdisc&quot;)
           return errors.Trace(err)
       }
   }
   return nil
}
</code></pre><p>Finally, the <a href="https://github.com/vishvananda/netlink"><code>vishvananda/netlink</code> library</a> operates the Linux network interface to complete the job.</p><p>From here, <code>NetworkChaos</code> manipulates the Linux host network to create chaos. It includes tools such as iptables and ipset.</p><p>In Chaos Daemon&#x27;s Dockerfile, you can see the Linux tool chain that it depends on:</p><pre><code class="language-dockerfile">RUN apt-get update &amp;&amp; \
   apt-get install -y tzdata iptables ipset stress-ng iproute2 fuse util-linux procps curl &amp;&amp; \
   rm -rf /var/lib/apt/lists/*
</code></pre><h3>Stress test</h3><p>Chaos Daemon also implements <code>StressChaos</code>. After the Controller Manager calculates the rules, it sends the task to the specific <code>Daemon</code>. The assembled parameters are shown below. They are combined into command execution parameters and appended to the <code>stress-ng</code> command for execution.</p><pre><code class="language-go">// Normalize the stressors to comply with stress-ng
func (in *Stressors) Normalize() (string, error) {
   stressors := &quot;&quot;
   if in.MemoryStressor != nil &amp;&amp; in.MemoryStressor.Workers != 0 {
       stressors += fmt.Sprintf(&quot; --vm %d --vm-keep&quot;, in.MemoryStressor.Workers)
       if len(in.MemoryStressor.Size) != 0 {
           if in.MemoryStressor.Size[len(in.MemoryStressor.Size)-1] != &#x27;%&#x27; {
               size, err := units.FromHumanSize(string(in.MemoryStressor.Size))
               if err != nil {
                   return &quot;&quot;, err
               }
               stressors += fmt.Sprintf(&quot; --vm-bytes %d&quot;, size)
           } else {
               stressors += fmt.Sprintf(&quot; --vm-bytes %s&quot;,
                   in.MemoryStressor.Size)
           }
       }
       if in.MemoryStressor.Options != nil {
           for _, v := range in.MemoryStressor.Options {
               stressors += fmt.Sprintf(&quot; %v &quot;, v)
           }
       }
   }
   if in.CPUStressor != nil &amp;&amp; in.CPUStressor.Workers != 0 {
       stressors += fmt.Sprintf(&quot; --cpu %d&quot;, in.CPUStressor.Workers)
       if in.CPUStressor.Load != nil {
           stressors += fmt.Sprintf(&quot; --cpu-load %d&quot;,
               *in.CPUStressor.Load)
       }
       if in.CPUStressor.Options != nil {
           for _, v := range in.CPUStressor.Options {
               stressors += fmt.Sprintf(&quot; %v &quot;, v)
           }
       }
   }
   return stressors, nil
}
</code></pre><p>The Chaos Daemon server side processes the function&#x27;s execution command to call the official Go package <code>os/exec</code>. For details, see the <a href="https://github.com/chaos-mesh/chaos-mesh/blob/98af3a0e7832a4971d6b133a32069539d982ef0a/pkg/chaosdaemon/stress_server_linux.go#L33"><code>pkg/chaosdaemon/stress_server_linux.go</code></a> file. There is also a file with the same name that ends with darwin. <code>*_darwin</code> files prevent possible errors when the program is running on macOS.</p><p>The code uses the <a href="https://github.com/shirou/gopsutil"><code>shirou/gopsutil</code></a> package to obtain the PID process status and reads the stdout and stderr standard outputs. I&#x27;ve seen this processing mode in <a href="https://github.com/hashicorp/go-plugin"><code>hashicorp/go-plugin</code></a>, and go-plugin does this better.</p><h3>I/O fault injection</h3><p><a href="https://github.com/chaos-mesh/chaos-mesh/pull/826">Pull request #826</a> introduces a new implementation of IOChaos, without the use of sidecar injection. It uses Chaos Daemon to directly manipulate the Linux namespace through the underlying commands of the <a href="https://github.com/opencontainers/runc">runc</a> container and runs the <a href="https://github.com/chaos-mesh/toda">chaos-mesh/toda</a> FUSE program developed by Rust to inject container I/O chaos. The <a href="https://pkg.go.dev/github.com/ethereum/go-ethereum/rpc">JSON-RPC 2.0</a> protocol is used to communicate between toda and the control plane.</p><p>The new IOChaos implementation doesn&#x27;t modify the Pod resources. When you define the IOChaos chaos experiment, for each Pod filtered by the selector field, a corresponding PodIOChaos resource is created. PodIoChaos&#x27; <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/owners-dependents/">owner reference</a> is the Pod. At the same time, a set of <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/finalizers/">finalizers</a> is added to PodIoChaos to release PodIoChaos resources before PodIoChaos is deleted.</p><pre><code class="language-go">// Apply implements the reconciler.InnerReconciler.Apply

func (r *Reconciler) Apply(ctx context.Context, req ctrl.Request, chaos v1alpha1.InnerObject) error {
   iochaos, ok := chaos.(*v1alpha1.IoChaos)
   if !ok {
       err := errors.New(&quot;chaos is not IoChaos&quot;)
       r.Log.Error(err, &quot;chaos is not IoChaos&quot;, &quot;chaos&quot;, chaos)
       return err
   }
   source := iochaos.Namespace + &quot;/&quot; + iochaos.Name
   m := podiochaosmanager.New(source, r.Log, r.Client)
   pods, err := utils.SelectAndFilterPods(ctx, r.Client, r.Reader, &amp;iochaos.Spec)
   if err != nil {
       r.Log.Error(err, &quot;failed to select and filter pods&quot;)
       return err
   }
   r.Log.Info(&quot;applying iochaos&quot;, &quot;iochaos&quot;, iochaos)
   for _, pod := range pods {
       t := m.WithInit(types.NamespacedName{
           Name:      pod.Name,
           Namespace: pod.Namespace,
       })

       // TODO: support chaos on multiple volume

       t.SetVolumePath(iochaos.Spec.VolumePath)
       t.Append(v1alpha1.IoChaosAction{
           Type: iochaos.Spec.Action,
           Filter: v1alpha1.Filter{
               Path:    iochaos.Spec.Path,
               Percent: iochaos.Spec.Percent,
               Methods: iochaos.Spec.Methods,
           },
           Faults: []v1alpha1.IoFault{
               {
                   Errno:  iochaos.Spec.Errno,
                   Weight: 1,
               },
           },
           Latency:          iochaos.Spec.Delay,
           AttrOverrideSpec: iochaos.Spec.Attr,
           Source:           m.Source,
       })
       key, err := cache.MetaNamespaceKeyFunc(&amp;pod)
       if err != nil {
           return err
       }
       iochaos.Finalizers = utils.InsertFinalizer(iochaos.Finalizers, key)
   }
   r.Log.Info(&quot;commiting updates of podiochaos&quot;)
   err = m.Commit(ctx)
   if err != nil {
       r.Log.Error(err, &quot;fail to commit&quot;)
       return err
   }
   r.Event(iochaos, v1.EventTypeNormal, utils.EventChaosInjected, &quot;&quot;)
   return nil
}
</code></pre><p>In the controller of the PodIoChaos resource, Controller Manager encapsulates the resource into parameters and calls the Chaos Daemon interface to process the parameters.</p><pre><code class="language-go">// Apply flushes io configuration on pod

func (h *Handler) Apply(ctx context.Context, chaos *v1alpha1.PodIoChaos) error {
   h.Log.Info(&quot;updating io chaos&quot;, &quot;pod&quot;, chaos.Namespace+&quot;/&quot;+chaos.Name, &quot;spec&quot;, chaos.Spec)
   ...
   res, err := pbClient.ApplyIoChaos(ctx, &amp;pb.ApplyIoChaosRequest{
       Actions:     input,
       Volume:      chaos.Spec.VolumeMountPath,
       ContainerId: containerID,
       Instance:  chaos.Spec.Pid,
       StartTime: chaos.Spec.StartTime,
   })
   if err != nil {
       return err
   }
   chaos.Spec.Pid = res.Instance
   chaos.Spec.StartTime = res.StartTime
   chaos.OwnerReferences = []metav1.OwnerReference{
       {
           APIVersion: pod.APIVersion,
           Kind:       pod.Kind,
           Name:       pod.Name,
           UID:        pod.UID,
       },
   }
   return nil
}
</code></pre><p>The <code>pkg/chaosdaemon/iochaos_server.go</code> file processes IOChaos. ‚Äã‚ÄãIn this file, a FUSE program needs to be injected into the container. As discussed in issue <a href="https://github.com/chaos-mesh/chaos-mesh/issues/2305">#2305</a> on GitHub, the <code>/usr/local/bin/nsexec -l- p /proc/119186/ns/pid -m /proc/119186/ns/mnt - /usr/local/bin/toda --path /tmp --verbose info</code> command is executed to run the toda program under the same namespace as the Pod.</p><pre><code class="language-go">func (s *DaemonServer) ApplyIOChaos(ctx context.Context, in *pb.ApplyIOChaosRequest) (*pb.ApplyIOChaosResponse, error) {
   ...
   pid, err := s.crClient.GetPidFromContainerID(ctx, in.ContainerId)
   if err != nil {
       log.Error(err, &quot;error while getting PID&quot;)
       return nil, err
   }
   args := fmt.Sprintf(&quot;--path %s --verbose info&quot;, in.Volume)
   log.Info(&quot;executing&quot;, &quot;cmd&quot;, todaBin+&quot; &quot;+args)
   processBuilder := bpm.DefaultProcessBuilder(todaBin, strings.Split(args, &quot; &quot;)...).
       EnableLocalMnt().
       SetIdentifier(in.ContainerId)
   if in.EnterNS {
       processBuilder = processBuilder.SetNS(pid, bpm.MountNS).SetNS(pid, bpm.PidNS)
   }
   ...

   // Calls JSON RPC

   client, err := jrpc.DialIO(ctx, receiver, caller)
   if err != nil {
       return nil, err
   }
   cmd := processBuilder.Build()
   procState, err := s.backgroundProcessManager.StartProcess(cmd)
   if err != nil {
       return nil, err
   }
   ...
}
</code></pre><p>The following code sample builds the running commands. These commands are the underlying namespace isolation implementation of runc:</p><pre><code class="language-go">// GetNsPath returns corresponding namespace path

func GetNsPath(pid uint32, typ NsType) string {
   return fmt.Sprintf(&quot;%s/%d/ns/%s&quot;, DefaultProcPrefix, pid, string(typ))
}

// SetNS sets the namespace of the process

func (b *ProcessBuilder) SetNS(pid uint32, typ NsType) *ProcessBuilder {
   return b.SetNSOpt([]nsOption{{
       Typ:  typ,
       Path: GetNsPath(pid, typ),
   }})
}

// Build builds the process

func (b *ProcessBuilder) Build() *ManagedProcess {
   args := b.args
   cmd := b.cmd
   if len(b.nsOptions) &gt; 0 {
       args = append([]string{&quot;--&quot;, cmd}, args...)
       for _, option := range b.nsOptions {
           args = append([]string{&quot;-&quot; + nsArgMap[option.Typ], option.Path}, args...)
       }
       if b.localMnt {
           args = append([]string{&quot;-l&quot;}, args...)
       }
       cmd = nsexecPath
   }
   ...
}
</code></pre><h2>Control plane</h2><p>Chaos Mesh is an open-source chaos engineering system under the Apache 2.0 protocol. As discussed above, it has rich capabilities and a good ecosystem. The maintenance team developed the <a href="https://github.com/chaos-mesh/toda"><code>chaos-mesh/toda</code></a> FUSE based on the chaos system, the <a href="https://github.com/chaos-mesh/k8s_dns_chaos"><code>chaos-mesh/k8s_dns_chaos</code></a> CoreDNS chaos plug-in, and Berkeley Packet Filter (BPF)-based kernel error injection <a href="https://github.com/chaos-mesh/bpfki"><code>chaos-mesh/bpfki</code></a>.</p><p>Now, I&#x27;ll describe the server side code required to build an end-user-oriented chaos engineering platform. This implementation is only an example‚Äînot necessarily the best example. If you want to see the development practice on a real world platform, you can refer to Chaos Mesh&#x27;s <a href="https://github.com/chaos-mesh/chaos-mesh/tree/master/pkg/dashboard">Dashboard</a>. It uses the <a href="https://github.com/uber-go/fx"><code>uber-go/fx</code></a> dependency injection framework and the controller runtime&#x27;s manager mode.</p><h3>Key Chaos Mesh features</h3><p>As shown in the Chaos Mesh workflow below, we need to implement a server that sends YAML to the Kubernetes API. Chaos Controller Manager implements complex rule verification and rule delivery to Chaos Daemon. If you want to use Chaos Mesh with your own platform, you only need to connect to the process of creating CRD resources.</p><p><img src="/img/chaos-mesh-basic-workflow.png" alt="Chaos Mesh&#x27;s basic workflow"/></p><p class="caption-center">Chaos Mesh&#x27;s basic workflow</p><p>Let&#x27;s take a look at the example on the Chaos Mesh website:</p><pre><code class="language-go">import (
   &quot;context&quot;
   &quot;github.com/pingcap/chaos-mesh/api/v1alpha1&quot;
   &quot;sigs.k8s.io/controller-runtime/pkg/client&quot;
)

func main() {
   ...
   delay := &amp;chaosv1alpha1.NetworkChaos{
       Spec: chaosv1alpha1.NetworkChaosSpec{...},
   }
   k8sClient := client.New(conf, client.Options{ Scheme: scheme.Scheme })
   k8sClient.Create(context.TODO(), delay)
   k8sClient.Delete(context.TODO(), delay)
}
</code></pre><p>Chaos Mesh provides APIs corresponding to all CRDs. We use the <a href="https://github.com/kubernetes-sigs/controller-runtime">controller-runtime</a> developed by Kubernetes <a href="https://github.com/kubernetes/community/tree/master/sig-api-machinery">API Machinery SIG</a> to simplify the interaction with the Kubernetes API.</p><h3>Inject chaos</h3><p>Suppose we want to create a <code>PodKill</code> resource by calling a program. After the resource is sent to the Kubernetes API server, it passes Chaos Controller Manager&#x27;s <a href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/">validating admission controller</a> to verify data. When we create a chaos experiment, if the admission controller fails to verify the input data, it returns an error to the client. For specific parameters, you can read <a href="https://chaos-mesh.org/docs/simulate-pod-chaos-on-kubernetes/#create-experiments-using-yaml-configuration-files">Create experiments using YAML configuration files</a>.</p><p><code>NewClient</code> creates a Kubernetes API client. You can refer to this example:</p><pre><code class="language-go">package main

import (
   &quot;context&quot;
   &quot;controlpanel&quot;
   &quot;log&quot;
   &quot;github.com/chaos-mesh/chaos-mesh/api/v1alpha1&quot;
   &quot;github.com/pkg/errors&quot;
   metav1 &quot;k8s.io/apimachinery/pkg/apis/meta/v1&quot;
)

func applyPodKill(name, namespace string, labels map[string]string) error {
   cli, err := controlpanel.NewClient()
   if err != nil {
       return errors.Wrap(err, &quot;create client&quot;)
   }
   cr := &amp;v1alpha1.PodChaos{
       ObjectMeta: metav1.ObjectMeta{
           GenerateName: name,
           Namespace:    namespace,
       },
       Spec: v1alpha1.PodChaosSpec{
           Action: v1alpha1.PodKillAction,
           ContainerSelector: v1alpha1.ContainerSelector{
               PodSelector: v1alpha1.PodSelector{
                   Mode: v1alpha1.OnePodMode,
                   Selector: v1alpha1.PodSelectorSpec{
                       Namespaces:     []string{namespace},
                       LabelSelectors: labels,
                   },
               },
           },
       },
   }

   if err := cli.Create(context.Background(), cr); err != nil {
       return errors.Wrap(err, &quot;create podkill&quot;)
   }
   return nil
}
</code></pre><p>The log output of the running program is:</p><pre><code class="language-bash">I1021 00:51:55.225502   23781 request.go:665] Waited for 1.033116256s due to client-side throttling, not priority and fairness, request: GET:https://***
2021/10/21 00:51:56 apply podkill
</code></pre><p>Use kubectl to check the status of the <code>PodKill</code> resource:</p><pre><code class="language-bash">$ k describe podchaos.chaos-mesh.org -n dev podkillvjn77
Name:         podkillvjn77
Namespace:    dev
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;
API Version:  chaos-mesh.org/v1alpha1
Kind:         PodChaos

Metadata:
 Creation Timestamp:  2021-10-20T16:51:56Z
 Finalizers:
   chaos-mesh/records
 Generate Name:     podkill
 Generation:        7
 Resource Version:  938921488
 Self Link:         /apis/chaos-mesh.org/v1alpha1/namespaces/dev/podchaos/podkillvjn77
 UID:               afbb40b3-ade8-48ba-89db-04918d89fd0b

Spec:
 Action:        pod-kill
 Grace Period:  0
 Mode:          one
 Selector:
   Label Selectors:
     app:  nginx
   Namespaces:
     dev

Status:
 Conditions:
   Reason:
   Status:  False
   Type:    Paused
   Reason:
   Status:  True
   Type:    Selected
   Reason:
   Status:  True
   Type:    AllInjected
   Reason:
   Status:  False
   Type:    AllRecovered

 Experiment:
   Container Records:
     Id:            dev/nginx
     Phase:         Injected
     Selector Key:  .
   Desired Phase:   Run

Events:
 Type    Reason           Age    From          Message
 ----    ------           ----   ----          -------
 Normal  FinalizerInited  6m35s  finalizer     Finalizer has been inited
 Normal  Updated          6m35s  finalizer     Successfully update finalizer of resource
 Normal  Updated          6m35s  records       Successfully update records of resource
 Normal  Updated          6m35s  desiredphase  Successfully update desiredPhase of resource
 Normal  Applied          6m35s  records       Successfully apply chaos for dev/nginx
 Normal  Updated          6m35s  records       Successfully update records of resource
</code></pre><p>The control plane also needs to query and acquire Chaos resources, so that platform users can view all chaos experiments&#x27; implementation status and manage them. To achieve this, we can call the <code>REST</code> API to send the <code>Get</code> or <code>List</code> request. But in practice, we need to pay attention to the details. At our company, we&#x27;ve noticed that each time the controller requests the full amount of resource data, the load of the Kubernetes API server increases.</p><p>I recommend that you read the <a href="https://zoetrope.github.io/kubebuilder-training/controller-runtime/client.html">How to use the controller-runtime client</a> (in Japanese) controller runtime tutorial. If you don&#x27;t understand Japanese, you can still learn a lot from the tutorial by reading the source code. It covers many details. For example, by default, the controller runtime reads kubeconfig, flags, environment variables, and the service account automatically mounted in the Pod from multiple locations. <a href="https://github.com/armosec/kubescape/pull/21">Pull request #21</a> for <a href="https://github.com/armosec/kubescape"><code>armosec/kubescape</code></a> uses this feature. This tutorial also includes common operations, such as how to paginate, update, and overwrite objects. I haven&#x27;t seen any English tutorials that are so detailed.</p><p>Here are examples of <code>Get</code> and <code>List</code> requests:</p><pre><code class="language-go">package controlpanel

import (
   &quot;context&quot;
   &quot;github.com/chaos-mesh/chaos-mesh/api/v1alpha1&quot;
   &quot;github.com/pkg/errors&quot;
   &quot;sigs.k8s.io/controller-runtime/pkg/client&quot;
)

func GetPodChaos(name, namespace string) (*v1alpha1.PodChaos, error) {
   cli := mgr.GetClient()
   item := new(v1alpha1.PodChaos)
   if err := cli.Get(context.Background(), client.ObjectKey{Name: name, Namespace: namespace}, item); err != nil {
       return nil, errors.Wrap(err, &quot;get cr&quot;)
   }
   return item, nil
}

func ListPodChaos(namespace string, labels map[string]string) ([]v1alpha1.PodChaos, error) {
   cli := mgr.GetClient()
   list := new(v1alpha1.PodChaosList)
   if err := cli.List(context.Background(), list, client.InNamespace(namespace), client.MatchingLabels(labels)); err != nil {
       return nil, err
   }
   return list.Items, nil
}
</code></pre><p>This example uses the manager. This mode prevents the cache mechanism from repetitively fetching large amounts of data. The following <a href="https://zoetrope.github.io/kubebuilder-training/controller-runtime/client.html">figure</a> shows the workflow:</p><ol><li><p>Get the Pod.</p></li><li><p>Get the <code>List</code> request&#x27;s full data for the first time.</p></li><li><p>Update the cache when the watch data changes.</p></li></ol><p><img src="/img/list-request.png" alt="List request"/></p><p class="caption-center">List request</p><h3>Orchestrate chaos</h3><p>The container runtime interface (CRI) container runtime provides strong underlying isolation capabilities that can support the stable operation of the container. But for more complex and scalable scenarios, container orchestration is required. Chaos Mesh also provides <a href="https://chaos-mesh.org/docs/define-scheduling-rules/"><code>Schedule</code></a> and <a href="https://chaos-mesh.org/docs/create-chaos-mesh-workflow/"><code>Workflow</code></a> features. Based on the set <code>Cron</code> time, <code>Schedule</code> can trigger faults regularly and at intervals. <code>Workflow</code> can schedule multiple fault tests like Argo Workflows.</p><p>Chaos Controller Manager does most of the work for us. The control plane mainly manages these YAML resources. You only need to consider the features you want to provide to end users.</p><h3>Platform features</h3><p>The following figure shows Chaos Mesh Dashboard. We need to consider what features the platform should provide to end users.</p><p><img src="/img/chaos-mesh-dashboard-k8s.png" alt="Chaos Mesh Dashboard"/></p><p class="caption-center">Chaos Mesh Dashboard</p><p>From the Dashboard, we know that the platform may have these features:</p><ul><li>Chaos injection</li><li>Pod crash</li><li>Network failure</li><li>Load test</li><li>I/O failure</li><li>Event tracking</li><li>Associated alarm</li><li>Timing telemetry</li></ul><p>If you are interested in Chaos Mesh and would like to improve it, join its <a href="https://slack.cncf.io/">Slack channel</a> (#project-chaos-mesh) or submit your pull requests or issues to its <a href="https://github.com/chaos-mesh/chaos-mesh">GitHub repository</a>.</p>]]></content>
        <author>
            <name>Mayo Cream</name>
            <uri>https://github.com/mayocream</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hacktoberfest 2021: hack with Chaos Mesh!]]></title>
        <id>/chaos-mesh-hacktoberfest-2021</id>
        <link href="https://chaos-mesh.org/blog/chaos-mesh-hacktoberfest-2021"/>
        <updated>2021-09-28T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos Mesh x Hacktoberfest 2021]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-hacktoberfest-2021.png" alt="Chaos Mesh x Hacktoberfest 2021"/></p><p>Happy <a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a> 2021! We are excited to announce that <a href="https://github.com/chaos-mesh">Chaos Mesh</a> will be participating in the 8th annual Hacktoberfest hosted by DigitalOcean. During the month of October, anyone is welcome to join in on this global celebration of open-source by contributing changes, and earn one of 55,000 custom-made Hacktoberfest T-shirts!</p><h2>What is Chaos Mesh?</h2><p>Chaos Mesh is a cloud-native Chaos Engineering platform that orchestrates chaos in Kubernetes environments. With Chaos Mesh, you can test your system&#x27;s resilience and robustness on Kubernetes by injecting all types of faults into Pods, network, file system, and even the kernel. Chaos Mesh is currently a CNCF Sandbox project.</p><p>More importantly, Chaos Mesh fully embraces open source: ever since open sourced 1.5 years ago, the project has gained more than 4k stars with over 1.2k commits from 140+ contributors all over the world. It is through the open-source world that we are able to collaborate with an amazing community. Simply put, Chaos Mesh grew alongside its community and would not be where it is today without the dedication and commitment to open source, which is why we are more than proud to be back again in Hacktoberfest!</p><h2>Why Hacktoberfest?</h2><p>If you are interested in chaos engineering, open-source, trying to come up with a project for school, or looking into a potential career path as an SRE/DevOps engineer, then this is your golden opportunity: throughout Hacktoberfest, anyone, regardless of background and experience, can join and contribute changes - big or small. So grab the chance and learn about how to make a system more resilient! The Chaos Mesh community welcomes you with open arms and is more than willing to work and share feedback with you. Your contributions can make a big difference!</p><h2>Quick start</h2><p>Here‚Äôs a quick run-through of how to be part of Hacktoberfest 2021, and you can check out a detailed how to be part of Hacktoberfest on the <a href="https://hacktoberfest.digitalocean.com/resources/participation">official website</a>:</p><ol><li>Sign up for <a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a> anytime between Oct 1 and Oct 31.</li><li>Join the #project-chaos-mesh channel under <a href="https://slack.cncf.io/">CNCF Slack</a>, just in case you have any questions, or need help.</li><li>Start creating and submitting your PRs! Here are some top tips:<ol><li>Check out the <a href="https://github.com/chaos-mesh/chaos-mesh/blob/master/CONTRIBUTING.md">Chaos Mesh Contribution guide</a> before making contributions.</li><li>Have a go at any <a href="https://github.com/chaos-mesh/chaos-mesh/issues">issue</a> labeled with &quot;Hacktoberfest&quot;, note that these are the ones that we think might be good for those new to open source or Chaos Mesh, so it only serves as a starting point!</li></ol></li></ol><h2>Some notes</h2><ul><li>To get a shirt, you must make 4 approved PRs on opted-in projects between October 1-31 in any time zone. If a repository has no ‚ÄúHacktoberfest‚Äù topic set, please reach out to us or mention Hacktoberfest in your PR so we can set repository topics.</li><li>No spams please (e.g. creating a PR just for the sake of it and not adding any value in any way)! Our maintainer will mark a PR as invalid if it‚Äôs determined to be spam, which does NOT count towards your PR total.</li><li>Note that if our maintainer reports behavior that‚Äôs not in line with the <a href="https://github.com/chaos-mesh/chaos-mesh/blob/master/CODE_OF_CONDUCT.md">code of conduct</a>, you will be ineligible to participate.</li></ul><p>Lastly, good luck, on your marks, get set, and hack away!</p>]]></content>
        <author>
            <name>Chaos Mesh Community</name>
            <uri>https://github.com/chaos-mesh</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to run chaos experiments on your physical machine]]></title>
        <id>/run-chaos-experiments-on-physical-machines</id>
        <link href="https://chaos-mesh.org/blog/run-chaos-experiments-on-physical-machines"/>
        <updated>2021-09-15T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[How to run chaos experiments on your physical machine]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaosd-banner.png" alt="How to run chaos experiments on your physical machine"/></p><p><a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a> is a cloud-native Chaos Engineering platform that orchestrates chaos in Kubernetes environments. With Chaos Mesh, you can simulate a variety of failures, and use Chaos Dashboard, a web UI, to manage chaos experiments directly. Since it was open-sourced, Chaos Mesh has been adopted by many companies to ensure their systems‚Äô resilience and robustness. But over the past year, we have frequently heard requests from the community asking how to run chaos experiments when the services are not deployed on Kubernetes.</p><h2>What is chaosd</h2><p>To meet the growing needs of chaos testing on physical machines, we are excited to present an enhanced toolkit called chaosd. You might find the name familiar. That‚Äôs because it evolved from <code>chaos-daemon</code>, a key component in Chaos Mesh. At TiDB Hackathon 2020, we <a href="https://en.pingcap.com/blog/chaos-mesh-remake-one-step-closer-toward-chaos-as-a-service#refactor-chaosd">refactored chaosd to make it more than a command-line tool</a>. Now with <a href="https://github.com/chaos-mesh/chaosd/releases/tag/v1.0.1">chaosd v1.0.1</a>, you can simulate specific errors that target physical machines, and then, undo the chaos experiments like nothing had happened.</p><h2>Benefits of chaosd</h2><p>chaosd has the following advantages:</p><ul><li><strong>Easy-to-use</strong>: You can easily create and manage chaos experiments with chaosd commands.</li><li><strong>Various fault types</strong>: You can simulate faults to be injected on physical machines at different levels, including process faults, network faults, Java Virtual Machine (JVM) application faults, stress scenarios, disk faults, and host faults.</li><li><strong>Multiple work modes</strong>: You can use chaosd as a command-line tool or as a service.</li></ul><p>Without further ado, let‚Äôs give it a try.</p><h2>How to use chaosd</h2><p>In this section, I will walk you through how to inject a network fault with chaosd. Your Linux kernel version must be v2.17 or later.</p><h3>1. Download and unzip chaosd</h3><p>To download chaosd, run the following command:</p><pre><code class="language-bash">curl -fsSL -o chaosd-v1.0.1-linux-amd64.tar.gz https://mirrors.chaos-mesh.org/chaosd-v1.0.1-linux-amd64.tar.gz
</code></pre><p>Unzip the file. It contains two file folders:</p><ul><li><code>chaosd</code> contains the tool entry of chaosd.</li><li><code>tools</code> contains the tools needed to perform the chaos experiment, including <a href="https://wiki.ubuntu.com/Kernel/Reference/stress-ng">stress-ng</a> (to simulate stress scenarios), <a href="https://github.com/chaos-mesh/byteman">Byteman</a> (to simulate JVM application faults), and PortOccupyTool (to simulate network faults).</li></ul><h3>2. Create a chaos experiment</h3><p>In this chaos experiment, the server will be unable to access chaos-mesh.org.</p><p>Run the following command:</p><pre><code class="language-bash">sudo ./chaosd attack network loss --percent 100 --hostname chaos-mesh.org --device ens33
</code></pre><p>Example output:</p><pre><code class="language-bash">Attack network successfully, uid: c55a84c5-c181-426b-ae31-99c8d4615dbe
</code></pre><p>In this simulation, the ens33 network interface card cannot send network packets to or receive packets from <a href="http://chaos-mesh.org">chaos-mesh.org</a>. The reason why you have to use <code>sudo</code> commands is that the chaos experiment modifies network rules, which require root privileges.</p><p>Also, don‚Äôt forget to save the <code>uid</code> of the chaos experiment. You‚Äôll be entering that later as part of the recovery process.</p><h3>3. Verify the results</h3><p>Use the <code>ping</code> command to see if the server can access chaos-mesh.org:</p><pre><code class="language-bash">ping chaos-mesh.org
PING chaos-mesh.org (185.199.109.153) 56(84) bytes of data.
</code></pre><p>When you execute the command, it‚Äôs very likely that the site won‚Äôt respond. Press <code>CTRL</code>+<code>C</code> to stop the ping process. You should be able to see the statistics of the <code>ping</code> command: <code>100% packet loss</code>.</p><p>Example output:</p><pre><code class="language-bash">2 packets transmitted, 0 received, 100% packet loss, time 1021ms
</code></pre><h3>4. Recover the experiment</h3><p>To recover the experiment, run the following command:</p><pre><code class="language-bash">sudo ./chaosd recover c55a84c5-c181-426b-ae31-99c8d4615dbe
</code></pre><p>Example output:</p><pre><code class="language-bash">Recover c55a84c5-c181-426b-ae31-99c8d4615dbe successfully
</code></pre><p>In this step, you also need to use <code>sudo</code> commands because root privileges are required. When you finish recovering the experiment, try to ping chaos-mesh.org again to verify the connection.</p><h2>Next steps</h2><h3>Support dashboard web</h3><p>As you can see, chaosd is fairly easy to use. But we can make it easier‚Äîa dashboard web for chaosd is currently under extensive development.</p><p>We will continue to enhance its usability and implement more functionalities such as managing chaos experiments run with chaosd as well as those run with Chaos Mesh. This will provide a consistent and unified user experience for chaos testing on Kubernetes and physical machines. The architecture below is just a simple example:</p><p><img src="/img/chaos-mesh-optimized-architecture.png" alt="Chaos Mesh&#x27;s optimized architecture"/></p><p class="caption-center">Chaos Mesh&#x27;s optimized architecture</p><p>For more, check out <a href="https://en.pingcap.com/blog/chaos-mesh-remake-one-step-closer-toward-chaos-as-a-service#developing-chaos-mesh-towards-caas">Chaos Mesh&#x27;s optimized architecture</a>.</p><h3>Add more fault injection types</h3><p>Currently, chaosd provides six fault injection types. We plan to develop more types that have been supported by Chaos Mesh, including HTTPChaos and IOChaos.</p><p>If you are interested in helping us improve chaosd, you are welcome to <a href="https://github.com/chaos-mesh/chaosd/labels/help%20wanted">pick an issue</a> and get started!</p><h2>Try it out!</h2><p>If you are interested in using chaosd and want to explore more, check out the <a href="https://chaos-mesh.org/docs/chaosd-overview">documentation</a>. If you come across an issue when you run chaosd, or if you have a feature request, feel free to <a href="https://github.com/chaos-mesh/chaosd/issues">create an issue</a>. We would love to hear your voice!</p>]]></content>
        <author>
            <name>Xiang Wang</name>
            <uri>https://github.com/WangXiangUSTC</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Securing Online Gaming: Combine Chaos Engineering with DevOps Practices]]></title>
        <id>/Securing-Online-Gaming-Combine-Chaos-Engineering-with-DevOps-Practices</id>
        <link href="https://chaos-mesh.org/blog/Securing-Online-Gaming-Combine-Chaos-Engineering-with-DevOps-Practices"/>
        <updated>2021-08-26T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Securing Online Gaming: Combine Chaos Engineering with DevOps Practices]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-tencent-ieg.jpeg" alt="Securing Online Gaming: Combine Chaos Engineering with DevOps Practices"/></p><p>Interactive Entertainment Group (IEG) is a division of Tencent Holdings that focuses on the development of online video games and other digital content such as live broadcasts. It is well-known for being the publisher of some of the most popular video games.</p><p>In this article, I will explain why and how we introduce chaos engineering into our DevOps process.</p><p>For each day, we handle over 10,000,000 total visits, and, during peak hours, we process over 1,000,000 queries per second (QPS). To guarantee players a fun and engaging experience, we launch various daily or seasonal game events. Sometimes, that means we must update the event code over 500 times per day. As our user base grows, the total amount of data quickly multiplies. Currently, the figure stands at 200 terabytes. We have to manage the massive user queries and rapid release iterations, and we managed it well.</p><p>A cloud-native DevOps solution frees our events operator from the growing number of online events. We developed a pipeline that takes care of everything they need, from writing code to launching events in production environments: once new event codes are detected, the operation platform automatically builds images from them and deploys the image to Tencent Kubernetes Engine (TKE). You might be wondering how long this entire automated process takes: only 5 minutes.</p><p>Currently, almost all IEG operation services run in TKE. Elastic scaling promises faster capacity expansion and reduction of cloud services thanks to cloud-native technology.</p><p>In addition, we expect the iterations to be easier. A best practice is to break down the large, hard-to-maintain service into many ‚Äúsmaller‚Äù services that we can maintain independently. ‚ÄúSmall‚Äù services have less code and simpler logic, with lower handover and training costs. We as developers continue to practice this kind of microservices architecture as part of DevOps initiatives. Yet similar issues persist. As the number of services increases, so does the complexity of making calls between them. <strong>Worse, if one ‚Äúsmall‚Äù service fails, it could set off a chain reaction that brings all the services down‚Äîa microservice dependency hell.</strong></p><p>The thing is, fault tolerance varies by service. Some support downgrading, while others don‚Äôt. Not to mention that some services are unable to provide timely alerts or lack an effective debugging tool. As a result, debugging services has become a tricky and increasingly pressing issue in our day-to-day work.</p><p>But we can‚Äôt just let it be. What if the unstable performance constantly chases our players away? What if there is a catastrophic failure?</p><h2>Let there be faults</h2><p>Netflix introduced the idea of chaos engineering. This approach tests the resilience of the system against all kinds of edgy cases by injecting faults in a non-production environment to achieve ideal system reliability. According to one Gartner article, by 2023, 40% of organizations will use chaos engineering to meet their top DevOps objectives, reducing unplanned downtime by 20%.</p><p>This is exactly how we avoid the worst-case scenario. Fault injection, in my opinion, is now a must-do in every technical team. In our early test cases, developers would bring down a node before launching a service to see if the primary node automatically switched to the secondary node and if disaster recovery worked.</p><p><strong>But chaos engineering is more than fault injection.</strong> It is a field that constantly drives new techniques, professional testing tools, and solid theories. That‚Äôs why we continue to explore it.</p><p>IEG officially launched its chaos engineering project over a year ago. We wanted to do this right the first time. The key is to select a chaos engineering tool that supports running experiments in the Kubernetes environment. <strong>After a careful comparison, we believe <a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a> is our best option</strong> because:</p><ul><li>It is a Cloud Native Computing Foundation (CNCF) Sandbox project with a friendly and productive community.</li><li>It does not intrude on existing applications.</li><li>It provides a web UI and a variety of fault injection types, as shown in the image below.</li></ul><p><img src="/img/comparison-of-chaos-engineering-tools.png" alt="A comparison of chaos engineering tools"/></p><p class="caption-center"> A comparison of chaos engineering tools </p><blockquote><p>Note: This comparison is outdated and is intended simply to compare fault injection features supported by Chaos Mesh with other well-known chaos engineering platforms. It is not intended to favor or position one project over another. Any corrections are welcome.</p></blockquote><h2>Build a chaos testing platform</h2><p>Our chaos engineering team embedded Chaos Mesh into our continuous integration and continuous delivery pipelines. As shown in the diagram below, Chaos Mesh now plays an important role in our operation platform. We use Chaos Mesh&#x27;s dashboard API to create, run, and delete chaos experiments and monitor them on our own platform. We can simulate basic system-level faults in Pods, container, network, and IO.</p><p><img src="/img/chaos-mesh-embedded-in-IEG&#x27;s-operation-platform.png" alt="Chaos Mesh embedded in IEG&#x27;s operation platform"/></p><p class="caption-center">Chaos Mesh embedded in IEG&#x27;s operation platform</p><p>In IEG, <strong>chaos engineering is generally summarized as a closed loop with several key phases</strong>:</p><ul><li><p>Improve overall system resilience.</p><p>Build a chaos testing platform that we can modify as our needs change.</p></li><li><p>Design a testing plan.</p><p>The testing plan must specify the target, scope, fault to be injected, monitoring metrics, etc. Make sure the testing is well-controlled.</p></li><li><p>Execute chaos experiments and review the results.</p><p>Compare the system‚Äôs performance before and after the chaos experiment.</p></li><li><p>Resolve any issues that may arise.</p><p>Fix found issues and upgrade the system for the follow-up experiment.</p></li><li><p>Repeat chaos experiments and verify performance.</p><p>Repeat chaos experiments to see if the system‚Äôs performance meets expectations. If it does, design another testing plan.</p></li></ul><p><img src="/img/five-phases-of-chaos-engineering-in-IEG.png" alt="Five phases of chaos engineering in IEG"/></p><p class="caption-center">Five phases of chaos engineering in IEG</p><p>We frequently <strong>test the performance of services under high CPU usage</strong>, for example. We begin by orchestrating and scheduling experiments. Following that, we run experiments and monitor the performance of related services. Multiple monitoring metrics, such as QPS, latency, response success, are immediately visible through the operation platform. The platform then generates reports for us to review, so we can check whether these experiments met our expectations.</p><h2>Use cases</h2><p>The following are a few examples of how we use chaos engineering in our DevOps workflow.</p><h3>Finer granularity of fault injection</h3><p>There is no need to shut down the entire system to see if our games are still available to players. Sometimes we only want to inject faults, say, network latency, into a single game account, and observe how it responds. We are now able to achieve this finer granularity by hijacking traffic and running experiments at the gateway.</p><h3>Red teaming</h3><p>Understandably, our team members grew bored of regular chaos experiments. After all, it‚Äôs something like telling your left hand to fight against your right hand. Here at IEG, <strong>we integrate a testing practice called red teaming into chaos engineering to ensure that our system resiliency improves in an organic way.</strong> Red teaming is similar to penetration testing, but more targeted. It requires a group of testers to emulate real-world attacks from an outsider‚Äôs perspective. If I were in charge of IT operations, I would simulate faults to specific services, and check to see whether my developer colleges were doing a good job. If I found any potential faults, well, be prepared for some ‚Äúhard talk.‚Äù On the other hand, developers would actively perform chaos experiments and make sure no risk was left behind to avoid being blamed.</p><p><img src="/img/red-teaming-process-in-IEG.png" alt="The red teaming process in IEG"/></p><p class="caption-center">The red teaming process in IEG</p><h3>Dependency analysis</h3><p>It‚Äôs important to manage dependencies for microservices. In our case, non-core services cannot be the bottleneck for core services. Fortunately, with chaos engineering, we can run dependency analysis simply by injecting faults into called services and observing how badly the main service is affected. Based on the results, we can optimize the service calling chain in a specific scenario.</p><h3>Automated fault detection and diagnosis</h3><p>We are also exploring AI bots to help us detect and diagnose faults. As services become more complex, the likelihood of failure increases. <strong>Our goal is to train a fault detection model through large-scale chaos experiments in production or other controlled environments.</strong></p><h2>Chaos engineering empowers DevOps practices</h2><p>Currently, on average, more than 50 people run chaos experiments each week, running more than 150 tests, and detecting more than 100 problems in total.</p><p>Gone are the days when performing fault injection requires a handwritten script, which can be a tough thing to do for those who are unfamiliar with it. <strong>The benefits of combining chaos engineering with DevOps practices are obvious: within a few minutes, you can orchestrate various fault types by simply dragging and dropping, execute them with a single click, and monitor the results in real-time‚Äîall in one platform.</strong></p><p><img src="/img/chaos-engineering-with-devops.png" alt="Chaos engineering with DevOps ensures efficient fault injection"/></p><p class="caption-center">Chaos engineering with DevOps ensures efficient fault injection</p><p>Thanks to full-featured chaos engineering tools and streamlined DevOps processes, we estimate that the efficiency of fault injection and chaos-based optimization at IEG has been improved at least by 10 times in the last six months. If you were unsure about implementing chaos engineering in your business, I hope our experience can be of some help.</p>]]></content>
        <author>
            <name>Zhaojun Wu</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How Chaos Mesh Helps Apache APISIX Improve System Stability]]></title>
        <id>/How-Chaos-Mesh-Helps-Apache-APISIX-Improve-System-Stability</id>
        <link href="https://chaos-mesh.org/blog/How-Chaos-Mesh-Helps-Apache-APISIX-Improve-System-Stability"/>
        <updated>2021-08-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos Mesh helps Apache APISIX improve system stability]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-apisix.jpeg" alt="Chaos Mesh helps Apache APISIX improve system stability"/></p><p><a href="https://github.com/apache/apisix">Apache APISIX</a> is a cloud-native, high-performance, scaling microservices API gateway. It is one of the Apache Software Foundation&#x27;s top-level projects and serves hundreds of companies around the world, processing their mission-critical traffic, including finance, the Internet, manufacturing, retail, and operators. Our customers include NASA, the European Union&#x27;s digital factory, China Mobile, and Tencent.</p><p>As our community grows, Apache APISIX&#x27;s features more frequently interact with external components, making our system more complex and increasing the possibility of errors. To identify potential system failures and build confidence in the production environment, we introduced the concept of Chaos Engineering.</p><p><img src="/img/apache-apisix-architecture.jpg" alt="Apache APISIX architecture"/></p><p class="caption-center"> Apache APISIX architecture </p><p>In this post, we&#x27;ll share how we use <a href="https://chaos-mesh.org/">Chaos Mesh</a> to improve our system stability.</p><h2>Our pain points</h2><p>Apache APISIX processes tens of billions of requests a day. At that volume level, our users have noticed a couple of issues:</p><ul><li><strong>Scenario #1:</strong> In Apache APISIX&#x27;s configuration center, when unexpectedly high network latency occurs between etcd and Apache APISIX, can Apache APISIX still filter and forward traffic normally?</li><li><strong>Scenario #2:</strong> When a node in the etcd cluster fails and the cluster can still run normally, an error is reported for the node&#x27;s interaction with the Apache APISIX admin API.</li></ul><p>Although Apache APISIX has covered many scenarios through unit, end-to-end (E2E), and fuzz tests in continuous integration (CI), it has not covered the interaction scenario with external components. If the system behaves abnormally, for example, if the network jitters, a hard disk fails, or a process is killed, can Apache APISIX give appropriate error messages? Can it keep running or restore itself to normal operation?</p><h2>Why we chose Chaos Mesh</h2><p>To test these user scenarios and to discover similar problems before our product goes into production, our community decided to use Chaos Mesh for chaos testing.</p><p>Chaos Mesh is a cloud-native Chaos Engineering platform that features all-around fault injection methods for complex systems on Kubernetes, covering faults in Pod, the network, file system, and even the kernel. It helps users find weaknesses in the system and ensures that the system can resist out-of-control situations in the production environment.</p><p>Like Apache APISIX, Chaos Mesh has an active open source community. We know that an active community can ensure stable software use and rapid iteration. This makes Chaos Mesh more attractive.</p><h2>How we use Chaos Mesh in APISIX</h2><p>Chaos Engineering has grown beyond simple fault injection and now forms a complete methodology. To create a chaos experiment, we determined what the normal operation or &quot;steady state&quot; of our application should be. We then introduced potential problems to see how the system responded. If the problems knocked the application out of its steady state, we fixed them.</p><p>Now, we&#x27;ll take the two scenarios we mentioned to show you how we use Chaos Mesh in Apache APISIX.</p><h3>Scenario #1</h3><p>We deployed a Chaos Engineering experiment using the following steps:</p><ol><li><p>We found metrics to measure whether Apache APISIX is running normally. In the test, the most important method is to use Grafana to monitor the Apache APISIX&#x27;s running metrics. We extracted data from Prometheus in CI for comparison. Here, we used the routing and forwarding requests per second (RPS) and etcd connectivity as evaluation metrics. We analyzed the log. For Apache APISIX, we checked Nginx&#x27;s error log to determine whether there was an error and whether the error was in line with our expectations.</p></li><li><p>We performed a test in the control group. We found that both <code>create route</code> and <code>access route</code> were successful, and we could connect to etcd. We recorded the RPS.</p></li><li><p>We used network chaos to add a five second network latency and then retested. This time, <code>set route</code> failed, <code>get route</code> succeeded, etcd could be connected to, and RPS had no significant change compared to the previous experiment. The experiment met our expectations.</p></li></ol><p><img src="/img/high-network-latency-between-etcd-and-apache-apisix.jpg" alt="High network latency occurs between etcd and Apache APISIX"/></p><p class="caption-center"> High network latency occurs between etcd and Apache APISIX </p><h3>Scenario #2</h3><p>After we conducted the same experiment as above in the control group, we introduced pod-kill chaos and reproduced the expected error. When we randomly deleted a small number of etcd nodes in the cluster, sometimes APISIX could connect to etcd and sometimes not, and the log printed a large number of connection rejection errors.</p><p>When we deleted the first or third node in the etcd endpoint list, the <code>set route</code> returned a result normally. However, when we deleted the second node in the list, the <code>set route</code> returned the error &quot;connection refused.&quot;</p><p>Our troubleshooting revealed that the etcd Lua API used by Apache APISIX selected the endpoint sequentially, not randomly. Therefore, when we created an etcd client, we bound to only one etcd endpoint. This led to continuous failure.</p><p>After we fixed this problem, we added a health check to the etcd Lua API to ensure that a large number of requests would not be sent to the disconnected etcd node. To avoid flooding the log with errors, we added a fallback mechanism when the etcd cluster was completely disconnected.</p><p><img src="/img/error-reported-from-etcd-node-interaction.jpg" alt="Error Reported from etcd Node Interaction"/></p><p class="caption-center"> An error is reported from one etcd node&#x27;s interaction with the Apache APISIX admin API </p><h2>Our future plans</h2><h3>Run a chaos test in E2E simulation scenarios</h3><p>In Apache APISIX, we manually identify system weaknesses for testing and repair. As in the open source community, we test in CI, so we don&#x27;t need to worry about the impact of Chaos Engineering&#x27;s failure radius on the production environment. But the test cannot cover complicated and comprehensive application scenarios in the production environment.</p><p>To cover more scenarios, the community plans to use the existing E2E test to simulate more complete scenarios and conduct chaos tests that are more random and cover a larger range.</p><h3>Add chaos tests to more Apache APISIX projects</h3><p>In addition to finding more vulnerabilities for Apache APISIX, the community plans to add chaos tests to more projects such as Apache APISIX Dashboard and Apache APISIX Ingress Controller.</p><h3>Add features to Chaos Mesh</h3><p>When we deployed Chaos Mesh, some features were temporarily unsupported. For example, we couldn&#x27;t select a service as a network latency target or specify container port injection as network chaos. In the future, the Apache APISIX community will assist Chaos Mesh to add related features.</p><p>You&#x27;re welcome to contribute to the <a href="https://github.com/apache/apisix">Apache APISIX project</a> on GitHub. If you are interested in Chaos Mesh and would like to improve it, join our <a href="https://slack.cncf.io/">Slack channel</a> (#project-chaos-mesh) or submit your pull requests or issues to our <a href="https://github.com/chaos-mesh/chaos-mesh">GitHub repository</a>.</p>]]></content>
        <author>
            <name>Shuyang Wu</name>
            <uri>https://github.com/Yiyiyimu</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chaos Mesh 2.0: To a Chaos Engineering Ecology]]></title>
        <id>/chaos-mesh-2.0-to-a-chaos-engineering-ecology</id>
        <link href="https://chaos-mesh.org/blog/chaos-mesh-2.0-to-a-chaos-engineering-ecology"/>
        <updated>2021-08-13T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos Mesh 2.0: To a Chaos Engineering Ecology]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-2.0-ga.png" alt="Chaos Mesh 2.0: To a Chaos Engineering Ecology"/></p><p>On July 23, 2021, Chaos Mesh 2.0 was made generally available! It‚Äôs an exciting release, marking a solid milestone towards the chaos engineering ecology that we hope to build.</p><p>Making chaos engineering easier has always been Chaos Mesh‚Äôs unswerving goal, and this release is a key step. After almost a year of continuous efforts, we have made major improvements in three main areas: ease of use, native experiment orchestration &amp; scheduling, along with the richness of fault injection types.</p><h2>Ease of use</h2><p>We are committed to improving the usability of Chaos Mesh, and a key path to this is Chaos Dashboard, a web interface for users to orchestrate chaos experiments. For Chaos Mesh 2.0, we have improved the Chaos Dashboard in the following ways, further simplifying the complexity of chaos experiments:</p><ul><li>It now supports the creation, viewing, and updating of AWSChaos and GCPChaos, so that conducting chaos experiments in a cloud environment can provide a consistent experience as in Kubernetes; </li><li>It can display more detailed records of each experiment, further enhancing its visibility.</li></ul><p><img src="/img/chaos-mesh-scheduling-2.0.png" alt="Chaos Mesh 2.0 - Experiment scheduling"/></p><h2>Native experiment orchestration &amp; scheduling</h2><p>When conducting chaos experiments, a single experiment is often not enough to simulate a complete testing scenario, and manually starting or stopping the experiment would be a tedious and dangerous thing to do. Previously, we <a href="https://chaos-mesh.org/blog/building_automated_testing_framework">combined Argo with Chaos Mesh</a> to inject faults automatically as a workflow. However, we later realized that Argo workflow is not the best way to describe declarative chaos experiments, and decided to write another workflow engine. Chaos Mesh 2.0 features native Workflow to support experiment orchestration, which means you can serially or parallely execute multiple experiments. You can even weave in notifications and health checks to simulate more complex experimental scenarios.</p><p><img src="/img/chaos-mesh-workflow-2.0.png" alt="Chaos Mesh 2.0 - Workflow"/></p><p>In previous versions, we used the <code>cron</code> and <code>duration</code> fields to define chaos experiments that were executed periodically.  It didn‚Äôt take us long to realize that describing behavior this way was not fitting. For example, a single execution often takes longer than an execution cycle. This definition works fine, but lacks a suitable description for the study of expected behavior. We referred to CronJob and introduced Schedule, a new custom object, to Chaos Mesh. It adds more explicit properties to periodically executed tasks, such as whether multiple experiments are allowed to be executed at the same time, thereby restricting behavior.</p><p><img src="/img/chaos-dashboard-schedule-2.0.png" alt="Chaos Mesh 2.0 - Schedule"/></p><h2>Richer fault injection types</h2><p>Chaos Mesh already supports system-level fault injection types, as well as fault injections into cloud environments such as AWSChaos and GCPChaos. Starting from 2.0, injecting chaos into the application layer has been made possible with the introduction of JVMChaos and HTTPChaos.</p><h3>JVMChaos</h3><p>JVM languages such as Java and Kotlin are widely used in the industry. A JVMChaos can be easily simulated through methods like JVM bytecode enhancement and Java Agent. Currently, JVMChaos uses <a href="https://github.com/chaosblade-io/chaosblade-exec-jvm">chaosblade-exec-jvm</a>, and supports injecting various application-level fault types including method delay, specify return value, OOM and throw custom exception. For more info, you can refer to the document: <a href="https://chaos-mesh.org/docs/simulate-jvm-application-chaos">Simulate JVM Application Faults</a>.</p><h3>HTTPChaos</h3><p>HTTPChaos is a brand new Chaos type supported in the 2.0 version. It can hijack HTTP service requests and responses from the server side, as well as interrupt links, delay injection, or modify Header/Body. It is suitable for all scenarios that use HTTP as the communication protocol. For more information, refer to <a href="https://chaos-mesh.org/docs/simulate-http-chaos-on-kubernetes">Simulate HTTP Faults</a>.</p><h2>Chaosd: an fault injection tool for physical nodes</h2><p>Chaos Mesh is designed for Kubernetes. For physical machine environments, we present <a href="https://github.com/chaos-mesh/chaosd">Chaosd</a>. It evolved from chaos-daemon, a key component in Chaos Mesh, and we have added specific chaos experiments based on the characteristics of physical machines. Currently, Chaosd supports process kill, network, JVM, pressure, disk and a few other types of fault injection onto the physical machine.</p><h2>Looking ahead</h2><p>Chaos Mesh is still under active development, and we have some more powerful features in the works, including:</p><ul><li>To inject JVMChaos at runtime, lowering the cost of JVMChaos and making it more easy-to-use.</li><li>To introduce a plug-in mechanism to build custom chaos experiments, while the Scheduling function remains unimpaired.</li></ul><p>In addition, we noticed that chaos experiments can be reused in a number of scenarios, hence we plan to launch a platform, where customized experiments can be turned into templates. This will enable our users to share and reuse not only specific chaos experiments, but also Workflows for different scenarios.</p><h2>Try it out!</h2><p>Try out the <a href="https://chaos-mesh.org/interactive-tutorial">Chaos Mesh 2.0 interactive scenarios</a> from your browser! There‚Äôs no need to install or configure, as the complete development environment has been preconfigured with everything you need. Otherwise, you can visit <a href="https://chaos-mesh.org/docs">the Chaos Mesh docs</a> for more info.</p><h2>A big thank you</h2><p>Thanks to all <a href="https://github.com/chaos-mesh/chaos-mesh/graphs/contributors">Chaos Mesh contributors</a>, Chaos Mesh couldn‚Äôt have come from 1.0 to 2.0 without all of your efforts!</p><p>If you are interested in Chaos Mesh and would like to help us improve it, you‚Äôre welcome to join <a href="https://slack.cncf.io/">our Slack channel</a> or submit your pull requests or issues to our <a href="https://github.com/chaos-mesh/chaos-mesh">GitHub repository</a>. Chaos Mesh looks forward to your participation and feedback!</p>]]></content>
        <author>
            <name>Chaos Mesh Maintainers</name>
            <uri>https://github.com/chaos-mesh</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chaos Mesh Celebrates 100th Contributor]]></title>
        <id>/chaos-mesh-celebrates-100th-contributor</id>
        <link href="https://chaos-mesh.org/blog/chaos-mesh-celebrates-100th-contributor"/>
        <updated>2021-08-05T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos Mesh Celebrates 100th Contributor]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-celebrates-100-contributors.png" alt="Chaos Mesh Celebrates 100th Contributor"/></p><p>The <a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh project</a> just hit two major milestones: the community recently welcomed our <a href="https://github.com/chaos-mesh/chaos-mesh/graphs/contributors">100th contributor</a> to the chaos-mesh repo and 1,000 followers on <a href="https://twitter.com/chaos_mesh">Twitter</a>!</p><p>Chaos Mesh is a Chaos Engineering platform that orchestrates chaos experiments on Kubernetes environments. Ever since first open-sourced on GitHub on Dec 31st, 2019, it has not stopped: in July 2020, Chaos Mesh joined CNCF <a href="https://chaos-mesh.org/blog/chaos-mesh-join-cncf-sandbox-project">as a Sandbox project</a>; a few months later in September, Chaos Mesh 1.0 was <a href="https://chaos-mesh.org/blog/chaos-mesh-1.0-chaos-engineering-on-kubernetes-made-easier">officially released</a>. In July 2021, after a few beta versions, <a href="https://github.com/chaos-mesh/chaos-mesh/releases/tag/v2.0.0">Chaos Mesh 2.0 was announced generally available</a>!</p><p>So far, Chaos Mesh has brought out 35 releases, received 1,500+ commits from 100+ contributors, won over 3.8k+ stargazers and 420+ forks. All these achievements would not have been possible without the wonderful community.</p><p><img src="/img/chaos-mesh-all-contributors.jpeg" alt="Chaos Mesh contributors"/></p><p class="caption-center">Chaos Mesh contributors (as of 2021.08.02)</p><p>Here are a few of our favourite contributions to highlight:</p><ul><li><a href="https://github.com/YangKeao">@YangKeao</a> introduced <code>kubebuilder</code> to Chaos Mesh, an SDK for building Kubernetes APIs using CRD, which simplified the steps to implement the Controller.</li><li><a href="https://github.com/g1eny0ung">@g1eny0ung</a> brought in the Chaos Dashboard, a Web UI for manipulating and observing chaos experiments.</li><li><a href="https://github.com/Yiyiyimu">@Yiyiyimu</a> contributed <code>chaosctl</code>, a tool that simplifies chaos development and debugging.</li><li><a href="https://github.com/Gallardot">@Gallardot</a> helped implement JVMChaos, making it possible for Chaos Mesh to simulate JVM application faults.</li><li><a href="https://github.com/STRRL">@STRRL</a> started the work on Chaos Mesh Workflow, a built-in workflow engine which enables running different chaos experiments in a serial or parallel manner to simulate production-level errors.</li></ul><p>For those who enjoy chaos engineering and open source equally, our mission is to make sure that this is where you belong by enriching the contribution journey, and here‚Äôs where we are at so far:</p><ul><li>We published the Chaos Mesh <a href="https://github.com/chaos-mesh/chaos-mesh/blob/master/GOVERNANCE.md">Governance</a> in the beginning of 2021, making clear the roles and responsibilities of each community member as well as the decision-making process, and has since promoted 9 Committers.</li><li>We have mentored 4 mentees through the LFX mentorship programs so far. Our mentees have written blogs and hosted talks sharing their LFX experience.</li><li>We have participated in 3 KubeCons, where we participated in the bug bash contest and hosted Office Hours to meet and chat with old faces and welcome new members to our community. We even posted a <a href="https://chaos-mesh.org/blog/chaos-mesh-q&amp;a">Q&amp;A</a> after the KubeCon EU 2021 since we received so many questions!</li><li>We are currently applying to propose Chaos Mesh to be promoted to the CNCF <a href="https://github.com/cncf/toc/pull/683">incubating stage</a>, hoping that being promoted to the next stage of maturity brings the project new chances and more exposure.</li></ul><p>Although this is an achievement worth celebrating, we know that there is still a lot of work ahead:</p><ul><li>We have also been working with the community to refine the Chaos Mesh <a href="https://chaos-mesh.org/docs/">documentation</a>: updating English versions as per each release and adding Chinese versions for our growing number of Chinese adopters and contributors.</li><li>We hope to continue to contribute to the Cloud-Native ecosystem: for example, by developing and amplifying chaos engineering related content, and collaborating with other communities for meetups and projects.</li></ul><p>Another goal of ours is to continue building a more diverse and engaging community‚Äî there is no barrier to being part of the Chaos Mesh community and becoming a Chaos Mesh contributor, as contributions are not limited to coding: writing documentation, offering ideas for features, posting issues, writing blogs, answering community questions, or sharing cases are all part of the contribution journey.</p><h2>To sum up</h2><p>From the bottom of our hearts, thank you! We hope that we can keep up the good work and continue to build up this not-so-little community of ours, and continue to contribute to the CNCF and the chaos engineering ecology.</p><p>If this is the first time you are hearing of Chaos Mesh, and would like to learn more, find the #project-chaos-mesh channel in <a href="https://slack.cncf.io/">CNCF slack workspace</a>, submit your pull requests or issues to our <a href="https://github.com/chaos-mesh/chaos-mesh">GitHub repository</a>, or sign up to join in on our next <a href="https://community.cncf.io/chaos-mesh-community/">monthly community meeting</a>!</p>]]></content>
        <author>
            <name>Chaos Mesh Maintainers</name>
            <uri>https://github.com/chaos-mesh/chaos-mesh/blob/master/MAINTAINERS.md</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chaos Mesh Q&A]]></title>
        <id>/chaos-mesh-q&amp;a</id>
        <link href="https://chaos-mesh.org/blog/chaos-mesh-q&amp;a"/>
        <updated>2021-07-09T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos Mesh Q&A]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-q&amp;a.jpeg" alt="Chaos Mesh Q&amp;A"/></p><p>At KubeCon EU 2021, the <a href="https://chaos-mesh.org/">Chaos Mesh</a> team hosted two ‚Äúoffice hours sessions‚Äù where newcomers, community members, and project maintainers had a chance to chat, get to know each other, and learn more about the project.</p><p>Big thanks to the more than 200 of you who joined us! We received so many great questions during the session, we thought we‚Äôd do a round up Q&amp;A.</p><h2>Your questions answered</h2><p><strong>Q: Is Chaos Mesh compatible with Service Meshes, such as Istio?</strong></p><p><strong>A:</strong> Yes, you can use Chaos Mesh in the Service Mesh environment. At one of our <a href="https://www.youtube.com/watch?v=paIgJYOhdGw">previous community meetings</a>, Sergio M√©ndez and Jossie Castrillo from the University of San Carlos of Guatemala shared how they used Linkerd and Chaos Mesh to conduct chaos experiments for their project, ‚Äú<a href="https://github.com/sergioarmgpl/operating-systems-usac-course/blob/master/lang/en/projects/project1v3/project1.md">COVID-19 Realtime Vaccinated People Visualizer</a>‚Äù.</p><p><img src="/img/chaos-mesh-linkerd-architecture.png" alt="Project Architecture"/></p><p class="caption-center">Project Architecture</p><p><strong>Q: Can I use Chaos Mesh on-premises or do I need Amazon Web Services (AWS) or Google Cloud Platform (GCP)?</strong></p><p><strong>A:</strong> You can do either! You can deploy Chaos Mesh on your Kubernetes cluster, so it does not matter whether you manage it yourself or have it hosted on AWS or GCP. However, if you would like to use it in a Kubernetes environment, you need to <a href="https://chaos-mesh.org/docs/1.2.4/user_guides/installation">set relevant parameters</a> during installation.</p><p><strong>Q: How do &quot;chaos actions&quot; work?</strong></p><p><strong>A:</strong> Chaos Mesh uses Kubernetes CustomResourceDefinitions (CRDs) to manage chaos experiments. Different fault injection behaviors are implemented in different ways, but the overall idea is the same: Chaos Mesh uses an application&#x27;s execution link to inject chaos into the application. For example, when we inject chaos into the overall link of network interaction, the network interaction card is passed through. Because Linux uses traffic control to increase interference to the specific network interaction card, we can directly use traffic control for network fault injection.</p><p><strong>Q: Are you going to add probe support to Chaos Mesh for steady state detection and experiment validation?</strong></p><p><strong>A:</strong> Currently, there is no plan to add this support. Steady state detection and experiment validation are necessary if an application is ready for production. Chaos Mesh itself does not monitor related work, but provides an interface to access existing monitoring systems or the status interface of the application to monitor and detect the application‚Äôs steady state.</p><p><strong>Q: What elevated privileges do the Chaos Mesh pods need?</strong></p><p><strong>A:</strong> By default, the Chaos Daemon components in Chaos Mesh run in the <code>privileged</code> mode. If your Kubernetes cluster version is v3.11 or higher, you can replace <code>privileged</code> mode by configuring <code>capabilities</code>.</p><p><strong>Q: Can I implement Chaos Mesh inside build pipelines to log specific test results?</strong></p><p><strong>A:</strong> Yes, that‚Äôs easy to do. You can integrate Chaos Mesh with pipeline systems such as Argo, Jenkins, GitHub Action, and Spanner. Chaos Mesh uses Kubernetes CRDs to manage chaos experiments. To inject chaos, you only need to create the chaos CRD object you want in the pipeline. You can obtain the running status of an experiment through its status structure and event.</p><p><strong>Q: What can we expect from the 2.0 release? Can you share some updates on HTTPChaos?</strong></p><p><strong>A:</strong> Chaos Mesh 2.0 will provide native workflow support, and users can arrange chaos experiments in Chaos Mesh. In addition, for Chaos Mesh 2.0, we have reconstructed the existing chaos controller so that users can more easily add new fault injection types. As for HTTPChaos, we‚Äôre adding network failure simulation to the HTTP application layer!</p><h2>Join the Chaos Mesh community</h2><p>If you are interested in Chaos Mesh and would like to help us improve it, you&#x27;re welcome to join <a href="https://slack.cncf.io/">our Slack channel</a> or submit your pull requests or issues to our <a href="https://github.com/chaos-mesh/chaos-mesh">GitHub repository</a>.</p>]]></content>
        <author>
            <name>Chaos Mesh Community</name>
            <uri>https://github.com/chaos-mesh</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Securing tenant namespaces using restrict authorization feature in Chaos Mesh]]></title>
        <id>/securing-tenant-namespaces-using-restrict-authorization-feature</id>
        <link href="https://chaos-mesh.org/blog/securing-tenant-namespaces-using-restrict-authorization-feature"/>
        <updated>2021-07-07T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos engineering tools]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-restrict-authorization.jpeg" alt="Chaos engineering tools"/></p><p>A <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/multitenancy-overview">multi-tenant</a> cluster is shared by multiple users and/or workloads which are referred to as &quot;tenants&quot;.The operators of multi-tenant clusters must isolate tenants from each other to minimize the damage that a compromised or malicious tenant can do to the cluster and other tenants.</p><h2>Cluster multi-tenancy</h2><p>When you plan a multi-tenant architecture, you should consider the layers of resource isolation in Kubernetes: cluster, namespace, node, Pod, and container.</p><p>Although Kubernetes cannot guarantee perfectly secure isolation between tenants, it does offer features that may be sufficient for specific use cases. You can separate each tenant and their Kubernetes resources into their own <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/">namespaces</a>.
Kubernetes supports multiple virtual clusters backed by the same physical cluster. These virtual clusters are called namespaces. <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/">Namespaces</a> are intended for use in environments with many users spread across multiple teams, or projects.</p><h2>Cluster having Chaos Mesh</h2><p>You designed your Kubernetes cluster to have multiple tenant services. You followed the best security practices for Kubernetes: each tenant service is running in its own namespaces, users of these tenant services have appropriate access that also only for their respective namespaces, etc.</p><p>You enabled Chaos Mesh (<a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a> is a cloud-native Chaos Engineering platform that orchestrates chaos on Kubernetes environments) on the cluster so that your tenant services can perform different chaos activities to make sure their application/system is resilient. You have also given Chaos Mesh specific rights to those tenant service users so that they can manage Chaos Mesh resources using <a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/">RBAC</a>.</p><p>Suppose one of the tenant users wants to perform pod kill operations in his/her namespace i.e. chaos-testing. To achieve the same, the user created the below Chaos Mesh YAML file:</p><pre><code class="language-yml">apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: pod-kill
  namespace: chaos-testing
spec:
  action: pod-kill
  mode: one
  selector:
    namespaces:
      - tidb-cluster-demo
    labelSelectors:
      &#x27;app.kubernetes.io/component&#x27;: &#x27;tikv&#x27;
  scheduler:
    cron: &#x27;@every 1m&#x27;
</code></pre><p>The user has required rights to namespace chaos-testing, but does not have rights on tidb-cluster-demo namespace. When the user applies the above YAML file using kubectl, it will create the pod-kill Chaos Mesh resource in chaos-testing namespace. As we can see in the selector section, the user has specified some other namespace (tidb-cluster-demo), which means the pods which will be selected for this chaos operation will be from tidb-cluster-demo namespace, and not from the one for which the user has access i.e. chaos-testing. This means that this user is able to impact the other namespace for which (s)he does not have the rights. <strong>Problem!!!</strong></p><p>Since the release of Chaos Mesh 1.1.3, this security issue has been fixed with a restricted authorization feature. Now when user applies the above YAML file, the system shows the error similar to:</p><pre><code class="language-yml">Error when creating &quot;pod/pod-kill.yaml&quot;: admission webhook &quot;vauth.kb.io&quot; denied the request: ... is forbidden on namespace
tidb-cluster-demo
</code></pre><p><strong>Problem solved!</strong></p><p>Please note, if the user has required rights on tidb-cluster-demo namespace as well, then there will be no such error.</p><h2>For more tutorials</h2><p>In case you want to enforce that no user should be allowed to create chaos across namespaces, you can check out my previous blog: <a href="https://anuragpaliwal-93749.medium.com/securing-tenant-services-while-using-chaos-mesh-using-opa-3ae80c7f4b85">Securing tenant services while using chaos mesh using OPA</a>.</p><h2>Last but not least</h2><p>If you are interested in Chaos Mesh and would like to learn more, you&#x27;re welcome to join the <a href="https://slack.cncf.io/">Slack channel</a> or submit your pull requests or issues to its <a href="https://github.com/chaos-mesh/chaos-mesh">GitHub repository</a>.</p>]]></content>
        <author>
            <name>Anurag Paliwal</name>
            <uri>https://github.com/anuragpaliwal80</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to efficiently stress test Pod memory]]></title>
        <id>/how-to-efficiently-stress-test-pod-memory</id>
        <link href="https://chaos-mesh.org/blog/how-to-efficiently-stress-test-pod-memory"/>
        <updated>2021-07-01T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[banner]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/how-to-efficiently-stress-test-pod-memory-banner.jpg" alt="banner"/></p><p><a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a> includes the StressChaos tool, which allows you to inject CPU and memory stress into your Pod. This tool can be very useful when you test or benchmark a CPU-sensitive or memory-sensitive program and want to know its behavior under pressure.</p><p>However, as we tested and used StressChaos, we found some issues with usability and performance. For example, why does StressChaos use far less memory than we configured? To correct these issues, we developed a new set of tests. In this article, I&#x27;ll describe how we troubleshooted these issues and corrected them. This information will enable you to get the most out of StressChaos.</p><p>Before you continue, you need to install Chaos Mesh in your cluster. You can find detailed instructions on our <a href="https://chaos-mesh.org/docs/quick-start">website</a>.</p><h2>Injecting stress into a target</h2><p>I‚Äôd like to demonstrate how to inject StressChaos into a target. In this example, I‚Äôll use <a href="https://github.com/paulbouwer/hello-kubernetes"><code>hello-kubernetes</code></a>, which is managed by <a href="https://helm.sh/">helm charts</a>. The first step is to clone the <a href="https://github.com/paulbouwer/hello-kubernetes"><code>hello-kubernetes</code></a> repo and modify the chart to give it a resource limit.</p><pre><code class="language-bash">git clone https://github.com/paulbouwer/hello-kubernetes.git
code deploy/helm/hello-kubernetes/values.yaml # or whichever editor you prefer
</code></pre><p>Find the resources line, and change it into:</p><pre><code class="language-yaml">resources:
  requests:
    memory: &#x27;200Mi&#x27;
  limits:
    memory: &#x27;500Mi&#x27;
</code></pre><p>However, before we inject anything, let&#x27;s see how much memory the target is consuming. Go into the Pod and start a shell. Enter the following, substituting the name of your Pod for the one in the example:</p><pre><code class="language-bash">kubectl exec -it -n hello-kubernetes hello-kubernetes-hello-world-b55bfcf68-8mln6 -- /bin/sh
</code></pre><p>Display a summary of memory usage. Enter:</p><pre><code class="language-sh">/usr/src/app $ free -m
/usr/src/app $ top
</code></pre><p>As you can see from the output below, the Pod is consuming 4,269 MB of memory.</p><pre><code class="language-sh">/usr/src/app $ free -m
              used
Mem:          4269
Swap:            0

/usr/src/app $ top
Mem: 12742432K used
  PID  PPID USER     STAT   VSZ %VSZ CPU %CPU COMMAND
    1     0 node     S     285m   2%   0   0% npm start
   18     1 node     S     284m   2%   3   0% node server.js
   29     0 node     S     1636   0%   2   0% /bin/sh
   36    29 node     R     1568   0%   3   0% top
</code></pre><p>That doesn‚Äôt seem right. We‚Äôve limited its memory usage to 500 MiBs, and now the Pod seems to be using several GBs of memory. If we total the amount of process memory being used, it doesn‚Äôt equal 500 MiB. However, top and free at least give similar answers.</p><p>We will run a StressChaos on the Pod and see what happens. Here&#x27;s the yaml we‚Äôll use:</p><pre><code class="language-yaml">apiVersion: chaos-mesh.org/v1alpha1
kind: StressChaos
metadata:
  name: mem-stress
  namespace: chaos-testing
spec:
  mode: all
  selector:
    namespaces:
      - hello-kubernetes
  stressors:
    memory:
      workers: 4
      size: 50MiB
      options: [&#x27;&#x27;]
  duration: &#x27;1h&#x27;
</code></pre><p>Save the yaml to a file. I named it <code>memory.yaml</code>. To apply the chaos, run</p><pre><code class="language-bash">~ kubectl apply -f memory.yaml
stresschaos.chaos-mesh.org/mem-stress created
</code></pre><p>Now, let&#x27;s check the memory usage again.</p><pre><code class="language-sh">              used
Mem:          4332
Swap:            0

Mem: 12805568K used
  PID  PPID USER     STAT   VSZ %VSZ CPU %CPU COMMAND
   54    50 root     R    53252   0%   1  24% {stress-ng-vm} stress-ng --vm 4 --vm-keep --vm-bytes 50000000
   57    52 root     R    53252   0%   0  22% {stress-ng-vm} stress-ng --vm 4 --vm-keep --vm-bytes 50000000
   55    53 root     R    53252   0%   2  21% {stress-ng-vm} stress-ng --vm 4 --vm-keep --vm-bytes 50000000
   56    51 root     R    53252   0%   3  21% {stress-ng-vm} stress-ng --vm 4 --vm-keep --vm-bytes 50000000
   18     1 node     S     289m   2%   2   0% node server.js
    1     0 node     S     285m   2%   0   0% npm start
   51    49 root     S    41048   0%   0   0% {stress-ng-vm} stress-ng --vm 4 --vm-keep --vm-bytes 50000000
   50    49 root     S    41048   0%   2   0% {stress-ng-vm} stress-ng --vm 4 --vm-keep --vm-bytes 50000000
   52    49 root     S    41048   0%   0   0% {stress-ng-vm} stress-ng --vm 4 --vm-keep --vm-bytes 50000000
   53    49 root     S    41048   0%   3   0% {stress-ng-vm} stress-ng --vm 4 --vm-keep --vm-bytes 50000000
   49     0 root     S    41044   0%   0   0% stress-ng --vm 4 --vm-keep --vm-bytes 50000000
   29     0 node     S     1636   0%   3   0% /bin/sh
   48    29 node     R     1568   0%   1   0% top
</code></pre><p>You can see that stress-ng instances are being injected into the Pod. There is a 60 MiB rise in the Pod, which we didn‚Äôt expect. The <a href="https://manpages.ubuntu.com/manpages/focal/en/man1/stress-ng.1.html">documentation</a> indicates that the increase should 200 MiB (4 <!-- -->*<!-- --> 50 MiB).</p><p>Let&#x27;s increase the stress by changing the memory stress from 50 MiB to 3,000 MiB. This should break the Pod‚Äôs memory limit. I‚Äôll delete the chaos, modify the size, and reapply it.</p><p>And then, boom! The shell exits with code 137. A moment later, I reconnect to the container, and the memory usage returns to normal. No stress-ng instances are found! What happened?</p><h2>Why does StressChaos disappear?</h2><p>Kubernetes limits your container memory usage through a mechanism named <a href="https://man7.org/linux/man-pages/man7/cgroups.7.html">cgroup</a>. To see the 500 MiB limit in our Pod, go to the container and enter:</p><pre><code class="language-bash">/usr/src/app $ cat /sys/fs/cgroup/memory/memory.limit_in_bytes
524288000
</code></pre><p>The output is displayed in bytes and translates to <code>500 * 1024 * 1024</code>.</p><p>Requests are used only for scheduling where to place the Pod. The Pod does not have a memory limit or request, but it can be seen as the sum of all its containers.</p><p>We&#x27;ve been making a mistake since the very beginning. free and top are not &quot;cgrouped.&quot; They rely on <code>/proc/meminfo</code> (procfs) for data. Unfortunately, <code>/proc/meminfo</code> is old, so old it predates cgroup. It will provide you with <strong>host</strong> memory information instead of your container. Let&#x27;s start from the beginning and see what memory usage we get this time.</p><p>To get the cgrouped memory usage, enter:</p><pre><code class="language-sh">/usr/src/app $ cat /sys/fs/cgroup/memory/memory.usage_in_bytes
39821312
</code></pre><p>Applying the 50 MiB StressChaos, yields the following:</p><pre><code class="language-sh">/usr/src/app $ cat /sys/fs/cgroup/memory/memory.usage_in_bytes
93577216
</code></pre><p>That is about 51 MiB more memory usage than without StressChaos.</p><p>Next, why did our shell exit? Exit code 137 indicates &quot;failure as container received SIGKILL.&quot; That leads us to check the Pod. Pay attention to the Pod state and events.</p><pre><code class="language-bash">~ kubectl describe pods -n hello-kubernetes
......
    Last State:     Terminated
      Reason:       Error
      Exit Code:    1
......
Events:
  Type     Reason     Age                  From               Message
  ----     ------     ----                 ----               -------
......
  Warning  Unhealthy  10m (x4 over 16m)    kubelet            Readiness probe failed: Get &quot;http://10.244.1.19:8080/&quot;: context deadline exceeded (Client.Timeout exceeded while awaiting headers)
  Normal   Killing    10m (x2 over 16m)    kubelet            Container hello-kubernetes failed liveness probe, will be restarted
......
</code></pre><p>The events tell us why the shell crashed. <code>hello-kubernetes</code> has a liveness probe, and when the container memory is reaching the limit, the application starts to fail, and Kubernetes decides to terminate and restart it. When the Pod restarts, StressChaos stops. In that case, you can say that the chaos works fine. It finds vulnerability in your Pod. You could now fix it, and reapply the chaos. Everything seems perfect now‚Äîexcept for one thing. Why do four 50 MiB vm workers result in 51 MiB in total? The answer will not reveal itself unless we go into the stress-ng source code <a href="https://github.com/ColinIanKing/stress-ng/blob/819f7966666dafea5264cf1a2a0939fd344fcf08/stress-vm.c#L2074">here</a> :</p><pre><code class="language-c">vm_bytes /= args-&gt;num_instances;
</code></pre><p>Oops! So the document is wrong. The multiple vm workers will take up the total size specified, rather than <code>mmap</code> that much memory per worker. Now, finally, we get an answer for everything. In the following sections, we‚Äôll discuss some other situations involving memory stress.</p><h2>What if there was no liveness probe?</h2><p>Let&#x27;s delete the probes and try again. Find the following lines in <code>deploy/helm/hello-kubernetes/templates/deployment.yaml</code> and delete them.</p><pre><code class="language-yaml">livenessProbe:
  httpGet:
    path: /
    port: http
readinessProbe:
  httpGet:
    path: /
    port: http
</code></pre><p>After that, upgrade the deployment.</p><p>What is interesting in this scenario is that the memory usage goes up continuously, and then drops sharply; it goes back and forth. What is happening now? Let&#x27;s check the kernel log. Pay attention to the last two lines.</p><pre><code class="language-sh">/usr/src/app $ dmesg
......
[189937.362908] [ pid ]   uid  tgid total_vm      rss nr_ptes swapents oom_score_adj name
[189937.363092] [441060]  1000 441060    63955     3791      80     3030           988 node
[189937.363110] [441688]     0 441688   193367     2136     372   181097          1000 stress-ng-vm
......
[189937.363148] Memory cgroup out of memory: Kill process 443160 (stress-ng-vm) score 1272 or sacrifice child
[189937.363186] Killed process 443160 (stress-ng-vm), UID 0, total-vm:773468kB, anon-rss:152704kB, file-rss:164kB, shmem-rss:0kB
</code></pre><p>It‚Äôs clear from the output that the <code>stress-ng-vm</code> processes are being killed because there are out of memory (OOM) errors.</p><p>If processes can‚Äôt get the memory they want, things get tricky. They are very likely to fail. Rather than wait for processes to crash, it‚Äôs better if you kill some of them to get more memory. The OOM killer stops processes by an order and tries to recover the most memory while causing the least trouble. For detailed information on this process, see <a href="https://lwn.net/Articles/391222/">this introduction</a> to OOM killer.</p><p>Looking at the output above, you can see that <code>node</code>, which is our application process that should never be terminated, has an <code>oom_score_adj</code> of 988. That is quite dangerous since it is the process with the highest score to get killed. But there is a simple way to stop the OOM killer from killing a specific process. When you create a Pod, it is assigned a Quality of Service (QoS) class. For detailed information, see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/">Configure Quality of Service for Pods</a>.</p><p>Generally, if you create a Pod with precisely-specified resource requests, it is classified as a <code>Guaranteed</code> Pod. OOM killers do not kill containers in a <code>Guaranteed</code> Pod if there are other things to kill. These entities include non-<code>Guaranteed</code> Pods and stress-ng workers. A Pod with no resource requests is marked as <code>BestEffort</code>, and the OOM killer stops it first.</p><p>So that&#x27;s all for the tour. Our suggestion is that <code>free</code> and <code>top</code> should not be used to assess memory in containers. Be careful when you assign resource limits to your Pod and select the right QoS. In the future, we‚Äôll create a more detailed StressChaos document.</p><h2>Deeper dive into Kubernetes memory management</h2><p>Kubernetes tries to evict Pods that use too much memory (but not more memory than their limits). Kubernetes gets your Pod memory usage from <code>/sys/fs/cgroup/memory/memory.usage_in_bytes</code> and subtracts it by the <code>total_inactive_file</code> line in <code>memory.stat</code>.</p><p>Keep in mind that Kuberenetes <strong>does not</strong> support swap. Even if you have a node with swap enabled, Kubernetes creates containers with <code>swappiness=0</code>, which means swap is eventually disabled. That is mainly for performance concerns.</p><p><code>memory.usage_in_bytes</code> equals <code>resident set</code> plus <code>cache</code>, and <code>total_inactive_file</code> is memory in cache that the OS can retrieve if the memory is running out. <code>memory.usage_in_bytes - total_inactive_file</code> is called <code>working_set</code>. You will get this <code>working_set</code> value by <code>kubectl top pod &lt;your pod&gt; --containers</code>. Kubernetes uses this value to decide whether or not to evict your Pods.</p><p>Kubernetes periodically inspects memory usage. If a container&#x27;s memory usage increases too quickly or the container cannot be evicted, the OOM killer is invoked. Kubernetes has its way of protecting its own process, so it always picks the container. When a container is killed, it may or may not be restarted, depending on your restart policy. If it is killed, when you execute <code>kubectl describe pod &lt;your pod&gt;</code> you will see it is restarted and the reason is <code>OOMKilled</code>.</p><p>Another thing worth mentioning is the kernel memory. Since <code>v1.9</code>, Kubernetes‚Äô kernel memory support is enabled by default. It is also a feature of cgroup memory subsystems. You can limit container kernel memory usage. Unfortunately, this causes a cgroup leak on kernel versions up to <code>v4.2</code>. You can either upgrade your kernel to <code>v4.3</code> or disable it.</p><h2>How we implement StressChaos</h2><p>StressChaos is a simple way to test your container&#x27;s behavior when it is low on memory. StressChaos utilizes a powerful tool named <code>stress-ng</code> to allocate memory and continue writing to the allocated memory. Because containers have memory limits and container limits are bound to a cgroup, we must find a way to run <code>stress-ng</code> in a specific cgroup. Luckily, this part is easy. With enough privileges, we can assign any process to any cgroup by writing to files in <code>/sys/fs/cgroup/</code>.</p><p>If you are interested in Chaos Mesh and would like to help us improve it, you&#x27;re welcome to join our <a href="https://slack.cncf.io/">Slack channel</a> (#project-chaos-mesh)! Or submit your pull requests or issues to our <a href="https://github.com/chaos-mesh/chaos-mesh">GitHub repository</a>.</p>]]></content>
        <author>
            <name>Yinghao Wang</name>
            <uri>https://github.com/AsterNighT</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chaos Mesh Remake: One Step Closer toward Chaos as a Service]]></title>
        <id>/chaos-mesh-remake-one-step-closer-towards-chaos-as-a-service</id>
        <link href="https://chaos-mesh.org/blog/chaos-mesh-remake-one-step-closer-towards-chaos-as-a-service"/>
        <updated>2021-06-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos engineering tools]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-engineering-tools-as-a-service.jpeg" alt="Chaos engineering tools"/></p><p><a href="https://chaos-mesh.org/">Chaos Mesh</a> is a cloud-native Chaos Engineering platform that orchestrates chaos in Kubernetes environments. With Chaos Mesh, you can test your system&#x27;s resilience and robustness on Kubernetes by injecting all types of faults into Pods, network, file system, and even the kernel.</p><p>Since it was open-sourced and accepted by the Cloud Native Computing Foundation (CNCF) as a sandbox project, Chaos Mesh has attracted contributors worldwide and helped users test their systems. Yet it still has a lot of room for improvement:</p><ul><li>It needs to improve usability. Some features are complicated to use. For example, when you apply a chaos experiment, you often have to manually check whether the experiment has started.</li><li>It is mostly for Kubernetes environments. Because Chaos Mesh can&#x27;t manage multiple Kubernetes clusters, you need to deploy Chaos Mesh for each Kubernetes cluster. Though <a href="https://github.com/chaos-mesh/chaosd">chaosd</a> supports running chaos experiments on physical machines, the features are quite limited, and command line usage is not user friendly.</li><li>It doesn&#x27;t allow plugins. To apply a customized chaos experiment, you have to alter the source code. Moreover, Chaos Mesh only supports Golang.</li></ul><p>Admittedly, Chaos Mesh is a first-rate Chaos Engineering platform, but is still a long way from offering Chaos as a Service (CaaS). Therefore, at <a href="https://pingcap.com/community/events/hackathon2020/">TiDB Hackathon 2020</a>, <strong>we made changes to Chaos Mesh&#x27;s architecture, moving it one step closer toward CaaS</strong>.</p><p>In this article, I&#x27;ll talk about what CaaS is, how we achieve it with Chaos Mesh, and our plans and lessons learned. I hope you find our experience helpful in building your own Chaos Engineering system.</p><h2>What is Chaos as a Service?</h2><p>As Matt Fornaciari, co-founder of Gremlin, <a href="https://jaxenter.com/chaos-engineering-service-144113.html">puts it</a>, CaaS &quot;means you will get an intuitive UI, customer support, out-of-the-box integrations, and everything else you need to get experimenting in a matter of minutes.&quot;</p><p>From our perspective, CaaS should offer:</p><ul><li>A unified console for management, where you can edit the configuration and create chaos experiments.</li><li>Visualized metrics for you to see the experiment status.</li><li>Operations to pause or archive experiments.</li><li>Simple interaction. You can easily drag and drop the objects to orchestrate your experiments.</li></ul><p>Some companies already adapted Chaos Mesh to meet their own needs, such as <a href="https://pingcap.com/blog/how-a-top-game-company-uses-chaos-engineering-to-improve-testing">NetEase Fuxi AI Lab</a> and FreeWheel, making it a mock-up for CaaS.</p><h2>Developing Chaos Mesh towards CaaS</h2><p>Based on our understanding of CaaS, we refined the architecture of Chaos Mesh during Hackathon, including improved support for different systems and better observability. You can check out our code in <a href="https://github.com/wuntun/chaos-mesh/tree/caas">wuntun/chaos-mesh</a> and <a href="https://github.com/wuntun/chaosd/tree/caas">wuntun/chaosd</a>.</p><h3>Refactor Chaos Dashboard</h3><p>The current Chaos Mesh architecture is suited for individual Kubernetes clusters. Chaos Dashboard, the web UI, is bound to a specified Kubernetes environment:</p><p><img src="/img/chaos-mesh-remake-architecture.jpeg" alt="Chaos Mesh architecture"/></p><p class="caption-center">The current Chaos Mesh architecture</p><p>During this refactor, <strong>to allow Chaos Dashboard to manage multiple Kubernetes clusters, we separate Chaos Dashboard from the main architecture</strong>. Now, if you deploy Chaos Dashboard outside of the Kubernetes cluster, you can add the cluster to Chaos Dashboard via the web UI. If you deploy Chaos Dashboard inside the cluster, it automatically obtains the cluster information through environment variables.</p><p>You can register Chaos Mesh (technically, the Kubernetes configuration) in Chaos Dashboard or ask <code>chaos-controller-manager</code> to report to Chaos Dashboard via configuration. Chaos Dashboard and <code>chaos-controller-manager</code> interact via CustomResourceDefinitions (CRDs). When <code>chaos-controller-manager</code> finds a Chaos Mesh CRD event, it invokes <code>chaos-daemon</code> to carry out the related chaos experiment. Therefore, Chaos Dashboard can manage experiments by operating on CRDs.</p><h3>Refactor chaosd</h3><p>chaosd is a toolkit for running chaos experiments on physical machines. Previously, it was only a command line tool and had limited features.</p><p><img src="/img/chaosd-chaos-engineering-command-line-tool.jpeg" alt="chaosd, a Chaos Engineering command line tool"/></p><p class="caption-center">Previously, chaosd was a command line tool</p><p>During the refactoring, <strong>we enabled chaosd to support the RESTful API and enhanced its services so that it can configure chaos experiments by parsing CRD-format JSON or YAML files</strong>.</p><p>Now, chaosd can register itself to Chaos Dashboard via configuration and send regular heartbeats to Chaos Dashboard. With the heartbeat signals, Chaos Dashboard can manage the chaosd node status. You can also add chaosd nodes to Chaos Dashboard via the web UI.</p><p>Moreover, <strong>chaosd can now schedule chaos experiments at specified time and manage experiment lifecycles, which unifies the user experience on Kubernetes and on physical machines</strong>.</p><p>With new Chaos Dashboard and chaosd, the optimized architecture of Chaos Mesh is as follows:</p><p><img src="/img/chaos-mesh-optimized-architecture.jpeg" alt="Chaos Mesh&#x27;s optimized architecture"/></p><p class="caption-center">Chaos Mesh&#x27;s optimized architecture</p><h3>Improve observability</h3><p>Another improvement is observability, namely how to tell if an experiment is carried out successfully.</p><p>Before the improvement, you had to manually check the experiment metrics. If you injected <a href="https://chaos-mesh.org/docs/1.2.4/chaos_experiments/stresschaos">StressChaos</a> into a Pod, you had to enter the Pod to see if there was a <code>stress-ng</code> process and then use <code>top</code> commands to check CPU and memory utilization. These metrics told you whether your StressChaos experiment was created successfully.</p><p>To streamline the process, we now integrate <code>node_exporter</code> into <code>chaos-daemon</code> and chaosd to collect node metrics. We also deploy <code>kube-state-metrics</code> in the Kubernetes cluster, combined with cadvisor, to collect Kubernetes metrics. The collected metrics are saved and visualized by Prometheus and Grafana, which provide a simple method for you to check the experiment status.</p><h4>Further improvements needed</h4><p>Overall, metrics aim to help you:</p><ul><li>Confirm that chaos is injected.</li><li>Observe the chaos impact on the service and make periodic analysis.</li><li>Respond to exceptional chaos events.</li></ul><p>To achieve these goals, the system needs to monitor the experiment data metrics, the ordinary metrics, and the experiment events. Chaos Mesh still needs to improve:</p><ul><li>Experiment data metrics, such as the exact latency duration of the injected network latency and the specific load of the simulated workload.</li><li>Experiment events; that is, the Kubernetes events of creating, deleting, and running experiments.</li></ul><p>Here is a good example of metrics from <a href="https://github.com/litmuschaos/chaos-exporter#example-metrics">Litmus</a>.</p><h2>Other proposals for Chaos Mesh</h2><p>Because of the limited time at Hackathon, we didn&#x27;t finish all our plans. Here are some of our proposals for the Chaos Mesh community to consider in the future.</p><h3>Orchestration</h3><p>A closed loop of Chaos Engineering includes four steps: exploring chaos, discovering deficiencies in the system, analyzing root causes, and sending feedback for improvement.</p><p><img src="/img/closed-loop-of-chaos-engineering.jpeg" alt="A closed loop of Chaos Engineering"/></p><p class="caption-center">A closed loop of Chaos Engineering</p><p>However, <strong>most of the current open source Chaos Engineering tools only focus on exploration and do not provide pragmatic feedback.</strong> Based on the improved observability component, we can monitor chaos experiments in real time and compare and analyze the experiment results.</p><p>With these results, we will be able to realize a closed loop by adding another important component: orchestration. The Chaos Mesh community already proposed a <a href="https://github.com/chaos-mesh/rfcs/pull/10/files">Workflow</a> feature, which enables you to easily orchestrate and call back chaos experiments or conveniently integrate Chaos Mesh with other systems. You can run chaos experiments in the CI/CD phase or after a canary release.</p><p><strong>Combining observability and orchestration makes a closed feedback loop for Chaos Engineering.</strong> If you were to launch a 100 ms network latency test on a Pod, you could observe the latency change using the observability component and check if the Pod service is still available using PromQL or other DSL based on orchestration. If the service was unavailable, you may conclude that the service is unavailable when the latency is &gt;= 100 ms.</p><p>But 100 ms is not the threshold of your service; you need to know what is the largest latency your service can handle. By orchestrating the value of the chaos experiment, you&#x27;ll know what is the threshold value you must ensure to meet your service-level objectives. Also, you&#x27;ll find out the service performance under different network conditions and whether they meet your expectations.</p><h3>Data format</h3><p>Chaos Mesh uses CRDs to define its chaos objects. If we can convert CRDs to JSON files, we can achieve communication between components.</p><p>In terms of data format, chaosd just consumes and registers CRD data in JSON format. If a chaos tool can consume CRD data and register itself, it can run chaos experiments in different scenarios.</p><h3>Plugins</h3><p>Chaos Mesh has limited support for plugins. You can only <a href="https://chaos-mesh.org/docs/1.2.4/development_guides/develop_a_new_chaos/">add a new Chaos</a> by registering a CRD in Kubernetes API. This brings about two problems:</p><ul><li>You must develop the plugin using Golang, the same language in which Chaos Mesh is written.</li><li>You must merge the extended code into the Chaos Mesh project. Because Chaos Mesh doesn&#x27;t have a security mechanism like Berkeley Packet Filter (BPF), merging plugin code may introduce extra risks.</li></ul><p>To enable full plugin support, we need to explore a new method to add plugins. As Chaos Mesh essentially carries out chaos experiments based on CRD, a chaos experiment only requires generating, listening to, and deleting CRDs. In this regard, we have several ideas worth trying:</p><ul><li>Develop a controller or operator to manage CRDs.</li><li>Handle CRD events uniformly and operate on CRDs via HTTP callback. This method only uses HTTP APIs, with no requirement on Golang. For an example, see <a href="https://github.com/summerwind/whitebox-controller">Whitebox Controller</a>.</li><li>Use WebAssembly (Wasm). When you need to call chaos experiment logic, just call the Wasm program. See Vector&#x27;s <a href="https://vector.dev/docs/reference/transforms/wasm/">WASM Transform</a>.</li><li>Use SQL to query the chaos experiment status. Because Chaos Mesh is based on CRDs, you can use SQL to operate on Kubernetes. Examples include <a href="https://github.com/xuxinkun/kubesql">Presto connector</a> and <a href="https://github.com/aquasecurity/kube-query">osquery extension</a>.</li><li>Use SDK-based extensions, such as <a href="https://docs.chaostoolkit.org/reference/api/experiment/">Chaos Toolkit</a>.</li></ul><h3>Integration with other Chaos tools</h3><p>For real-world systems, a single Chaos Engineering tool can hardly exhaust all possible use cases. That&#x27;s why integrating with other chaos tools can make the Chaos Engineering ecosystem more powerful.</p><p>There are numerous Chaos Engineering tools on the market. Litmus&#x27;s <a href="https://github.com/litmuschaos/litmus-go/tree/master/chaoslib/powerfulseal">Kubernetes implementation</a> is based on <a href="https://github.com/powerfulseal/powerfulseal">PowerfulSeal</a>, while its <a href="https://github.com/litmuschaos/litmus-go/tree/master/chaoslib/pumba">container implementation</a> is based on <a href="https://github.com/alexei-led/pumba">Pumba</a>. <a href="https://github.com/cloud-bulldozer/kraken">Kraken</a> focuses on Kubernetes, <a href="https://github.com/amzn/awsssmchaosrunner">AWSSSMChaosRunner</a> focuses on AWS, and <a href="https://github.com/shopify/toxiproxy">Toxiproxy</a> targets TCP. There are also merging projects based on <a href="https://docs.google.com/presentation/d/1gMlmXqH6ufnb8eNO10WqVjqrPRGAO5-1S1zjcGo1Zr4/edit#slide=id.g58453c664c_2_75">Envoy</a> and Istio.</p><p>To manage the various chaos tools, we may need a uniform pattern, such as <a href="https://hub.litmuschaos.io/">Chaos Hub</a>.</p><h2>Voices from the community</h2><p>Here, we&#x27;d like to share how a leading cyber security company in China as well as a Chaos Mesh user, adapts Chaos Mesh to meet their needs. Their adaptation has three aspects: physical node, container, and application.</p><h3>Physical node</h3><ul><li>Support executing scripts on physical servers. You can configure the script directory in CRDs and run your scripts using <code>chaos-daemon</code>.</li><li>Simulate reboot, shutdown, and kernel panic using the customized script.</li><li>Shut down the node&#x27;s NIC using the customized script.</li><li>Create frequent context switching using sysbench to simulate the &quot;noisy neighbor&quot; effect.</li><li>Intercept the container&#x27;s system call using BPF&#x27;s <code>seccomp</code>. This is achieved by passing and filtering PIDs.</li></ul><h3>Container</h3><ul><li>Randomly change the number of Deployment replicas to test if the application&#x27;s traffic is abnormal.</li><li>Embed based on CRD objects: fill Ingress objects in chaos CRDs to simulate the speed limit of the interface.</li><li>Embed based on CRD objects: fill Cilium network policy objects in chaos CRDs to simulate fluctuating network conditions.</li></ul><h3>Application</h3><ul><li>Support running customized jobs. Currently, Chaos Mesh injects chaos using <code>chaos-daemon</code>, which doesn&#x27;t guarantee fairness and affinity of scheduling. To address this issue, we can use <code>chaos-controller-manager</code> to directly create jobs for different CRDs.</li><li>Support running <a href="https://github.com/postmanlabs/newman">Newman</a> in customized jobs to randomly change HTTP parameters. This is to implement chaos experiments on the HTTP interface, which happens when a user performs exceptional behaviors.</li></ul><h2>Summary</h2><p>Traditional fault testing targets specific points in the system that are anticipated to be vulnerable. It is often an assertion: a specific condition produces a specific result.</p><p><strong>Chaos Engineering is more powerful in that it helps you discover the &quot;unknown unknowns.&quot;</strong> By exploring in the broader domain, Chaos Engineering deepens your knowledge of the system being tested and unearths new information.</p><p>To sum up, these are some of our personal thoughts and practice on Chaos Engineering and Chaos Mesh. Our Hackathon project is not ready for production yet, but we hope to shed some light on CaaS and draft a promising roadmap for Chaos Mesh. If you&#x27;re interested in building Chaos as a Service, <a href="https://slack.cncf.io/">join our Slack</a> (#project-chaos-mesh)!</p>]]></content>
        <author>
            <name>Chang Yu, Xiang Wang</name>
            <uri>https://github.com/chaos-mesh/chaos-mesh/blob/master/MAINTAINERS.md</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[From a Newbie in Software Engineering to a Graduated LFX-Mentee]]></title>
        <id>/lfx-mentorship-enriching-awschaos</id>
        <link href="https://chaos-mesh.org/blog/lfx-mentorship-enriching-awschaos"/>
        <updated>2021-06-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[LFX Mentorship Experience]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/mentorship_blog.jpeg" alt="LFX Mentorship Experience"/></p><p><a href="https://mentorship.lfx.linuxfoundation.org/mentee/6a0bf7de-9e18-4acb-9a66-f5fecdbeb42e">I‚Äôm</a> a junior undergraduate majoring in Biomedical Engineering in the Department of Biotechnology and Medical Engineering at the <a href="https://nitrkl.ac.in/">National Institute of Technology Rourkela</a>, India. For someone who started to code only because I was fascinated by it, it was all a journey of self-learning, filled with various adversities. But when I started with open-source contributions, it was all very beginner-friendly and I came across a lot of people who helped me learn the tech stack better.</p><p><img src="/img/mentroship_blog1.png" alt="img1"/></p><h2>The journey through the application</h2><p>In the spring of 2021, I got to know about this LFX mentorship program and after browsing through all the <a href="https://github.com/cncf/mentoring/blob/master/lfx-mentorship/2021/01-Spring/README.md">projects</a>, it felt quite intimidating to me as I wasn‚Äôt acquainted with most of the terms and was confused, and I thought it was not for newbies like me. Then I went through the program <a href="https://docs.linuxfoundation.org/lfx/mentorship">docs</a>, the mentorship <a href="https://docs.linuxfoundation.org/lfx/mentorship/mentorship-faqs">FAQ‚Äôs</a> followed the steps mentioned there and applied for a few projects that interested me, and used tech-stacks that I am familiar with, like Docker, AWS, Python, etc.</p><p>Then I applied to both projects offered by <a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a> and submitted my CV and cover letter as immediate tasks. After a few days, I received an email from my mentor regarding an additional task to be submitted.</p><p><img src="/img/mentorship_blog2.png" alt="img2"/></p><p>I completed the above-mentioned task, uploaded the files to GitHub, and shared the link with my mentor.</p><h2>The selection and Initial days as a mentee</h2><p>I distinctly remember the day when I received an email from my mentor regarding my selection in the mentorship program. I was elated, as it was my first involvement in any open-source program. I was glad to be accepted as a mentee in the program, I even received an email from CNCF regarding my selection.</p><p><img src="/img/mentorship_blog4.png" alt="img3"/></p><p>Along with my mentor, we decided on our mode of communication: through Slack. He also enquired about my knowledge of Kubernetes and GOlang, as I didn‚Äôt have much knowledge about either of them. He suggested a few resources and gave me 2 weeks to go through them. In the meantime, he also planned a few experiments for me to get acquainted with all these technologies.</p><p>As I was getting more comfortable with Kubernetes, I started exploring Chaos Mesh and completed the interactive <a href="https://chaos-mesh.org/interactive-tutorial">tutorial</a>, which gave me a clearer idea about the usage of Chaos Mesh. I then implemented the <a href="https://chaos-mesh.org/docs/1.2.4/development_guides/develop_a_new_chaos">hello-world chaos</a>, which helped me to know more about controllers and CRDs, considered to be the most important part of Chaos Mesh. Also, I got to know about the boilerplate codes, the <a href="https://github.com/kubernetes-sigs/kubebuilder">kube-builder client</a>, and how to use them for scaffolding, followed by writing our own controllers.</p><p>After the initial days of experimenting and getting to know the project better, I started with solving a few good first issues to get acquainted with upstream contributions to Chaos Mesh.</p><p><img src="/img/mentorship_blog3.png" alt="img4"/></p><p>In one of my contributions, I tried to add multi-container support to stress-chaos, which was not possible before. Though it was successfully implemented, it broke a few other features and couldn‚Äôt be merged for the upcoming release. What‚Äôs more, for the 2.0.0 release, this refactoring was already done, so this particular contribution was a learning experience for both me and my mentor. After that, we became careful and the next time we tried to implement any new features, we would first submit an <a href="https://github.com/chaos-mesh/rfcs">RFC</a> and have discussions with the other contributors before starting.</p><h2>My contribution to AWS Chaos</h2><p>Initially, I was asked to implement one type of AWS Chaos as part of this project, but as I started exploring more about it, I found <a href="https://github.com/amzn/awsssmchaosrunner">awsssmchaosrunner</a>, and given its functionality, we wanted to integrate it into Chaos Mesh.</p><p>We planned to do it in two parts, one part is the ‚Äú<a href="https://github.com/STRRL/awsssmchaosrunner-cli">runner thing</a>‚Äù project, which integrates with awsssmchaosrunner, that part should be written in kotlin, and a docker image is to be built out of it.</p><p>Another part is the definition of the AWS Chaos and its <a href="https://github.com/chaos-mesh/chaos-mesh/pull/1919">controller</a>, which is to be written in go, the controller of AWS Chaos will create a pod with that ‚Äúkotlin cli image‚Äù, and send commands to AWS.</p><h2>Other opportunities</h2><p>I was invited to one of the Chaos Mesh <a href="https://www.youtube.com/watch?v=ElG0pHRoXwI&amp;t=2s">community meetings</a> towards the end of the mentorship where I showcased my project.</p><p>Afterwards, I applied for the CFP for <a href="https://community.cncf.io/events/details/cncf-kcd-bengaluru-presents-kubernetes-community-days-bengaluru/">Kubernetes Community Days Bangalore</a>, scheduled virtually from June 25‚Äì26, 2021, and was selected as a speaker and now I‚Äôm all set to present my talk there.</p><h2>Graduation and Next steps</h2><p>Yayyyy!! After 12 weeks, I successfully graduated from the program, thanks to my mentor <a href="https://mentorship.lfx.linuxfoundation.org/mentor/e78b3177-160c-4566-9f3d-8fc9b2ec3cea">Zhou Zhiqiang</a> and his guidance, because without whom, this wouldn‚Äôt have been possible.</p><p>I had an amazing time with the Chaos Mesh community, with the amazing members supporting and helping me throughout the journey. I look forward to contributing more to this project and being more active in the community.</p><h2>Join the Chaos Mesh community</h2><p>To join and learn more about Chaos Mesh, find the #project-chaos-mesh channel in <a href="https://slack.cncf.io/">CNCF slack workspace</a> or their <a href="https://github.com/chaos-mesh/chaos-mesh">GitHub</a>.</p>]]></content>
        <author>
            <name>Debabrata Panigrahi</name>
            <uri>https://github.com/Debanitrkl</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Celebrating One Year of Chaos Mesh: Looking Back and Ahead]]></title>
        <id>/celebrating-one-year-of-chaos-mesh-looking-back-and-ahead</id>
        <link href="https://chaos-mesh.org/blog/celebrating-one-year-of-chaos-mesh-looking-back-and-ahead"/>
        <updated>2021-02-05T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Celebrating One Year of Chaos Mesh: Looking Back and Ahead]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/celebrating-one-year-of-chaos-mesh-looking-back-and-ahead.jpg" alt="Celebrating One Year of Chaos Mesh: Looking Back and Ahead"/></p><p>It‚Äôs been a year since Chaos Mesh was first open-sourced on GitHub. Chaos Mesh started out as a mere fault injection tool and is now heading towards the goal of building a chaos engineering ecology. Meanwhile, the Chaos Mesh community was also built from scratch and has helped <a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a> join CNCF as a Sandbox project.</p><p>In this article, we will share with you how Chaos Mesh has grown and changed in the past year, and also discuss its future goals and plans.</p><h2>The project: thrive with a clear goal in mind</h2><p>In this past year, Chaos Mesh has grown at an impressive speed with the joint efforts of the community. From the very first version to the recently released <a href="https://github.com/chaos-mesh/chaos-mesh/releases/tag/v1.1.0">v1.1.0</a>, Chaos Mesh has been greatly improved in terms of functionality, ease of use, and security.</p><h3>Functionality</h3><p>When first open-sourced, Chaos Mesh supported only three fault types: PodChaos, NetworkChaos, and IOChaos. Within only a year, Chaos Mesh can perform all around fault injections into the network, system clock, JVM applications, filesystems, operating systems, and so on.</p><p><img src="/img/chaos-tests.png" alt="Chaos Tests"/></p><p>After continuous optimization, Chaos Mesh now provides a flexible scheduling mechanism, which enables users to better design their own chaos experiments. This laid the foundation for chaos orchestration.</p><p>In the meantime, we are happy to see that a number of users have started to <a href="https://github.com/chaos-mesh/chaos-mesh/issues/1182">test Chaos Mesh on major cloud platforms</a>, such as Amazon Web Services (AWS), Google Kubernetes Engine (GKE), Alibaba Cloud, and Tencent Cloud. We have continuously conducted compatibility testing and adaptations, in order to support <a href="https://github.com/chaos-mesh/chaos-mesh/pull/1330">fault injection for specific cloud platforms</a>.</p><p>To better support Kubernetes native components and node-level failures, we developed <a href="https://github.com/chaos-mesh/chaosd">Chaosd</a>, which provides physical node-level fault injection. We&#x27;re extensively testing and refining this feature for release within the next few months.</p><h3>Ease of use</h3><p>Ease of use has been one of the guiding principles of Chaos Mesh development since day one. You can deploy Chaos Mesh with a single command line. The V1.0 release brought the long-awaited Chaos Dashboard, a one-stop web interface for users to orchestrate chaos experiments. You can define the scope of the chaos experiment, specify the type of chaos injection, define scheduling rules, and observe the results of the chaos experiment‚Äîall in the same web interface with only a few clicks.</p><p><img src="/img/chaos-dashboard1.png" alt="Chaos Dashboard"/></p><p>Prior to V1.0, many users reported being blocked by various configuration problems when injecting IOChaos faults. After intense investigations and discussions, we gave up the original SideCar implementation. Instead, we used chaos-daemon to dynamically invade the target Pod, which significantly simplifies the logic. This optimization has made dynamic I/O fault injection possible with Chaos Mesh, and users can focus solely on their experiments without having to worry about additional configurations.</p><h3>Security</h3><p>We have improved the security of Chaos Mesh. It now provides a comprehensive set of selectors to control the scope of the experiments, and supports setting specific namespaces to protect important applications. What‚Äôs more, the support of namespace permissions allows users to limit the ‚Äúexplosion radius‚Äù of a chaos experiment to a specific namespace.</p><p>In addition, Chaos Mesh directly reuses Kubernetes‚Äô native permission mechanism and supports verification on the Chaos Dashboard. This protects you from other users‚Äô errors, which can cause chaos experiments to fail or become uncontrollable.</p><h2>Cloud native ecosystem: integrations and cooperations</h2><p>In July 2020, Chaos Mesh was successfully <a href="https://chaos-mesh.org/blog/chaos-mesh-join-cncf-sandbox-project">accepted as a CNCF Sandbox project</a>. This shows that Chaos Mesh has received initial recognition from the cloud native community. At the same time, it means that Chaos Mesh has a clear mission: to promote the application of chaos engineering in the cloud native field and to cooperate with other cloud native projects so we can grow together.</p><h3>Grafana</h3><p>To further improve the observability of chaos experiments, we have included a separate <a href="https://github.com/chaos-mesh/chaos-mesh-datasource">Grafana plug-in</a> for Chaos Mesh, which allows users to directly display real-time chaos experiment information on the application monitoring panel. This way, users can simultaneously observe the running status of the application and the current chaos experiment information.</p><h3>GitHub Action</h3><p>To enable users to run chaos experiments even during the development phase, we developed the <a href="https://github.com/chaos-mesh/chaos-mesh-action">chaos-mesh-action</a> project, allowing Chaos Mesh to run in the workflow of GitHub Actions. This way, Chaos Mesh can easily be integrated into daily system development and testing.</p><h3>TiPocket</h3><p><a href="https://github.com/pingcap/tipocket">TiPocket</a> is an automated test platform that integrates Chaos Mesh and Argo, a workflow engine designed for Kubernetes. TiPocket is designed to be a fully automated chaos engineering testing loop for TiDB, a distributed database. There are a number of steps when we conduct chaos experiments, including deploying applications, running workloads, injecting exceptions, and business checks. To fully automate these steps, Argo was integrated into TiPocket. Chaos Mesh provides rich fault injection, while Argo provides flexible orchestration and scheduling.</p><p><img src="/img/tipocket.png" alt="TiPocket"/></p><h2>The community: built from the ground up</h2><p>Chaos Mesh is a community-driven project, and cannot progress without an active, friendly, and open community. Since it was open-sourced, Chaos Mesh has quickly become one of the most eye-catching open-source projects in the chaos engineering world. Within a year, it has accumulated more than 3k stars on GitHub and 70+ contributors. Adopters include Tencent Cloud, XPeng Motors, Dailymotion, NetEase Fuxi Lab, JuiceFS, APISIX, and Meituan. Looking back on the past year, the Chaos Mesh community was built from scratch, and has laid the foundation for a transparent, open, friendly, and autonomous open source community.</p><h3>Becoming part of the CNCF family</h3><p>Cloud native has been in the DNA of Chaos Mesh since the very beginning. Joining CNCF was a natural choice, which marks a critical step for Chaos Mesh to becoming a vendor-neutral, open and transparent open-source community. Aside from integration within the cloud native ecosystem, joining CNCF gives Chaos Mesh:</p><ul><li><p>More community and project exposure. Collaborations with other projects and various cloud native community activities such as Kubernetes Meetup and KubeCon have presented us great opportunities to communicate with the community. We are amazed how the high-quality content produced by the community has also played a positive and far-reaching role in promoting Chaos Mesh.</p></li><li><p>A more complete and open community framework. CNCF provides a rather mature framework for open-source community operations. Under CNCF‚Äôs guidance, we established our basic community framework, including a Code of Conduct, Contributing Guide, and Roadmap. We‚Äôve also created our own channel, #project-chaos-mesh, under CNCF‚Äôs Slack.</p></li></ul><h3>A friendly and supportive community</h3><p>The quality of the open source community determines whether our adopters and contributors are willing to stick around and get involved in the community for the long run. In this regard, we‚Äôve been working hard on:</p><ul><li><p>Continuously enriching documentation and optimizing its structure. So far, we have developed a complete set of documentation for different groups of audiences, including <a href="https://chaos-mesh.org/docs/1.2.4/user_guides/installation">a user guide</a> and <a href="https://chaos-mesh.org/docs/1.2.4/development_guides/development_overview">developer guide</a>, <a href="https://chaos-mesh.org/docs/1.2.4/get_started/get_started_on_kind">quick start guides</a>, <a href="https://chaos-mesh.org/docs/1.2.4/use_cases/multi_data_centers">use cases</a>, and <a href="https://github.com/chaos-mesh/chaos-mesh/blob/master/CONTRIBUTING.md">a contributing guide</a>. All are constantly updated per each release.</p></li><li><p>Working with the community to publish blog posts, tutorials, use cases, and chaos engineering practices. So far, we‚Äôve produced 26 Chaos Mesh related articles. Among them is <a href="https://chaos-mesh.org/interactive-tutorial">an interactive tutorial</a>, published on O‚ÄôReilly‚Äôs Katakoda site. These materials make a great complement to the documentation.</p></li><li><p>Repurposing and amplifying videos and tutorials generated in community meetings, webinars, and meetups. Valuing and responding to community feedback and queries.</p></li></ul><h2>Looking ahead</h2><p>Google‚Äôs recent global outage reminded us of the importance of system reliability, and it highlighted the importance of chaos engineering. Liz Rice, CNCF TOC Chair, shared <a href="https://twitter.com/CloudNativeFdn/status/1329863326428499971">The 5 technologies to watch in 2021</a>, and chaos engineering is on top of the list. We boldly predict that chaos engineering is about to enter a new stage in the near future. Chaos Mesh 2.0 is now in active development, and it includes community requirements such as an embedded workflow engine to support the definition and management of more flexible chaos scenarios, application state checking mechanisms, and more detailed experiments reports. Follow along through the project <a href="https://github.com/chaos-mesh/chaos-mesh/blob/master/ROADMAP.md">roadmap</a>.</p><h2>Last but not least</h2><p>Chaos Mesh has grown so much in the past year, yet it is still young, and we have just set sail towards our goal. In the meantime, we call for all of you to participate and help build the Chaos Engineering system ecology together!</p><p>If you are interested in Chaos Mesh and would like to help us improve it, you&#x27;re welcome to join <a href="https://slack.cncf.io/">our Slack channel</a> or submit your pull requests or issues to our <a href="https://github.com/chaos-mesh/chaos-mesh">GitHub repository</a>.</p>]]></content>
        <author>
            <name>Cwen Yin, Calvin Weng</name>
            <uri>https://github.com/chaos-mesh/chaos-mesh/blob/master/MAINTAINERS.md</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to Simulate I/O Faults at Runtime]]></title>
        <id>/how-to-simulate-io-faults-at-runtime</id>
        <link href="https://chaos-mesh.org/blog/how-to-simulate-io-faults-at-runtime"/>
        <updated>2021-01-08T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos Engineering - How to simulate I/O faults at runtime]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/how-to-simulate-io-faults-at-runtime.jpg" alt="Chaos Engineering - How to simulate I/O faults at runtime"/></p><p>In a production environment, filesystem faults might occur due to various incidents such as disk failures and administrator errors. As a Chaos Engineering platform, Chaos Mesh has supported simulating I/O faults in a filesystem ever since its early versions. By simply adding an IOChaos CustomResourceDefinition (CRD), we can watch how the filesystem fails and returns errors.</p><p>However, before Chaos Mesh 1.0, this experiment was not easy and may have consumed a lot of resources. We needed to inject sidecar containers to the Pod through the mutating admission webhooks and rewrite the <code>ENTRYPOINT</code> command. Even if no fault was injected, the injected sidecar container caused a substantial amount of overhead.</p><p>Chaos Mesh 1.0 has changed all this. Now, we can use IOChaos to inject faults to a filesystem at runtime. This simplifies the process and greatly reduces system overhead. This blog post introduces how we implement the IOChaos experiment without using a sidecar.</p><h2>I/O fault injection</h2><p>To simulate I/O faults at runtime, we need to inject faults into a filesystem after the program starts <a href="https://man7.org/linux/man-pages/man2/syscall.2.html">system calls</a> (such as reads and writes) but before the call requests arrive at the target filesystem. We can do that in one of two ways:</p><ul><li>Use Berkeley Packet Filter (BPF); however, it <a href="https://github.com/iovisor/bcc/issues/2336">cannot be used to inject delay</a>.</li><li>Add a filesystem layer called ChaosFS before the target filesystem. ChaosFS uses the target filesystem as the backend and receives requests from the operating system. The entire call link is <strong>target program syscall</strong> -&gt; <strong>Linux kernel</strong> -&gt; <strong>ChaosFS</strong> -&gt; <strong>target filesystem</strong>. Because ChaosFS is customizable, we can inject delays and errors as we want. Therefore, ChaosFS is our choice.</li></ul><p>But ChaosFS has several problems:</p><ul><li>If ChaosFS reads and writes files in the target filesystem, we need to <a href="https://man7.org/linux/man-pages/man2/mount.2.html">mount</a> ChaosFS to a different path than the target path specified in the Pod configuration. ChaosFS <strong>cannot</strong> be mounted to the path of the target directory.</li><li>We need to mount ChaosFS <strong>before</strong> the target program starts running. This is because the newly-mounted ChaosFS takes effect only on files that are newly opened by the program in the target filesystem.</li><li>We need to mount ChaosFS to the target containter&#x27;s <code>mnt</code> namespace. For details, see <a href="https://man7.org/linux/man-pages/man7/mount_namespaces.7.html">mount_namespaces(7) ‚Äî Linux manual page</a>.</li></ul><p>Before Chaos Mesh 1.0, we used the <a href="https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/">mutating admission webhook</a> to implement IOChaos. This technique addressed the three problems lists above and allowed us to:</p><ul><li>Run scripts in the target container. This action changed the target directory of the ChaosFS&#x27;s backend filesystem (for example, from <code>/mnt/a</code> to <code>/mnt/a_bak</code>) so that we could mount ChaosFS to the target path (<code>/mnt/a</code>).
Modify the command that starts the Pod. For example, we could modify the original command <code>/app</code> to <code>/waitfs.sh /app</code>.</li><li>The <code>waitfs.sh</code> script kept checking whether the filesystem was successfully mounted. If it was mounted, <code>/app</code> was started.</li><li>Add a new container in the Pod to run ChaosFS. This container needed to share a volume with the target container (for example, <code>/mnt</code>), and then we mounted this volume to the target directory (for example, <code>/mnt/a</code>). We also properly enabled <a href="https://kubernetes.io/docs/concepts/storage/volumes/#mount-propagation">mount propagation</a> for this volume&#x27;s mount to penetrate the share to host and then penetrate slave to the target.</li></ul><p>These three approaches allowed us to inject I/O faults while the program was running. However, the injection was far from convenient:</p><ul><li>We could only inject faults into a volume subdirectory, not into the entire volume. The workaround was to replace <code>mv</code> (rename) with <code>mount move</code> to move the mount point of the target volume.</li><li>We had to explicitly write commands in the Pod rather than implicitly use the image commands. Otherwise, the <code>/waitfs.sh</code> script could not properly start the program after the filesystem was mounted.</li><li>The corresponding container needed to have a proper configuration for mount propagation. Due to potential privacy and security issues, we <strong>could not</strong> modify the configuration via the mutating admission webhook.</li><li>The injection configuration was troublesome. Worse still, we had to create a new Pod after the configuration was able to inject faults.</li><li>We could not withdraw ChaosFS while the program was running. Even if no fault or error was injected, the performance was greatly affected.</li></ul><h2>Inject I/O faults without the mutating admission webhook</h2><p>What about cracking these tough nuts without the mutating admission webhook? Let&#x27;s get back and think a bit about the reason why we used the mutating admission webhook to add a container in which ChaosFS runs. We do that to mount the filesystem to the target container.</p><p>In fact, there is another solution. Instead of adding containers to the Pod, we can first use the <code>setns</code> Linux system call to modify the namespace of the current process and then use the <code>mount</code> call to mount ChaosFS to the target container. Suppose that the filesystem to inject is <code>/mnt</code>. The new injection process is as follows:</p><ol><li>Use <code>setns</code> for the current process to enter the mnt namespace of the target container.</li><li>Execute <code>mount --move</code> to move <code>/mnt</code> to <code>/mnt_bak</code>.</li><li>Mount ChaosFS to <code>/mnt</code> and use <code>/mnt_bak</code> as the backend.</li></ol><p>After the process is finished, the target container will open, read, and write the files in <code>/mnt</code> through ChaosFS. In this way, delays or faults are injected much more easily. However, there are still two questions to answer:</p><ul><li>How do you handle the files that are already opened by the target process?</li><li>How do you recover the process given that we cannot unmount the filesystem when files are opened?</li></ul><h3>Dynamically replace file descriptors</h3><p><strong>ptrace solves both of the two questions above.</strong> We can use ptrace to replace the opened file descriptors (FD) at runtime and replace the current working directory (CWD) and mmap.</p><h4>Use ptrace to allow a tracee to run a binary program</h4><p><a href="https://man7.org/linux/man-pages/man2/ptrace.2.html">ptrace</a> is a powerful tool that makes the target process (tracee) to run any system call or binary program. For a tracee to run the program, ptrace modifies the RIP-pointed address to the target process and adds an <code>int3</code> instruction to trigger a breakpoint. When the binary program stops, we need to restore the registers and memory.</p><blockquote><p><strong>Note:</strong></p><p>In the <a href="https://en.wikipedia.org/wiki/X86_assembly_language">x86_64 architecture</a>, the RIP register (also called an instruction pointer) always points to the memory address at which the next directive is run.
To load the program into the target process memory spaces:</p></blockquote><ol><li>Use ptrace to call mmap in the target program to allocate the needed memory.</li><li>Write the binary program to the newly allocated memory and make the RIP register point to it.</li><li>After the binary program stops, call munmap to clean up the memory section.</li></ol><p>As a best practice, we often replace ptrace <code>POKE_TEXT</code> writes with <code>process_vm_writev</code> because if there is a huge amount of data to write, <code>process_vm_writev</code> performs more efficiently.</p><p>Using ptrace, we are able to make a process to replace its own FD. Now we only need a method to make that replacement happen. This method is the <code>dup2</code> system call.</p><h4>Use <code>dup2</code> to replace file descriptor</h4><p>The signature of the <code>dup2</code> function is <code>int dup2(int oldfd, int newfd);</code>. It is used to create a copy of the old FD (<code>oldfd</code>). This copy has an FD number of <code>newfd</code>. If <code>newfd</code> already corresponds to the FD of an opened file, the FD on the file that&#x27;s already opened is automatically closed.</p><p>For example, the current process opens <code>/var/run/__chaosfs__test__/a</code> whose FD is <code>1</code>. To replace this opened file with <code>/var/run/test/a</code>, this process performs the following operations:</p><ol><li>Uses the <code>fcntl</code> system call to get the <code>OFlags</code> (the parameter used by the <code>open</code> system call, such as <code>O_WRONLY</code>) of <code>/var/run/__chaosfs__test__/a</code>.</li><li>Uses the <code>Iseek</code> system call to get the current location of <code>seek</code>.</li><li>Uses the <code>open</code> system call to open <code>/var/run/test/a</code> using the same <code>OFlags</code>. Assume that the FD is <code>2</code>.</li><li>Uses <code>Iseek</code> to change the <code>seek</code> location of the newly opened FD <code>2</code>.</li><li>Uses <code>dup2(2, 1)</code> to replace the FD <code>1</code> of <code>/var/run/__chaosfs__test__/a</code> with the newly opened FD <code>2</code>.</li><li>Closes FD <code>2</code>.</li></ol><p>After the process is finished, FD <code>1</code> of the current process points to <code>/var/run/test/a</code>. So that we can inject faults, any subsequent operations on the target file go through the <a href="https://en.wikipedia.org/wiki/Filesystem_in_Userspace">Filesystem in Userspace</a> (FUSE). FUSE is a software interface for Unix and Unix-like computer operating systems that lets non-privileged users create their own file systems without editing kernel code.</p><h4>Write a program to make the target process replace its own file descriptor</h4><p>The combined functionality of ptrace and dup2 makes it possible for the tracer to make the tracee replace the opened FD by itself. Now, we need to write a binary program and make the target process run it:</p><blockquote><p><strong>Note:</strong></p><p>In the implementation above, we assume that:</p><ul><li>The threads of the target process are POSIX threads and share the opened files.</li><li>When the target process creates threads using the <code>clone</code> function, the <code>CLONE_FILES</code> parameter is passed.</li></ul><p>Therefore, Chaos Mesh only replaces the FD of the first thread in the thread group.</p></blockquote><ol><li>Write a piece of assembly code according to the two sections above and the usage of syscall directives. <a href="https://github.com/chaos-mesh/toda/blob/1d73871d8ab72b8d1eace55f5222b01957193531/src/replacer/fd_replacer.rs#L133">Here</a> is an example of the assembly code.</li><li>Use an assembler to translate the code into a binary program. We use <a href="https://github.com/CensoredUsername/dynasm-rs">dynasm-rs</a> as the assembler.</li><li>Use ptrace to make the target process run this program.
When the program runs, the FD is replaced at runtime.</li></ol><h3>Overall fault injection process</h3><p>The following diagram illustrates the overall I/O fault injection process:</p><p><img src="/img/fault-injection-process.jpg" alt="Fault injection process"/></p><div style="margin:1rem 0;font-style:italic;text-align:center"> Fault injection process </div><p>In this diagram, each horizontal line corresponds to a thread that runs in the direction of the arrows. The <strong>Mount/Umount Filesystem</strong> and <strong>Replace FD</strong> tasks are carefully arranged in sequence. Given the process above, this arrangement makes a lot of sense.</p><h2>What&#x27;s next</h2><p>I&#x27;ve discussed how we implement fault injection to simulate I/O faults at runtime (see <a href="https://github.com/chaos-mesh/toda">chaos-mesh/toda</a>). However, the current implementation is far from perfect:</p><ul><li>Generation numbers are not supported.</li><li>ioctl is not supported.</li><li>Chaos Mesh does not immediately determine whether a filesystem is successfully mounted. It does so only after one second.</li></ul><p>If you are interested in Chaos Mesh and would like to help us improve it, you&#x27;re welcome to join <a href="https://slack.cncf.io/">our Slack channel</a> or submit your pull requests or issues to our <a href="https://github.com/chaos-mesh/chaos-mesh">GitHub repository</a>.</p><p>This is the first post in a series on Chaos Mesh implementation. If you want to see how other types of fault injection are implemented, stay tuned.</p>]]></content>
        <author>
            <name>Keao Yang</name>
            <uri>https://github.com/YangKeao</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[How a Top Game Company Uses Chaos Engineering to Improve Testing]]></title>
        <id>/how-a-top-game-company-uses-chaos-engineering-to-improve-testing</id>
        <link href="https://chaos-mesh.org/blog/how-a-top-game-company-uses-chaos-engineering-to-improve-testing"/>
        <updated>2020-11-26T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[How-a-Top-Game-Company-Uses-Chaos-Engineering-to-Improve-Testing]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/fuxi-case-banner.jpg" alt="How-a-Top-Game-Company-Uses-Chaos-Engineering-to-Improve-Testing"/></p><p>NetEase Fuxi AI Lab is China‚Äôs first professional game AI research institution. Researchers use our Kubernetes-based Danlu platform for algorithm development, training and tuning, and online publishing. Thanks to the integration with Kubernetes, our platform is much more efficient. However, due to Kubernetes- and microservices-related issues, we are constantly testing and improving our platform to make it more stable.</p><p>In this article, I‚Äôll discuss one of our most valuable testing tools, <a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a>. Chaos Mesh is an open-source Chaos Engineering tool that provides a wide range of fault injections and excellent fault monitoring through its Dashboard.</p><h2>Why Chaos Mesh</h2><p>We started our search for a Chaos Engineering tool in 2018. We were looking for a tool with:</p><ul><li><p>Cloud-native support. Kubernetes is practically the de facto standard for service orchestration and scheduling, and the application runtime has been fully standardized. For applications that run entirely on K8s, cloud-native support is a must for any tools that go with them.</p></li><li><p>Sufficient fault injection types. For stateful services, network failure simulation is particularly important. The platform must be able to simulate failures at different levels, such as Pods, network, and I/O.</p></li><li><p>Good observability. Knowing when a fault is injected and when it can be recovered is vital for us to tell whether there is an abnormality in the application.</p></li><li><p>Active community support. We want to use an open-source project that is thoroughly tested and consistently maintained. That‚Äôs why we value sustained and timely community support.</p></li><li><p>No intrusion on existing applications, with no domain knowledge required.</p></li><li><p>Actual use cases for us to evaluate and build upon.</p></li></ul><p>In 2019, when Chaos Mesh, a Chaos Engineering platform for Kubernetes was open-sourced, we found the tool we were looking for. It was still in its early stage; however, we were immediately struck with the richness of fault types it supported. This was a big advantage over other chaos engineering tools, because, to a certain degree, it determines the number of issues that we can locate in the system. We instantly realized that Chaos Mesh met our expectations in almost every way.</p><p><img src="/img/chaos-mesh-architecture.png" alt="Chaos Mesh architecture"/></p><h2>Our journey with Chaos Mesh</h2><p>Chaos Mesh has helped us find several important bugs. For example, it detected a brain-split issue in <a href="https://www.rabbitmq.com/">rabbitMQ</a>, the open-source message-queueing software for Danlu. According to <a href="https://en.wikipedia.org/wiki/Split-brain">Wikipedia</a>, ‚Äúa split-brain condition indicates data or availability inconsistencies originating from the maintenance of two separate data sets with overlap in scope.‚Äù When a rabbitMQ cluster has a brain split error, there will be data write conflicts or errors, which cause more serious problems such as data inconsistencies in the messaging service. As shown in our architecture below, when brain split happens, consumers do not function normally and keep reporting server exceptions.</p><p><img src="/img/architecture-of-a-rabbitmq-cluster.png" alt="Architecture of a RabbitMQ cluster"/></p><p>With Chaos Mesh, we could stably reproduce this issue by injecting <code>pod-kill</code> faults into our container instances cloud.</p><p>Chaos Mesh also found several other issues including a startup failure, a join failure for crashed broker clusters, a heartbeat timeout, and a connection channel shutdown. Over time, our development team fixed these issues and greatly improved the stability of the Danlu platform.</p><h2>A fast-growing project</h2><p>Chaos Mesh is constantly updated and improved. When we first adopted it, it hadn‚Äôt even reached a stable version. It didn‚Äôt have a debugging or log collection tool, and the Dashboard component only applied to TiDB. The only way we could use Chaos Mesh to test other applications was to execute the YAML configuration file via <code>kubectl apply</code>.</p><p><a href="https://chaos-mesh.org/blog/chaos-mesh-1.0-chaos-engineering-on-kubernetes-made-easier">Chaos Mesh 1.0</a> fixed or improved most of these limitations. It offers more fine-grained and powerful chaos support, a generally-available Chaos Dashboard, enhanced observability, and more accurate chaos scope control. These are all driven by an open, collaborative, and vibrant community.</p><p><img src="/img/chaos-dashboard.gif" alt="Chaos Dashboard is now generally available"/></p><h2>Looking forward</h2><p>It‚Äôs amazing to see how much Chaos Mesh has grown and how much traction it‚Äôs gaining. We‚Äôre also happy with what we have achieved with it.</p><p>However, Chaos Engineering is a big area to work on. In the future, we‚Äôd like to see the following features:</p><ul><li><p>Atomic fault injection</p></li><li><p>Unattended fault inject that combines customized fault types with standardized methods to validate experimental objects</p></li><li><p>Standard test cases for general components such as MySQL, Redis, and Kafka</p></li></ul><p>We‚Äôve discussed these features with those who maintain Chaos Mesh, and they said these features are on the Chaos Mesh 2.0 roadmap.</p><p>If you are interested, join the Chaos Mesh community via <a href="https://slack.cncf.io/">Slack</a> (#project-chaos-mesh) or <a href="https://github.com/chaos-mesh/chaos-mesh">GitHub</a>.</p>]]></content>
        <author>
            <name>Hui Zhang @ Fuxi Lab, NetEase</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chaos Engineering - Breaking things Intentionally]]></title>
        <id>/chaos-engineering-breaking-things-intentionally</id>
        <link href="https://chaos-mesh.org/blog/chaos-engineering-breaking-things-intentionally"/>
        <updated>2020-10-30T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos-Engineering-Breaking-things-Intentionally]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-engineering2.png" alt="Chaos-Engineering-Breaking-things-Intentionally"/></p><p>‚ÄúNecessity is the mother of invention‚Äù; similarly, Netflix is not only a platform for online media streaming. Netflix gave birth to Chaos engineering because of their necessity.</p><p>In 2008, Netflix <a href="https://about.netflix.com/en/news/completing-the-netflix-cloud-migration">experienced a major database corruption</a>. They couldn&#x27;t deliver DVDs for three days. This encouraged Netflix engineers to think about their monolithic architecture‚Äôs migration to a distributed cloud-based architecture.</p><p>The new distributed architecture of Netflix composed of hundreds of microservices. Migration to distributed architecture solved their single point failure problem, but it gave rise to many other complexities requiring a more reliable and fault-tolerant system. At this point, Netflix engineers came up with an innovative idea to test the system‚Äôs fault tolerance without impacting customer service.</p><p>They created <a href="https://github.com/Netflix/chaosmonkey">Chaos Monkey</a>: a tool that causes random failures at different places with different intervals of time. With the development of Chaos Monkey, a new discipline arises: Chaos Engineering.</p><p>‚ÄúChaos Engineering is the discipline of experimenting on a system in order to build confidence in the system‚Äôs capability to withstand turbulent conditions in production.‚Äù - <a href="https://principlesofchaos.org/">Principle of Chaos</a></p><p>Chaos Engineering is an approach for learning how your system behaves by applying a discipline of empirical exploration. Just as scientists conduct experiments to study physical and social phenomena, Chaos Engineering uses experiments to learn about a particular system - the systems&#x27; reliability, stability, and capability to survive in unexpected or unstable conditions.</p><p>When we have a large-scale distributed system, failures could be caused by a number of factors like application failure, infrastructure failure, dependency failure, network failure, and many more. These failures could not be all covered by traditional methods such as integration testing or unit testing, which makes Chaos Engineering a necessity:</p><ul><li>To improve resiliency of the system</li><li>To expose hidden threats and vulnerability of the system</li><li>To figure out system weaknesses before they cause any failure in production</li></ul><p>Lots of people think that they are not as big compared to Netflix and other tech giants; nor do they have any databases or systems of that scale.</p><p>They are probably right, but over the period, Chaos engineering has evolved so much that it‚Äôs no longer limited to digital companies like Netflix. To ensure consistent performance and constant availability of their systems, more and more companies from different industries are implementing chaos experiments.</p><h2>Chaos-Mesh</h2><p>To test the resiliency and reliability of <a href="https://pingcap.com/products/tidb">TiDB</a>, engineers at <a href="https://pingcap.com/">PingCAP</a> came up with a fantastic tool for Chaos testing called <a href="https://chaos-mesh.org/">Chaos Mesh</a>, a cloud-native Chaos Engineering platform that orchestrates chaos on Kubernetes environments.
Chaos Mesh takes into account the possible faults of a distributed system, covering the pod, the network, system I/O, and the kernel.</p><p>Chaos Mesh provides many fault injection methods:</p><ul><li><strong>clock-skew:</strong> Simulates clock skew</li><li><strong>container-kill:</strong> Simulates the container being killed</li><li><strong>cpu-burn:</strong> Simulates CPU pressure</li><li><strong>io-attribution-override:</strong> Simulates file exceptions</li><li><strong>io-fault:</strong> Simulates file system I/O errors</li><li><strong>io-latency:</strong> Simulates file system I/O latency</li><li><strong>kernel-injection:</strong> Simulates kernel failures</li><li><strong>memory-burn:</strong> Simulates memory pressure</li><li><strong>network-corrupt:</strong> Simulates network packet corruption</li><li><strong>network-duplication:</strong> Simulates network packet duplication</li><li><strong>network-latency:</strong> Simulate network latency</li><li><strong>network-loss:</strong> Simulates network loss</li><li><strong>network-partition:</strong> Simulates network partition</li><li><strong>pod-failure:</strong> Simulates continuous unavailability of Kubernetes Pods</li><li><strong>pod-kill:</strong> Simulates the Kubernetes Pod being killed</li></ul><p>Chaos Mesh mainly focuses on the simplicity of how all chaos tests are done quickly and easily understandable to anyone using it.</p><p>The recent <a href="https://chaos-mesh.org/blog/chaos-mesh-1.0-chaos-engineering-on-kubernetes-made-easier/">1.0 release</a> provides the general availability of Chaos Dashboard, which Chaos simplifies the complexities of chaos experiment. With a few mouse clicks, you can define the Chaos experiment&#x27;s scope, specify the type of chaos injection, define scheduling rules, and observe the chaos experiment results- all in the dashboard of Chaos Mesh.</p><p>In case you want to try Chaos Mesh in your browser, checkout <a href="https://chaos-mesh.org/interactive-tutorial">Katakoda interactive tutorial</a>, where you can get your hands on Chaos Mesh without even deploying it. To understand the design principles and how Chaos Mesh works, read <a href="https://chaos-mesh.org/blog/chaos_mesh_your_chaos_engineering_solution">this blog</a> by the project&#x27;s maintainer, <a href="https://www.linkedin.com/in/cwen-yin-81985318b/">Cwen Yin</a>.</p><h2>Join the community</h2><p>Anyone who wants to explore the area of chaos engineering or Chaos Mesh are welcomed to join the Chaos Mesh community. Being a member of the Chaos Mesh community, I would like to say it is a lovely community where project maintainers love to engage and hear your views and suggestions for the improvement of the project and the community.</p><p>To join and learn more about Chaos Mesh, find the #project-chaos-mesh channel in <a href="https://slack.cncf.io/">CNCF slack workspace</a>.</p>]]></content>
        <author>
            <name>Manish Dangi</name>
            <uri>https://www.linkedin.com/in/manishdangi/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chaos Mesh X Hacktoberfest 2020 - An Invitation to Open Source]]></title>
        <id>/chaos-mesh-x-hacktoberfest-2020</id>
        <link href="https://chaos-mesh.org/blog/chaos-mesh-x-hacktoberfest-2020"/>
        <updated>2020-10-14T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos-Mesh-X-Hacktoberfest-An-Invitation-to-Open-Source]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-x-hacktoberfest.jpg" alt="Chaos-Mesh-X-Hacktoberfest-An-Invitation-to-Open-Source"/></p><p><a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a> is proud to be in <a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest 2020</a>!</p><p>Hosted by DigitalOcean, Intel and DEV, Hacktoberfest is an open source celebration open to everyone in our global community. This month-long (Oct 1 - Oct 31) event encourages everyone to help drive the growth of open source and make positive contributions to an ever-growing community, whether you‚Äôre an experienced developer or open-source newbie learning to code. As long as you submit 4 PRs before Oct 31, you are eligible to claim a limit edition T-shirt (70000 in total on a first-come-first-served basis)!</p><p><img src="/img/hacktoberfest-shirt.png" alt="Hacktoberfest T-shirt"/></p><h2>Open source is the spirit</h2><p>Chaos Mesh has always been a dedicated and firm advocate of open source from day 1. Within only 10 months since it was open-sourced on December 31st, 2019, Chaos Mesh has received around 2.5k GitHub stars, with 59 contributors from multiple organizations. And it was accepted as a <a href="https://www.cncf.io/sandbox-projects/">CNCF sandbox project</a> in July 2020. The amazing growth of the project as well as the community could not have been possible without our shared commitment to the open-source community and spirit.</p><p>We hereby invite you to be part of us, starting from our handpicked issues with proper mentoring and assistance along your journey, which we hope you will find rewarding, inspiring, and most of all, fun.</p><h2>How can you participate</h2><p>So we are all set up for you in Hacktoberfest - labeled <a href="https://github.com/chaos-mesh/chaos-mesh/issues?q=is%3Aissue+is%3Aopen+label%3AHacktoberfest">suitable issues</a> with ‚ÄúHacktoberfest‚Äù, and updated the <a href="https://github.com/chaos-mesh/chaos-mesh/blob/master/CONTRIBUTING.md">Contributing Guide</a>.</p><p>How can you participate? It could not be easier with the following steps:</p><ol><li><p>Sign up for <a href="https://hacktoberfest.digitalocean.com/login">Hacktoberfest</a> using your GitHub account between Oct 1 and Oct 31.</p></li><li><p>Pick up an issue. Note that the issues are still being updated, but you don‚Äôt have to be limited to issues with the Hacktoberfest label, which only serve as a starting point.</p></li><li><p>Start coding and submit your PRs. Again the PR does not need to be corresponding to the labeled issue.</p></li><li><p>Our maintainers review your PRs. Once you successfully merged, or have gained approval for 4 or more of them, the PRs will be automatically counted on the Hacktoberfest end, and you will be eligible to claim your SWAG.</p><p><img src="/img/PR-count.png" alt="PR count"/></p></li></ol><p><strong>Note:</strong> If your PRs are merged or approved but you haven‚Äôt seen the number reflected on Hacktoberfest, comment under your PR.</p><h2>Strive for quality, learning, and no spammy</h2><p>In the spirit of open source and Hacktoberfest, we welcome all contributions and honor only valid PRs. However, we would not encourage or tolerate spammy contributions, which would not only cause waste to our maintainer‚Äôs time but also hurt the feelings and the integrity of the entire open source community. Spammy PRs will be labeled as &quot;invalid&quot; or &quot;spam&quot;, and will be closed as invalid.</p><p>Happy hacking! But don‚Äôt hack alone. Join #project-chaos-mesh in the <a href="https://slack.cncf.io/">CNCF Slack</a> to share your experience, provide your feedback on your experience, or let us help with any problem you have.</p>]]></content>
        <author>
            <name>Chaos Mesh Community</name>
            <uri>https://github.com/chaos-mesh</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chaos Mesh 1.0: Chaos Engineering on Kubernetes Made Easier]]></title>
        <id>/chaos-mesh-1.0-chaos-engineering-on-kubernetes-made-easier</id>
        <link href="https://chaos-mesh.org/blog/chaos-mesh-1.0-chaos-engineering-on-kubernetes-made-easier"/>
        <updated>2020-09-25T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos-Mesh-1.0 - Chaos-Engineering-on-Kubernetes-Made-Easier]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-1.0.png" alt="Chaos-Mesh-1.0 - Chaos-Engineering-on-Kubernetes-Made-Easier"/></p><p>Today, we are proud to announce the general availability of Chaos Mesh 1.0, following its entry into CNCF as a <a href="https://pingcap.com/blog/announcing-chaos-mesh-as-a-cncf-sandbox-project">sandbox project</a> in July, 2020.</p><p>Chaos Mesh 1.0 is a major milestone in the project‚Äôs development. After 10 months of effort within the open-source community, Chaos Mesh is now ready in terms of functionality, scalability, and ease of use. Here are some highlights.</p><h2>Powerful chaos support</h2><p><a href="https://chaos-mesh.org">Chaos Mesh</a> originated in the testing framework of <a href="https://pingcap.com/products/tidb">TiDB</a>, a distributed database, so it takes into account the possible faults of a distributed system. Chaos Mesh provides comprehensive and fine-grained fault types, covering the Pod, the network, system I/O, and the kernel. Chaos experiments are defined in YAML, which is fast and easy to use.</p><p>Chaos Mesh 1.0 supports the following fault types:</p><ul><li>clock-skew: Simulates clock skew</li><li>container-kill: Simulates the container being killed</li><li>cpu-burn: Simulates CPU pressure</li><li>io-attribution-override: Simulates file exceptions</li><li>io-fault: Simulates file system I/O errors</li><li>io-latency: Simulates file system I/O latency</li><li>kernel-injection: Simulates kernel failures</li><li>memory-burn: Simulates memory pressure</li><li>network-corrupt: Simulates network packet corruption</li><li>network-duplication: Simulates network packet duplication</li><li>network-latency: Simulate network latency</li><li>network-loss: Simulates network loss</li><li>network-partition: Simulates network partition</li><li>pod-failure: Simulates continuous unavailability of Kubernetes Pods</li><li>pod-kill: Simulates the Kubernetes Pod being killed</li></ul><h2>Visual chaos orchestration</h2><p>The Chaos Dashboard component is a one-stop web interface for Chaos Mesh users to orchestrate chaos experiments. Previously, Chaos Dashboard was only available for testing TiDB. With Chaos Mesh 1.0, it is available to everyone. Chaos Dashboard greatly simplifies the complexity of chaos experiments. With only a few mouse clicks, you can define the scope of the chaos experiment, specify the type of chaos injection, define scheduling rules, and observe the results of the chaos experiment‚Äîall in the same web interface.</p><p><img src="/img/chaos-dashboard.gif" alt="Chaos Dashboard"/></p><h2>Grafana plug-in for enhanced observability</h2><p>To further improve the observability of chaos experiments, Chaos Mesh 1.0 includes a Grafana plug-in to allow you to directly display real-time chaos experiment information on your application monitoring panel. Currently, the chaos experiment information is displayed as annotations. This way, you can simultaneously observe the running status of the application and the current chaos experiment information.</p><p><img src="/img/chaos-status.png" alt="Chaos status and application status on Grafana"/></p><h2>Safe and controllable chaos</h2><p>When we conduct chaos experiments, it is vital that we keep strict control over the chaos scope or ‚Äúblast radius.‚Äù Chaos Mesh 1.0 not only provides a wealth of selectors to accurately control the scope of the experiment, but it also enables you to set protected Namespaces to protect important applications. You can also use Namespace permissions to limit the scope of Chaos Mesh to a specific Namespace. Together, these features make chaos experiments with Chaos Mesh safe and controllable.</p><h2>Try it out now</h2><p>You can quickly deploy Chaos Mesh in your Kubernetes environment through the <code>install.sh</code> script or the Helm tool. For specific installation steps, please refer to the <a href="https://chaos-mesh.org/docs/1.2.4/user_guides/installation">Chaos Mesh Getting Started</a> document. In addition, thanks to the <a href="https://chaos-mesh.org/interactive-tutorial">Katakoda interactive tutorial</a>, you can also quickly get your hands on Chaos Mesh without having to deploy it.</p><p>If you haven‚Äôt upgraded to 1.0 GA, please refer to the <a href="https://github.com/chaos-mesh/chaos-mesh/releases/tag/v1.0.0">1.0 Release Notes</a> for the changes and upgrade guidelines.</p><h2>Thanks</h2><p>Thanks to all our Chaos Mesh <a href="https://github.com/chaos-mesh/chaos-mesh/graphs/contributors">contributors</a>!</p><p>If you are interested in Chaos Mesh, you‚Äôre welcome to join us by submitting issues, or contributing code, documentation, or articles. We look forward to your participation and feedback!</p>]]></content>
        <author>
            <name>Chaos Mesh Maintainers</name>
            <uri>https://github.com/chaos-mesh</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[chaos-mesh-action: Integrate Chaos Engineering into Your CI]]></title>
        <id>/chaos-mesh-action-integrate-chaos-engineering-into-your-ci</id>
        <link href="https://chaos-mesh.org/blog/chaos-mesh-action-integrate-chaos-engineering-into-your-ci"/>
        <updated>2020-09-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[chaos-mesh-action - Integrate Chaos Engineering into Your CI]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-action.png" alt="chaos-mesh-action - Integrate Chaos Engineering into Your CI"/></p><p><a href="https://chaos-mesh.org">Chaos Mesh</a> is a cloud-native chaos testing platform that orchestrates chaos in Kubernetes environments. While it‚Äôs well received in the community with its rich fault injection types and easy-to-use dashboard, it was difficult to use Chaos Mesh with end-to-end testing or the continuous integration (CI) process. As a result, problems introduced during system development could not be discovered before the release.</p><p>In this article, I will share how we use chaos-mesh-action, a GitHub action to integrate Chaos Mesh into the CI process.</p><p>chaos-mesh-action is available on <a href="https://github.com/marketplace/actions/chaos-mesh">GitHub market</a>, and the source code is on <a href="https://github.com/chaos-mesh/chaos-mesh-action">GitHub</a>.</p><h2>Design of chaos-mesh-action</h2><p><a href="https://docs.github.com/en/actions">GitHub Action</a> is a CI/CD feature natively supported by GitHub, through which we can easily build automated and customized software development workflows in the GitHub repository.</p><p>Combined with GitHub actions, Chaos Mesh can be more easily integrated into the daily development and testing of the system, thus guaranteeing that each code submission on GitHub is bug-free and won‚Äôt damage existing code. The following figure shows chaos-mesh-action integrated into the CI workflow:</p><p><img src="/img/chaos-mesh-action-integrate-in-the-ci-workflow.png" alt="chaos-mesh-action integration in the CI workflow"/></p><h2>Using chaos-mesh-action in GitHub workflow</h2><p><a href="https://github.com/marketplace/actions/chaos-mesh">chaos-mesh-action</a> works in Github workflows. A GitHub workflow is a configurable automated process that you can set up in your repository to build, test, package, release, or deploy any GitHub project. To integrate Chaos Mesh in your CI, do the following:</p><ol><li>Design a workflow.</li><li>Create a workflow.</li><li>Run the workflow.</li></ol><h3>Design a workflow</h3><p>Before you design a workflow, you must consider the following issues:</p><ul><li>What functions are we going to test in this workflow?</li><li>What types of faults will we inject?</li><li>How do we verify the correctness of the system?</li></ul><p>As an example, let‚Äôs design a simple test workflow that includes the following steps:</p><ol><li>Create two Pods in a Kubernetes cluster.</li><li>Ping one pod from the other.</li><li>Use Chaos Mesh to inject network delay chaos and test whether the ping command is affected.</li></ol><h3>Create the workflow</h3><p>After you design the workflow, the next step is to create it.</p><ol><li>Navigate to the GitHub repository that contains the software you want to test.</li><li>To start creating a workflow, click <strong>Actions</strong>, and then click the <strong>New workflow</strong> button:</li></ol><p><img src="/img/creating-a-workflow.png" alt="Creating a workflow"/></p><p>A workflow is essentially the configuration of jobs that take place sequentially and automatically. Note that the jobs are configured in a single file. For better illustration, we split the script into different job groups as shown below:</p><ul><li><p>Set the workflow name and trigger rules.</p><p>This job names the workflow &quot;Chaos.‚Äù When the code is pushed to the master branch or a pull request is submitted to the master branch, this workflow is triggered.</p><pre><code class="language-yaml">name: Chaos

on:
  push:
    branches:
      - master
  pull_request:
    branches:
      - master
</code></pre></li><li><p>Install the CI-related environment.</p><p>This configuration specifies the operating system (Ubuntu), and that it uses <a href="https://github.com/marketplace/actions/kind-cluster">helm/kind-action</a> to create a Kind cluster. Then, it outputs related information about the cluster. Finally, it checks out the GitHub repository for the workflow to access.</p><pre><code class="language-yaml">jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Creating kind cluster
        uses: helm/kind-action@v1.0.0-rc.1

      - name: Print cluster information
        run: |
          kubectl config view
          kubectl cluster-info
          kubectl get nodes
          kubectl get pods -n kube-system
          helm version
          kubectl version

      - uses: actions/checkout@v2
</code></pre></li><li><p>Deploy the application.</p><p>In our example, this job deploys an application that creates two Kubernetes Pods.</p><pre><code class="language-yaml">- name: Deploy an application
     run: |
       kubectl apply -f https://raw.githubusercontent.com/chaos-mesh/apps/master/ping/busybox-statefulset.yaml
</code></pre></li><li><p>Inject chaos with chaos-mesh-action.</p><pre><code class="language-yaml">- name: Run chaos mesh action
    uses: chaos-mesh/chaos-mesh-action@v0.5
    env:
      CHAOS_MESH_VERSION: v1.0.0
      CFG_BASE64: YXBpVmVyc2lvbjogY2hhb3MtbWVzaC5vcmcvdjFhbHBoYTEKa2luZDogTmV0d29ya0NoYW9zCm1ldGFkYXRhOgogIG5hbWU6IG5ldHdvcmstZGVsYXkKICBuYW1lc3BhY2U6IGJ1c3lib3gKc3BlYzoKICBhY3Rpb246IGRlbGF5ICMgdGhlIHNwZWNpZmljIGNoYW9zIGFjdGlvbiB0byBpbmplY3QKICBtb2RlOiBhbGwKICBzZWxlY3RvcjoKICAgIHBvZHM6CiAgICAgIGJ1c3lib3g6CiAgICAgICAgLSBidXN5Ym94LTAKICBkZWxheToKICAgIGxhdGVuY3k6ICIxMG1zIgogIGR1cmF0aW9uOiAiNXMiCiAgc2NoZWR1bGVyOgogICAgY3JvbjogIkBldmVyeSAxMHMiCiAgZGlyZWN0aW9uOiB0bwogIHRhcmdldDoKICAgIHNlbGVjdG9yOgogICAgICBwb2RzOgogICAgICAgIGJ1c3lib3g6CiAgICAgICAgICAtIGJ1c3lib3gtMQogICAgbW9kZTogYWxsCg==
</code></pre><p>With chaos-mesh-action, the installation of Chaos Mesh and the injection of chaos complete automatically. You simply need to prepare the chaos configuration that you intend to use to get its Base64 representation. Here, we want to inject network delay chaos into the Pods, so we use the original chaos configuration as follows:</p><pre><code class="language-yaml">apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: network-delay
  namespace: busybox
spec:
  action: delay # the specific chaos action to inject
  mode: all
  selector:
    pods:
      busybox:
        - busybox-0
  delay:
    latency: &#x27;10ms&#x27;
  duration: &#x27;5s&#x27;
  scheduler:
    cron: &#x27;@every 10s&#x27;
  direction: to
  target:
    selector:
      pods:
        busybox:
          - busybox-1
    mode: all
</code></pre><p>You can obtain the Base64 value of the above chaos configuration file using the following command:</p><pre><code class="language-shell">$ base64 chaos.yaml
</code></pre></li><li><p>Verify the system correctness.</p><p>In this job, the workflow pings one Pod from the other and observes the changes in network delay.</p><pre><code class="language-yaml">- name: Verify
     run: |
       echo &quot;do some verification&quot;
       kubectl exec busybox-0 -it -n busybox -- ping -c 30 busybox-1.busybox.busybox.svc
</code></pre></li></ul><h3>Run the workflow</h3><p>Now that the workflow is configured, we can trigger it by submitting a pull request to the master branch. When the workflow completes, the verification job outputs of the results that look similar to the following:</p><pre><code class="language-shell">do some verification
Unable to use a TTY - input is not a terminal or the right kind of file
PING busybox-1.busybox.busybox.svc (10.244.0.6): 56 data bytes
64 bytes from 10.244.0.6: seq=0 ttl=63 time=0.069 ms
64 bytes from 10.244.0.6: seq=1 ttl=63 time=10.136 ms
64 bytes from 10.244.0.6: seq=2 ttl=63 time=10.192 ms
64 bytes from 10.244.0.6: seq=3 ttl=63 time=10.129 ms
64 bytes from 10.244.0.6: seq=4 ttl=63 time=10.120 ms
64 bytes from 10.244.0.6: seq=5 ttl=63 time=0.070 ms
64 bytes from 10.244.0.6: seq=6 ttl=63 time=0.073 ms
64 bytes from 10.244.0.6: seq=7 ttl=63 time=0.111 ms
64 bytes from 10.244.0.6: seq=8 ttl=63 time=0.070 ms
64 bytes from 10.244.0.6: seq=9 ttl=63 time=0.077 ms
‚Ä¶‚Ä¶
</code></pre><p>The output indicates a regular series of 10-millisecond delays that last about 5 seconds each. This is consistent with the chaos configuration we injected into chaos-mesh-action.</p><h2>Current status and next steps</h2><p>At present, we have applied chaos-mesh-action to the <a href="https://github.com/pingcap/tidb-operator">TiDB Operator</a> project. The workflow is injected with the Pod chaos to verify the restart function of the specified instances of the operator. The purpose is to ensure that tidb-operator can work normally when the pods of the operator are randomly deleted by the injected faults. You can view the <a href="https://github.com/pingcap/tidb-operator/actions?query=workflow%3Achaos">TiDB Operator page</a> for more details.</p><p>In the future, we plan to apply chaos-mesh-action to more tests to ensure the stability of TiDB and related components. You are welcome to create your own workflow using chaos-mesh-action.</p><p>If you find a bug or think something is missing, feel free to file an issue, open a pull request (PR), or join us on the <a href="https://slack.cncf.io/">#project-chaos-mesh</a> channel in the <a href="https://www.cncf.io/">CNCF</a> slack workspace.</p>]]></content>
        <author>
            <name>Xiang Wang</name>
            <uri>https://github.com/WangXiangUSTC</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Building an Automated Testing Framework Based on Chaos Mesh and Argo]]></title>
        <id>/building_automated_testing_framework</id>
        <link href="https://chaos-mesh.org/blog/building_automated_testing_framework"/>
        <updated>2020-08-14T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[TiPocket - Automated Testing Framework]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/automated_testing_framework.png" alt="TiPocket - Automated Testing Framework"/></p><p><a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a> is an open-source chaos engineering platform for Kubernetes. Although it provides rich capabilities to simulate abnormal system conditions, it still only solves a fraction of the Chaos Engineering puzzle. Besides fault injection, a full chaos engineering application consists of hypothesizing around defined steady states, running experiments in production, validating the system via test cases, and automating the testing.</p><p>This article describes how we use <a href="https://github.com/pingcap/tipocket">TiPocket</a>, an automated testing framework to build a full Chaos Engineering testing loop for TiDB, our distributed database.</p><h2>Why do we need TiPocket?</h2><p>Before we can put a distributed system like <a href="https://github.com/pingcap/tidb">TiDB</a> into production, we have to ensure that it is robust enough for day-to-day use. For this reason, several years ago we introduced Chaos Engineering into our testing framework. In our testing framework, we:</p><ol><li>Observe the normal metrics and develop our testing hypothesis.</li><li>Inject a list of failures into TiDB.</li><li>Run various test cases to verify TiDB in fault scenarios.</li><li>Monitor and collect test results for analysis and diagnosis.</li></ol><p>This sounds like a solid process, and we‚Äôve used it for years. However, as TiDB evolves, the testing scale multiplies. We have multiple fault scenarios, against which dozens of test cases run in the Kubernetes testing cluster. Even with Chaos Mesh helping to inject failures, the remaining work can still be demanding‚Äînot to mention the challenge of automating the pipeline to make the testing scalable and efficient.</p><p>This is why we built TiPocket, a fully-automated testing framework based on Kubernetes and Chaos Mesh. Currently, we mainly use it to test TiDB clusters. However, because of TiPocket‚Äôs Kubernetes-friendly design and extensible interface, you can use Kubernetes‚Äô create and delete logic to easily support other applications.</p><h2>How does it work</h2><p>Based on the above requirements, we need an automatic workflow that:</p><ul><li><a href="#injecting-chaos---chaos-mesh">Injects chaos</a></li><li><a href="#verifying-chaos-impacts-test-cases">Verifies the impact of that chaos</a></li><li><a href="#automating-the-chaos-pipeline---argo">Automates the chaos pipeline</a></li><li><a href="#visualizing-the-results-loki">Visualizes the results</a></li></ul><h3>Injecting chaos - Chaos Mesh</h3><p>Fault injection is the core chaos testing. In a distributed database, faults can happen anytime, anywhere‚Äîfrom node crashes, network partitions, and file system failures, to kernel panics. This is where Chaos Mesh comes in.</p><p>Currently, TiPocket supports the following types of fault injection:</p><ul><li><strong>Network</strong>: Simulates network partitions, random packet loss, disorder, duplication, or delay of links.</li><li><strong>Time skew</strong>: Simulates clock skew of the container to be tested.</li><li><strong>Kill</strong>: Kills the specified pod, either randomly in a cluster or within a component (TiDB, TiKV, or Placement Driver (PD)).</li><li><strong>I/O</strong>: Injects I/O delays in TiDB‚Äôs storage engine, TiKV, to identify I/O related issues.</li></ul><p>With fault injection handled, we need to think about verification. How do we make sure TiDB can survive these faults?</p><h2>Verifying chaos impacts: test cases</h2><p>To validate how TiDB withstands chaos, we implemented dozens of test cases in TiPocket, combined with a variety of inspection tools. To give you an overview of how TiPocket verifies TiDB in the event of failures, consider the following test cases. These cases focus on SQL execution, transaction consistency, and transaction isolation.</p><h3>Fuzz testing: SQLsmith</h3><p><a href="https://github.com/pingcap/tipocket/tree/master/pkg/go-sqlsmith">SQLsmith</a> is a tool that generates random SQL queries. TiPocket creates a TiDB cluster and a MySQL instance.. The random SQL generated by SQLsmith is executed on TiDB and MySQL, and various faults are injected into the TiDB cluster to test. In the end, execution results are compared. If we detect inconsistencies, there are potential issues with our system.</p><h3>Transaction consistency testing: Bank and Porcupine</h3><p><a href="https://github.com/pingcap/tipocket/tree/master/cmd/bank">Bank</a> is a classical test case that simulates the transfer process in a banking system. Under snapshot isolation, all transfers must ensure that the total amount of all accounts must be consistent at every moment, even in the face of system failures. If there are inconsistencies in the total amount, there are potential issues with our system.</p><p><a href="https://github.com/anishathalye/porcupine">Porcupine</a> is a linearizability checker in Go built to test the correctness of distributed systems. It takes a sequential specification as executable Go code, along with a concurrent history, and it determines whether the history is linearizable with respect to the sequential specification. In TiPocket, we use the <a href="https://github.com/pingcap/tipocket/tree/master/pkg/check/porcupine">Porcupine</a> checker in multiple test cases to check whether TiDB meets the linearizability constraint.</p><h3>Transaction Isolation testing: Elle</h3><p><a href="https://github.com/jepsen-io/elle">Elle</a> is an inspection tool that verifies a database‚Äôs transaction isolation level. TiPocket integrates <a href="https://github.com/pingcap/tipocket/tree/master/pkg/elle">go-elle</a>, the Go implementation of the Elle inspection tool, to verify TiDB‚Äôs isolation level.</p><p>These are just a few of the test cases TiPocket uses to verify TiDB‚Äôs accuracy and stability. For more test cases and verification methods, see our <a href="https://github.com/pingcap/tipocket">source code</a>.</p><h2>Automating the chaos pipeline - Argo</h2><p>Now that we have Chaos Mesh to inject faults, a TiDB cluster to test, and ways to validate TiDB, how can we automate the chaos testing pipeline? Two options come to mind: we could implement the scheduling functionality in TiPocket, or hand over the job to existing open-source tools. To make TiPocket more dedicated to the testing part of our workflow, we chose the open-source tools approach. This, plus our all-in-K8s design, lead us directly to <a href="https://github.com/argoproj/argo">Argo</a>.</p><p>Argo is a workflow engine designed for Kubernetes. It has been an open source product for a long time, and has received widespread attention and application.</p><p>Argo has abstracted several custom resource definitions (CRDs) for workflows. The most important ones include Workflow Template, Workflow, and Cron Workflow. Here is how Argo fits in TiPocket:</p><ul><li><strong>Workflow Template</strong> is a template defined in advance for each test task. Parameters can be passed in when the test is running.</li><li><strong>Workflow</strong> schedules multiple workflow templates in different orders, which form the tasks to be executed. Argo also lets you add conditions, loops, and directed acyclic graphs (DAGs) in the pipeline.</li><li><strong>Cron Workflow</strong> lets you schedule a workflow like a cron job. It is perfectly suitable for scenarios where you want to run test tasks for a long time.</li></ul><p>The sample workflow for our predefined bank test is shown below:</p><pre><code class="language-yml">spec:
  entrypoint: call-tipocket-bank
  arguments:
    parameters:
      - name: ns
        value: tipocket-bank
            - name: nemesis
        value: random_kill,kill_pd_leader_5min,partition_one,subcritical_skews,big_skews,shuffle-leader-scheduler,shuffle-region-scheduler,random-merge-scheduler
  templates:
    - name: call-tipocket-bank
      steps:
        - - name: call-wait-cluster
            templateRef:
              name: wait-cluster
              template: wait-cluster
        - - name: call-tipocket-bank
            templateRef:
              name: tipocket-bank
              template: tipocket-bank
</code></pre><p>In this example, we use the workflow template and nemesis parameters to define the specific failure to inject. You can reuse the template to define multiple workflows that suit different test cases. This allows you to add more customized failure injections in the flow.</p><p>Besides <a href="https://github.com/pingcap/tipocket/tree/master/argo/workflow">TiPocket‚Äôs</a> sample workflows and templates, the design also allows you to add your own failure injection flows. Handling complicated logics using codable workflows makes Argo developer-friendly and an ideal choice for our scenarios.</p><p>Now, our chaos experiment is running automatically. But if our results do not meet our expectations? How do we locate the problem? TiDB saves a variety of monitoring information, which makes log collecting essential for enabling observability in TiPocket.</p><h2>Visualizing the results: Loki</h2><p>In cloud-native systems, observability is very important. Generally speaking, you can achieve observability through <strong>metrics</strong>, <strong>logging</strong>, and <strong>tracing</strong>. TiPocket‚Äôs main test cases evaluate TiDB clusters, so metrics and logs are our default sources for locating issues.</p><p>On Kubernetes, Prometheus is the de-facto standard for metrics. However, there is no common way for log collection. Solutions such as <a href="https://en.wikipedia.org/wiki/Elasticsearch">Elasticsearch</a>, <a href="https://fluentbit.io/">Fluent Bit</a>, and <a href="https://www.elastic.co/kibana">Kibana</a> perform well, but they may cause system resource contention and high maintenance costs. We decided to use <a href="https://github.com/grafana/loki">Loki</a>, the Prometheus-like log aggregation system from <a href="https://grafana.com/">Grafana</a>.</p><p>Prometheus processes TiDB‚Äôs monitoring information. Prometheus and Loki have a similar labeling system, so we can easily combine Prometheus&#x27; monitoring indicators with the corresponding pod logs and use a similar query language. Grafana also supports the Loki dashboard, which means we can use Grafana to display monitoring indicators and logs at the same time. Grafana is the built-in monitoring component in TiDB, which Loki can reuse.</p><h2>Putting them all together - TiPocket</h2><p>Now, everything is ready. Here is a simplified diagram of TiPocket:</p><p><img src="/img/tipocket-architecture.png" alt="TiPocket Architecture"/></p><p>As you can see, the Argo workflow manages all chaos experiments and test cases. Generally, a complete test cycle involves the following steps:</p><ol><li>Argo creates a Cron Workflow, which defines the cluster to be tested, the faults to inject, the test case, and the duration of the task. If necessary, the Cron Workflow also lets you view case logs in real-time.</li></ol><p><img src="/img/argo-workflow.png" alt="Argo Workflow"/></p><ol><li>At a specified time, a separate TiPocket thread is started in the workflow, and the Cron Workflow is triggered. TiPocket sends TiDB-Operator the definition of the cluster to test. In turn, TiDB-Operator creates a target TiDB cluster. Meanwhile, Loki collects the related logs.</li><li>Chaos Mesh injects faults in the cluster.</li><li>Using the test cases mentioned above, the user validates the health of the system. Any test case failure leads to workflow failure in Argo, which triggers Alertmanager to send the result to the specified Slack channel. If the test cases complete normally, the cluster is cleared, and Argo stands by until the next test.</li></ol><p><img src="/img/alert_message.png" alt="Alert in Slack"/></p><p>This is the complete TiPocket workflow. .</p><h2>Join us</h2><p><a href="https://github.com/pingcap/chaos-mesh">Chaos Mesh</a> and <a href="https://github.com/pingcap/tipocket">TiPocket</a> are both in active iterations. We have donated Chaos Mesh to <a href="https://github.com/cncf/toc/pull/367">CNCF</a>, and we look forward to more community members joining us in building a complete Chaos Engineering ecosystem. If this sounds interesting to you, check out our <a href="https://chaos-mesh.org/">website</a>, or join #project-chaos-mesh in the <a href="hthttps://slack.cncf.io/">CNCF Slack</a>.</p>]]></content>
        <author>
            <name>Ben Ye, Chengwen Yin</name>
            <uri>https://github.com/chaos-mesh/chaos-mesh/blob/master/MAINTAINERS.md</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chaos Mesh Joins CNCF as a Sandbox Project]]></title>
        <id>/chaos-mesh-join-cncf-sandbox-project</id>
        <link href="https://chaos-mesh.org/blog/chaos-mesh-join-cncf-sandbox-project"/>
        <updated>2020-07-28T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos Mesh Join CNCF as Sandbox Project]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-mesh-cncf.png" alt="Chaos Mesh Join CNCF as Sandbox Project"/>
We‚Äôre thrilled to announce that <a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a> is now officially accepted as a CNCF Sandbox project. As maintainers of Chaos Mesh, we‚Äôd like to thank all the contributors and adopters. This would not be possible without your trust, support, and contributions.</p><p>Chaos Mesh is a powerful Chaos Engineering platform that orchestrates chaos experiments on Kubernetes environments. By covering comprehensive fault injection methods in Pod, network, file system, and even the kernel, we aim at providing a neutral, universal Chaos Engineering platform that enables cloud-native applications to be as resilient as they should be.</p><p><img src="/img/chaos-mesh.svg" alt="Architecture"/></p><p>Within only 7 months since it was open-sourced on December 31st, 2019, Chaos Mesh has already received 2000 GitHub stars, with 44 contributors from multiple organizations. As a young project, the adoption in production has been the key recognition and motivation that pushes us forward constantly. Here is a list of our adopters so far:</p><ul><li><a href="http://www.pingcap.com">PingCAP</a></li><li><a href="https://en.xiaopeng.com/">Xpeng Motor</a></li><li><a href="https://fuxi.163.com/en/about.html">NetEase Fuxi Lab</a></li><li><a href="http://juicefs.com/?hl=en">JuiceFS</a></li><li><a href="https://www.dailymotion.com/">Dailymotion</a></li><li><a href="https://about.meituan.com/en">Meituan-Dianping</a></li><li><a href="https://celo.org/">Celo</a></li></ul><p>Being a CNCF Sandbox project marks a major step forward for the project. It means that Chaos Mesh has become part of the great vendor-neutral cloud-native community. With the guidance and help from CNCF, Chaos Mesh will strive to develop a community with transparent, meritocracy-based governance for open communication and open collaboration, while driving the project forward, towards our ultimate goal of establishing the Chaos Engineering standards on Cloud.
Currently, Chaos Mesh is in active development for 1.0 GA. Going forward, we will be focusing on the following aspects:</p><ul><li>Lowering the bar of chaos engineering by improving Chaos Dashboard.</li><li>Extending chaos injection to application layers</li><li>Completing the full chaos engineering loop with status checking, reporting, and scenario defining, etc.</li></ul><p>If you are interested in the project, check out our <a href="https://chaos-mesh.org/">website</a>, join our <a href="https://slack.cncf.io/">Slack</a> discussions, or attend our <a href="https://docs.google.com/document/d/1H8IfmhIJiJ1ltg-XLjqR_P_RaMHUGrl1CzvHnKM_9Sc/edit">monthly meeting</a> to know more. Or better yet, become part of us.</p>]]></content>
        <author>
            <name>Chaos Mesh Authors</name>
            <uri>https://github.com/chaos-mesh</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Simulating Clock Skew in K8s Without Affecting Other Containers on the Node]]></title>
        <id>/simulating-clock-skew-in-k8s-without-affecting-other-containers-on-node</id>
        <link href="https://chaos-mesh.org/blog/simulating-clock-skew-in-k8s-without-affecting-other-containers-on-node"/>
        <updated>2020-04-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Clock synchronization in distributed system]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/clock-sync-chaos-engineering-k8s.jpg" alt="Clock synchronization in distributed system"/></p><p><a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh‚Ñ¢</a>, an easy-to-use, open-source, cloud-native chaos engineering platform for Kubernetes (K8s), has a new feature, TimeChaos, which simulates the <a href="https://en.wikipedia.org/wiki/Clock_skew#On_a_network">clock skew</a> phenomenon. Usually, when we modify clocks in a container, we want a <a href="https://learning.oreilly.com/library/view/chaos-engineering/9781491988459/ch07.html">minimized blast radius</a>, and we don&#x27;t want the change to affect the other containers on the node. In reality, however, implementing this can be harder than you think. How does Chaos Mesh solve this problem?</p><p>In this post, I&#x27;ll describe how we hacked through different approaches of clock skew and how TimeChaos in Chaos Mesh enables time to swing freely in containers.</p><h2>Simulating clock skew without affecting other containers on the node</h2><p>Clock skew refers to the time difference between clocks on nodes within a network. It might cause reliability problems in a distributed system, and it&#x27;s a concern for designers and developers of complex distributed systems. For example, in a distributed SQL database, it&#x27;s vital to maintain a synchronized local clock across nodes to achieve a consistent global snapshot and ensure the ACID properties for transactions.</p><p>Currently, there are well-recognized <a href="https://pingcap.com/blog/Time-in-Distributed-Systems/">solutions to synchronize clocks</a>, but without proper testing, you can never be sure that your implementation is solid.</p><p>Then how can we test global snapshot consistency in a distributed system? The answer is obvious: we can simulate clock skew to test whether distributed systems can keep a consistent global snapshot under abnormal clock conditions. Some testing tools support simulating clock skew in containers, but they have an impact on physical nodes.</p><p><a href="https://github.com/chaos-mesh/chaos-mesh/wiki/Time-Chaos">TimeChaos</a> is a tool that <strong>simulates clock skew in containers to test how it impacts your application without affecting the whole node</strong>. This way, we can precisely identify the potential consequences of clock skew and take measures accordingly.</p><h2>Various approaches for simulating clock skew we&#x27;ve explored</h2><p>Reviewing the existing choices, we know clearly that they cannot be applied to Chaos Mesh, which runs on Kubernetes. Two common ways of simulating clock skew--changing the node clock directly and using the Jepsen framework--change the time for all processes on the node. These are not acceptable solutions for us. In a Kubernetes container, if we inject a clock skew error that affects the entire node, other containers on the same node will be disturbed. Such a clumsy approach is not tolerable.</p><p>Then how are we supposed to tackle this problem? Well, the first thing that comes into our mind is finding solutions in the kernel using <a href="https://en.wikipedia.org/wiki/Berkeley_Packet_Filter">Berkeley Packet Filter</a> (BPF).</p><h3><code>LD_PRELOAD</code></h3><p><code>LD_PRELOAD</code> is a Linux environment variable that lets you define which dynamic link library is loaded before the program execution.</p><p>This variable has two advantages:</p><ul><li>We can call our own functions without being aware of the source code.</li><li>We can inject code into other programs to achieve specific purposes.</li></ul><p>For some languages that use applications to call the time function in glibc, such as Rust and C, using <code>LD_PRELOAD</code> is enough to simulate clock skew. But things are trickier for Golang. Because languages such as Golang directly parse virtual Dynamic Shared Object (<a href="http://man7.org/linux/man-pages/man7/vdso.7.html">vDSO</a>), a mechanism to speed up system calls. To obtain the time function address, we can&#x27;t simply use <code>LD_PRELOAD</code> to intercept the glic interface. Therefore, <code>LD_PRELOAD</code> is not our solution.</p><h3>Use BPF to modify the return value of <code>clock_gettime</code> system call</h3><p>We also tried to filter the task <a href="http://www.linfo.org/pid.html">process identification number</a> (PID) with BPF. This way, we could simulate clock skew on a specified process and modify the return value of the <code>clock_gettime</code> system call.</p><p>This seemed like a good idea, but we also encountered a problem: in most cases, vDSO speeds up <code>clock_gettime</code>, but <code>clock_gettime</code> doesn&#x27;t make a system call. This selection didn&#x27;t work, either. Oops.</p><p>Thankfully, we determined that if the system kernel version is 4.18 or later, and if we use the <a href="https://www.kernel.org/doc/html/latest/timers/hpet.html">HPET</a> clock, <code>clock_gettime()</code> gets time by making normal system calls instead of vDSO. We implemented <a href="https://github.com/chaos-mesh/bpfki">a version of clock skew</a> using this approach, and it works fine for Rust and C. As for Golang, the program can get the time right, but if we perform <code>sleep</code> during the clock skew injection, the sleep operation is very likely to be blocked. Even after the injection is canceled, the system cannot recover. Thus, we have to give up this approach, too.</p><h2>TimeChaos, our final hack</h2><p>From the previous section, we know that programs usually get the system time by calling <code>clock_gettime</code>. In our case, <code>clock_gettime</code> uses vDSO to speed up the calling process, so we cannot use <code>LD_PRELOAD</code> to hack the <code>clock_gettime</code> system calls.</p><p>We figured out the cause; then what&#x27;s the solution? Start from vDSO. If we can redirect the address that stores the <code>clock_gettime</code> return value in vDSO to an address we define, we can solve the problem.</p><p>Easier said than done. To achieve this goal, we must tackle the following problems:</p><ul><li>Know the user-mode address used by vDSO</li><li>Know vDSO&#x27;s kernel-mode address, if we want to modify the <code>clock_gettime</code> function in vDSO by any address in the kernel mode</li><li>Know how to modify vDSO data</li></ul><p>First, we need to peek inside vDSO. We can see the vDSO memory address in <code>/proc/pid/maps</code>.</p><pre><code>$ cat /proc/pid/maps
...
7ffe53143000-7ffe53145000 r-xp 00000000 00:00 0                     [vdso]
</code></pre><p>The last line is vDSO information. The privilege of this memory space is <code>r-xp</code>: readable and executable, but not writable. That means the user mode cannot modify this memory. We can use <a href="http://man7.org/linux/man-pages/man2/ptrace.2.html">ptrace</a> to avoid this restriction.</p><p>Next, we use <code>gdb dump memory</code> to export the vDSO and use <code>objdump</code> to see what&#x27;s inside. Here is what we get:</p><pre><code>(gdb) dump memory vdso.so 0x00007ffe53143000 0x00007ffe53145000
$ objdump -T vdso.so
vdso.so:    file format elf64-x86-64
DYNAMIC SYMBOL TABLE:
ffffffffff700600  w  DF .text   0000000000000545  LINUX_2.6  clock_gettime
</code></pre><p>We can see that the whole vDSO is like a <code>.so</code> file, so we can use an executable and linkable format (ELF) file to format it. With this information, a basic workflow for implementing TimeChaos starts to take shape:</p><p><img src="/img/timechaos-workflow.jpg" alt="TimeChaos workflow"/></p><div class="caption-center"> TimeChaos workflow </div><p>The chart above is the process of <strong>TimeChaos</strong>, an implementation of clock skew in Chaos Mesh.</p><ol><li>Use ptrace to attach the specified PID process to stop the current process.</li><li>Use ptrace to create a new mapping in the virtual address space of the calling process and use <a href="https://linux.die.net/man/2/process_vm_writev"><code>process_vm_writev</code></a> to write the <code>fake_clock_gettime</code> function we defined into the memory space.</li><li>Use <code>process_vm_writev</code> to write the specified parameters into <code>fake_clock_gettime</code>. These parameters are the time we would like to inject, such as two hours backward or two days forward.</li><li>Use ptrace to modify the <code>clock_gettime</code> function in vDSO and redirect to the <code>fake_clock_gettime</code> function.</li><li>Use ptrace to detach the PID process.</li></ol><p>If you are interested in the details, see the <a href="https://github.com/chaos-mesh/chaos-mesh/blob/master/pkg/time/time_linux.go">Chaos Mesh GitHub repository</a>.</p><h2>Simulating clock skew on a distributed SQL database</h2><p>Statistics speak volumes. Here we&#x27;re going to try TimeChaos on <a href="https://pingcap.com/docs/stable/overview/">TiDB</a>, an open source, <a href="https://en.wikipedia.org/wiki/NewSQL">NewSQL</a>, distributed SQL database that supports <a href="https://en.wikipedia.org/wiki/Hybrid_transactional/analytical_processing">Hybrid Transactional/Analytical Processing</a> (HTAP) workloads, to see if the chaos testing can really work.</p><p>TiDB uses a centralized service Timestamp Oracle (TSO) to obtain the globally consistent version number, and to ensure that the transaction version number increases monotonically. The TSO service is managed by the Placement Driver (PD) component. Therefore, we choose a random PD node and inject TimeChaos regularly, each with a 10-millisecond-backward clock skew. Let&#x27;s see if TiDB can meet the challenge.</p><p>To better perform the testing, we use <a href="https://github.com/cwen0/bank">bank</a> as the workload, which simulates the financial transfers in a banking system. It&#x27;s often used to verify the correctness of database transactions.</p><p>This is our test configuration:</p><pre><code>apiVersion: chaos-mesh.org/v1alpha1
kind: TimeChaos
metadata:
  name: time-skew-example
  namespace: tidb-demo
spec:
  mode: one
  selector:
    labelSelectors:
      &quot;app.kubernetes.io/component&quot;: &quot;pd&quot;
  timeOffset:
    sec: -600
  clockIds:
    - CLOCK_REALTIME
  duration: &quot;10s&quot;
  scheduler:
    cron: &quot;@every 1m&quot;
</code></pre><p>During this test, Chaos Mesh injects TimeChaos into a chosen PD Pod every 1 millisecond for 10 seconds. Within the duration, the time acquired by PD will have a 600 second offset from the actual time. For further details, see <a href="https://github.com/chaos-mesh/chaos-mesh/wiki/Time-Chaos">Chaos Mesh Wiki</a>.</p><p>Let&#x27;s create a TimeChaos experiment using the <code>kubectl apply</code> command:</p><pre><code>kubectl apply -f pd-time.yaml
</code></pre><p>Now, we can retrieve the PD log by the following command:</p><pre><code>kubectl logs -n tidb-demo tidb-app-pd-0 | grep &quot;system time jump backward&quot;
</code></pre><p>Here&#x27;s the log:</p><pre><code>[2020/03/24 09:06:23.164 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585041383060109693]
[2020/03/24 09:16:32.260 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585041992160476622]
[2020/03/24 09:20:32.059 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585042231960027622]
[2020/03/24 09:23:32.059 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585042411960079655]
[2020/03/24 09:25:32.059 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585042531963640321]
[2020/03/24 09:28:32.060 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585042711960148191]
[2020/03/24 09:33:32.063 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585043011960517655]
[2020/03/24 09:34:32.060 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585043071959942937]
[2020/03/24 09:35:32.059 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585043131978582964]
[2020/03/24 09:36:32.059 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585043191960687755]
[2020/03/24 09:38:32.060 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585043311959970737]
[2020/03/24 09:41:32.060 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585043491959970502]
[2020/03/24 09:45:32.061 +00:00] [ERROR] [systime_mon.go:32] [&quot;system time jump backward&quot;] [last=1585043731961304629]
...
</code></pre><p>From the log above, we see that every now and then, PD detects that the system time rolls back. This means:</p><ul><li>TimeChaos successfully simulates clock skew.</li><li>PD can deal with the clock skew situation.</li></ul><p>That&#x27;s encouraging. But does TimeChaos affect services other than PD? We can check it out in the Chaos Dashboard:</p><p><img src="/img/chaos-dashboard.jpg" alt="Chaos Dashboard"/></p><div class="caption-center"> Chaos Dashboard </div><p>It&#x27;s clear that in the monitor, TimeChaos was injected every 1 millisecond and the whole duration lasted 10 seconds. What&#x27;s more, TiDB was not affected by that injection. The bank program ran normally, and performance was not affected.</p><h2>Try out Chaos Mesh</h2><p>As a cloud-native chaos engineering platform, Chaos Mesh features all-around <a href="https://pingcap.com/blog/chaos-mesh-your-chaos-engineering-solution-for-system-resiliency-on-kubernetes/">fault injection methods for complex systems on Kubernetes</a>, covering faults in Pods, the network, the file system, and even the kernel.</p><p>Wanna have some hands-on experience in chaos engineering? Welcome to <a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a>. This <a href="https://pingcap.com/blog/run-first-chaos-experiment-in-ten-minutes/">10-minute tutorial</a> will help you quickly get started with chaos engineering and run your first chaos experiment with Chaos Mesh.</p>]]></content>
        <author>
            <name>Cwen Yin</name>
            <uri>https://github.com/cwen0</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Run Your First Chaos Experiment in 10 Minutes]]></title>
        <id>/run_your_first_chaos_experiment</id>
        <link href="https://chaos-mesh.org/blog/run_your_first_chaos_experiment"/>
        <updated>2020-03-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Run your first chaos experiment in 10 minutes]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/run-first-chaos-experiment-in-ten-minutes.jpg" alt="Run your first chaos experiment in 10 minutes"/></p><p>Chaos Engineering is a way to test a production software system&#x27;s robustness by simulating unusual or disruptive conditions. For many people, however, the transition from learning Chaos Engineering to practicing it on their own systems is daunting. It sounds like one of those big ideas that require a fully-equipped team to plan ahead. Well, it doesn&#x27;t have to be. To get started with chaos experimenting, you may be just one suitable platform away.</p><p><a href="https://github.com/chaos-mesh/chaos-mesh">Chaos Mesh</a> is an <strong>easy-to-use</strong>, open-source, cloud-native Chaos Engineering platform that orchestrates chaos in Kubernetes environments. This 10-minute tutorial will help you quickly get started with Chaos Engineering and run your first chaos experiment with Chaos Mesh.</p><p>For more information about Chaos Mesh, refer to our <a href="https://pingcap.com/blog/chaos-mesh-your-chaos-engineering-solution-for-system-resiliency-on-kubernetes/">previous article</a> or the <a href="https://github.com/chaos-mesh/chaos-mesh">chaos-mesh project</a> on GitHub.</p><h2>A preview of our little experiment</h2><p>Chaos experiments are similar to experiments we do in a science class. It&#x27;s perfectly fine to stimulate turbulent situations in a controlled environment. In our case here, we will be simulating network chaos on a small web application called <a href="https://github.com/chaos-mesh/web-show">web-show</a>. To visualize the chaos effect, web-show records the latency from its pod to the kube-controller pod (under the namespace of <code>kube-system</code>) every 10 seconds.</p><p>The following clip shows the process of installing Chaos Mesh, deploying web-show, and creating the chaos experiment within a few commands:</p><p><img src="/img/whole-process-of-chaos-experiment.gif" alt="The whole process of the chaos experiment"/></p><div class="caption-center"> The whole process of the chaos experiment </div><p>Now it&#x27;s your turn! It&#x27;s time to get your hands dirty.</p><h2>Let&#x27;s get started!</h2><p>For our simple experiment, we use Kubernetes in the Docker (<a href="https://kind.sigs.k8s.io/">Kind</a>) for Kubernetes development. You can feel free to use <a href="https://minikube.sigs.k8s.io/">Minikube</a> or any existing Kubernetes clusters to follow along.</p><h3>Prepare the environment</h3><p>Before moving forward, make sure you have <a href="https://git-scm.com/">Git</a> and <a href="https://www.docker.com/">Docker</a> installed on your local computer, with Docker up and running. For macOS, it&#x27;s recommended to allocate at least 6 CPU cores to Docker. For details, see <a href="https://docs.docker.com/docker-for-mac/#advanced">Docker configuration for Mac</a>.</p><ol><li><p>Get Chaos Mesh:</p><pre><code class="language-bash">git clone https://github.com/chaos-mesh/chaos-mesh.git
cd chaos-mesh/
</code></pre></li><li><p>Install Chaos Mesh with the <code>install.sh</code> script:</p><pre><code class="language-bash">./install.sh --local kind
</code></pre><p><code>install.sh</code> is an automated shell script that checks your environment, installs Kind, launches Kubernetes clusters locally, and deploys Chaos Mesh. To see the detailed description of <code>install.sh</code>, you can include the <code>--help</code> option.</p><blockquote><p><strong>Note:</strong></p><p>If your local computer cannot pull images from <code>docker.io</code> or <code>gcr.io</code>, use the local gcr.io mirror and execute <code>./install.sh --local kind --docker-mirror</code> instead.</p></blockquote></li><li><p>Set the system environment variable:</p><pre><code class="language-bash">source ~/.bash_profile
</code></pre></li></ol><blockquote><p><strong>Note:</strong></p><ul><li><p>Depending on your network, these steps might take a few minutes.</p></li><li><p>If you see an error message like this:</p><pre><code class="language-bash">ERROR: failed to create cluster: failed to generate kubeadm config content: failed to get kubernetes version from node: failed to get file: command &quot;docker exec --privileged kind-control-plane cat /kind/version&quot; failed with error: exit status 1
</code></pre><p>increase the available resources for Docker on your local computer and execute the following command:</p><pre><code class="language-bash">./install.sh --local kind --force-local-kube
</code></pre></li></ul></blockquote><p>When the process completes you will see a message indicating Chaos Mesh is successfully installed.</p><h3>Deploy the application</h3><p>The next step is to deploy the application for testing. In our case here, we choose web-show because it allows us to directly observe the effect of network chaos. You can also deploy your own application for testing.</p><ol><li><p>Deploy web-show with the <code>deploy.sh</code> script:</p><pre><code class="language-bash"># Make sure you are in the Chaos Mesh directory
cd examples/web-show &amp;&amp;
./deploy.sh
</code></pre><blockquote><p><strong>Note:</strong></p><p>If your local computer cannot pull images from <code>docker.io</code>, use the <code>local gcr.io</code> mirror and execute <code>./deploy.sh --docker-mirror</code> instead.</p></blockquote></li><li><p>Access the web-show application. From your web browser, go to <code>http://localhost:8081</code>.</p></li></ol><h3>Create the chaos experiment</h3><p>Now that everything is ready, it&#x27;s time to run your chaos experiment!</p><p>Chaos Mesh uses <a href="https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/">CustomResourceDefinitions</a> (CRD) to define chaos experiments. CRD objects are designed separately based on different experiment scenarios, which greatly simplifies the definition of CRD objects. Currently, CRD objects that have been implemented in Chaos Mesh include PodChaos, NetworkChaos, IOChaos, TimeChaos, and KernelChaos. Later, we&#x27;ll support more fault injection types.</p><p>In this experiment, we are using <a href="https://github.com/chaos-mesh/chaos-mesh/blob/master/examples/web-show/network-delay.yaml">NetworkChaos</a> for the chaos experiment. The NetworkChaos configuration file, written in YAML, is shown below:</p><pre><code>apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: network-delay-example
spec:
  action: delay
  mode: one
  selector:
    namespaces:
      - default
    labelSelectors:
      &quot;app&quot;: &quot;web-show&quot;
  delay:
    latency: &quot;10ms&quot;
    correlation: &quot;100&quot;
    jitter: &quot;0ms&quot;
  duration: &quot;30s&quot;
  scheduler:
    cron: &quot;@every 60s&quot;
</code></pre><p>For detailed descriptions of NetworkChaos actions, see <a href="https://github.com/chaos-mesh/chaos-mesh/wiki/Network-Chaos">Chaos Mesh wiki</a>. Here, we just rephrase the configuration as:</p><ul><li>target: <code>web-show</code></li><li>mission: inject a <code>10ms</code> network delay every <code>60s</code></li><li>attack duration: <code>30s</code> each time</li></ul><p>To start NetworkChaos, do the following:</p><ol><li><p>Run <code>network-delay.yaml</code>:</p><pre><code class="language-bash"># Make sure you are in the chaos-mesh/examples/web-show directory
kubectl apply -f network-delay.yaml
</code></pre></li><li><p>Access the web-show application. In your web browser, go to <code>http://localhost:8081</code>.</p><p>From the line graph, you can tell that there is a 10 ms network delay every 60 seconds.</p></li></ol><p><img src="/img/using-chaos-mesh-to-insert-delays-in-web-show.png" alt="Using Chaos Mesh to insert delays in web-show"/></p><div class="caption-center"> Using Chaos Mesh to insert delays in web-show </div><p>Congratulations! You just stirred up a little bit of chaos. If you are intrigued and want to try out more chaos experiments with Chaos Mesh, check out <a href="https://github.com/chaos-mesh/chaos-mesh/tree/master/examples/web-show">examples/web-show</a>.</p><h3>Delete the chaos experiment</h3><p>Once you&#x27;re finished testing, terminate the chaos experiment.</p><ol><li><p>Delete <code>network-delay.yaml</code>:</p><pre><code class="language-bash"># Make sure you are in the chaos-mesh/examples/web-show directory
kubectl delete -f network-delay.yaml
</code></pre></li><li><p>Access the web-show application. From your web browser, go to <code>http://localhost:8081</code>.</p></li></ol><p>From the line graph, you can see the network latency level is back to normal.</p><p><img src="/img/network-latency-level-is-back-to-normal.png" alt="Network latency level is back to normal"/></p><div class="caption-center"> Network latency level is back to normal </div><h3>Delete Kubernetes clusters</h3><p>After you&#x27;re done with the chaos experiment, execute the following command to delete the Kubernetes clusters:</p><pre><code class="language-bash">kind delete cluster --name=kind
</code></pre><blockquote><p><strong>Note:</strong></p><p>If you encounter the <code>kind: command not found</code> error, execute <code>source ~/.bash_profile</code> command first and then delete the Kubernetes clusters.</p></blockquote><h2>Cool! What&#x27;s next?</h2><p>Congratulations on your first successful journey into Chaos Engineering. How does it feel? Chaos Engineering is easy, right? But perhaps Chaos Mesh is not that easy-to-use. Command-line operation is inconvenient, writing YAML files manually is a bit tedious, or checking the experiment results is somewhat clumsy? Don&#x27;t worry, Chaos Dashboard is on its way! Running chaos experiments on the web sure does sound exciting! If you&#x27;d like to help us build testing standards for cloud platforms or make Chaos Mesh better, we&#x27;d love to hear from you!</p><p>If you find a bug or think something is missing, feel free to file an issue, open a pull request (PR), or join us on the #project-chaos-mesh channel in the <a href="https://slack.cncf.io/">CNCF slack workspace</a>.</p><p>GitHub: <a href="https://github.com/chaos-mesh/chaos-mesh">https://github.com/chaos-mesh/chaos-mesh</a></p>]]></content>
        <author>
            <name>Cwen Yin</name>
            <uri>https://github.com/cwen0</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Chaos Mesh - Your Chaos Engineering Solution for System Resiliency on Kubernetes]]></title>
        <id>/chaos_mesh_your_chaos_engineering_solution</id>
        <link href="https://chaos-mesh.org/blog/chaos_mesh_your_chaos_engineering_solution"/>
        <updated>2020-01-15T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Chaos Engineering]]></summary>
        <content type="html"><![CDATA[<p><img src="/img/chaos-engineering.png" alt="Chaos Engineering"/></p><h2>Why Chaos Mesh?</h2><p>In the world of distributed computing, faults can happen to your clusters unpredictably any time, anywhere. Traditionally we have unit tests and integration tests that guarantee a system is production ready, but these cover just the tip of the iceberg as clusters scale, complexities amount, and data volumes increase by PB levels. To better identify system vulnerabilities and improve resilience, Netflix invented <a href="https://netflix.github.io/chaosmonkey/">Chaos Monkey</a> and injects various types of faults into the infrastructure and business systems. This is how Chaos Engineering was originated.</p><p>At <a href="https://chaos-mesh.org/">PingCAP</a>, we are facing the same problem while building <a href="https://github.com/pingcap/tidb">TiDB</a>, an open source distributed NewSQL database. To be fault tolerant, or resilient holds especially true to us, because the most important asset for any database users, the data itself, is at stake. To ensure resilience, we started <a href="https://pingcap.com/blog/chaos-practice-in-tidb/">practicing Chaos Engineering</a> internally in our testing framework from a very early stage. However, as TiDB grew, so did the testing requirements. We realized that we needed a universal chaos testing platform, not just for TiDB, but also for other distributed systems.</p><p>Therefore, we present to you Chaos Mesh, a cloud-native Chaos Engineering platform that orchestrates chaos experiments on Kubernetes environments. It&#x27;s an open source project available at <a href="https://github.com/chaos-mesh/chaos-mesh">https://github.com/chaos-mesh/chaos-mesh</a>.</p><p>In the following sections, I will share with you what Chaos Mesh is, how we design and implement it, and finally I will show you how you can use it in your environment.</p><h2>What can Chaos Mesh do?</h2><p>Chaos Mesh is a versatile Chaos Engineering platform that features all-around fault injection methods for complex systems on Kubernetes, covering faults in Pod, network, file system, and even the kernel.</p><p>Here is an example of how we use Chaos Mesh to locate a TiDB system bug. In this example, we simulate Pod downtime with our distributed storage engine (<a href="https://pingcap.com/docs/stable/architecture/#tikv-server">TiKV</a>) and observe changes in queries per second (QPS). Regularly, if one TiKV node is down, the QPS may experience a transient jitter before it returns to the level before the failure. This is how we guarantee high availability.</p><p><img src="/img/chaos-mesh-discovers-downtime-recovery-exceptions-in-tikv.png" alt="Chaos Mesh discovers downtime recovery exceptions in TiKV"/></p><div class="caption-center"> Chaos Mesh discovers downtime recovery exceptions in TiKV</div><p>As you can see from the dashboard:</p><ul><li>During the first two downtimes, the QPS returns to normal after about 1 minute.</li><li>After the third downtime, however, the QPS takes much longer to recover‚Äîabout 9 minutes. Such a long downtime is unexpected, and it would definitely impact online services.</li></ul><p>After some diagnosis, we found the TiDB cluster version under test (V3.0.1) had some tricky issues when handling TiKV downtimes. We resolved these issues in later versions.</p><p>But Chaos Mesh can do a lot more than just simulate downtime. It also includes these fault injection methods:</p><ul><li><strong>pod-kill:</strong> Simulates Kubernetes Pods being killed</li><li><strong>pod-failure:</strong> Simulates Kubernetes Pods being continuously unavailable</li><li><strong>network-delay:</strong> Simulates network delay</li><li><strong>network-loss:</strong> Simulates network packet loss</li><li><strong>network-duplication:</strong> Simulates network packet duplication</li><li><strong>network-corrupt:</strong> Simulates network packet corruption</li><li><strong>network-partition:</strong> Simulates network partition</li><li><strong>I/O delay:</strong> Simulates file system I/O delay</li><li><strong>I/O errno:</strong> Simulates file system I/O errors</li></ul><h2>Design principles</h2><p>We designed Chaos Mesh to be easy to use, scalable, and designed for Kubernetes.</p><h3>Easy to use</h3><p>To be easy to use, Chaos Mesh must:</p><ul><li>Require no special dependencies, so that it can be deployed directly on Kubernetes clusters, including <a href="https://github.com/kubernetes/minikube">Minikube</a>.</li><li>Require no modification to the deployment logic of the system under test (SUT), so that chaos experiments can be performed in a production environment.</li><li>Easily orchestrate fault injection behaviors in chaos experiments, and easily view experiment status and results. You should also be able to quickly rollback injected failures.</li><li>Hide underlying implementation details so that users can focus on orchestrating the chaos experiments.</li></ul><h3>Scalable</h3><p>Chaos Mesh should be scalable, so that we can &quot;plug&quot; new requirements into it conveniently without reinventing the wheel. Specifically, Chaos Mesh must:</p><ul><li>Leverage existing implementations so that fault injection methods can be easily scaled.</li><li>Easily integrate with other testing frameworks.</li></ul><h3>Designed for Kubernetes</h3><p>In the container world, Kubernetes is the absolute leader. Its growth rate of adoption is far beyond everybody&#x27;s expectations, and it has won the war of containerized orchestration. In essence, Kubernetes is an operating system for the cloud.</p><p>TiDB is a cloud-native distributed database. Our internal automated testing platform was built on Kubernetes from the beginning. We had hundreds of TiDB clusters running on Kubernetes every day for various experiments, including extensive chaos testing to simulate all kinds of failures or issues in a production environment. To support these chaos experiments, the combination of chaos and Kubernetes became a natural choice and principle for our implementation.</p><h2>CustomResourceDefinitions design</h2><p>Chaos Mesh uses <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">CustomResourceDefinitions</a> (CRD) to define chaos objects. In the Kubernetes realm, CRD is a mature solution for implementing custom resources, with abundant implementation cases and toolsets available. Using CRD makes Chaos Mesh naturally integrate with the Kubernetes ecosystem.</p><p>Instead of defining all types of fault injections in a unified CRD object, we allow flexible and separate CRD objects for different types of fault injection. If we add a fault injection method that conforms to an existing CRD object, we scale directly based on this object; if it is a completely new method, we create a new CRD object for it. With this design, chaos object definitions and the logic implementation are extracted from the top level, which makes the code structure clearer. This approach also reduces the degree of coupling and the probability of errors. In addition, Kubernetes&#x27; <a href="https://github.com/kubernetes-sigs/controller-runtime">controller-runtime</a> is a great wrapper for implementing controllers. This saves us a lot of time because we don&#x27;t have to repeatedly implement the same set of controllers for each CRD project.</p><p>Chaos Mesh implements the PodChaos, NetworkChaos, and IOChaos objects. The names clearly identify the corresponding fault injection types.</p><p>For example, Pod crashing is a very common problem in a Kubernetes environment. Many native resource objects automatically handle such errors with typical actions such as creating a new Pod. But can our application really deal with such errors? What if the Pod won&#x27;t start?</p><p>With well-defined actions such as <code>pod-kill</code>, PodChaos can help us pinpoint these kinds of issues more effectively. The PodChaos object uses the following code:</p><pre><code class="language-yml">spec:
 action: pod-kill
 mode: one
 selector:
   namespaces:
     - tidb-cluster-demo
   labelSelectors:
     &quot;app.kubernetes.io/component&quot;: &quot;tikv&quot;
  scheduler:
   cron: &quot;@every 2m&quot;
</code></pre><p>This code does the following:</p><ul><li>The <code>action</code> attribute defines the specific error type to be injected. In this case, <code>pod-kill</code> kills Pods randomly.</li><li>The <code>selector</code> attribute limits the scope of chaos experiment to a specific scope. In this case, the scope is TiKV Pods for the TiDB cluster with the <code>tidb-cluster-demo</code> namespace.</li><li>The <code>scheduler</code> attribute defines the interval for each chaos fault action.</li></ul><p>For more details on CRD objects such as NetworkChaos and IOChaos, see the <a href="https://github.com/chaos-mesh/chaos-mesh">Chaos-mesh documentation</a>.</p><h2>How does Chaos Mesh work?</h2><p>With the CRD design settled, let&#x27;s look at the big picture on how Chaos Mesh works. The following major components are involved:</p><ul><li><p><strong>controller-manager</strong></p><p>Acts as the platform&#x27;s &quot;brain.&quot; It manages the life cycle of CRD objects and schedules chaos experiments. It has object controllers for scheduling CRD object instances, and the <a href="https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/">admission-webhooks</a> controller dynamically injects sidecar containers into Pods.</p></li><li><p><strong>chaos-daemon</strong></p><p>Runs as a privileged DaemonSet that can operate network devices on the node and Cgroup.</p></li><li><p><strong>sidecar</strong></p><p>Runs as a special type of container that is dynamically injected into the target Pod by the admission-webhooks. For example, the <code>chaosfs</code> sidecar container runs a fuse-daemon to hijack the I/O operation of the application container.</p></li></ul><p><img src="/img/chaos-mesh-workflow.png" alt="Chaos Mesh workflow"/></p><div class="caption-center"> Chaos Mesh workflow </div><p>Here is how these components streamline a chaos experiment:</p><ol><li>Using a YAML file or Kubernetes client, the user creates or updates chaos objects to the Kubernetes API server.</li><li>Chaos Mesh uses the API server to watch the chaos objects and manages the lifecycle of chaos experiments through creating, updating, or deleting events. In this process, controller-manager, chaos-daemon, and sidecar containers work together to inject errors.</li><li>When admission-webhooks receives a Pod creation request, the Pod object to be created is dynamically updated; for example, it is injected into the sidecar container and the Pod.</li></ol><h2>Running chaos</h2><p>The above sections introduce how we design Chaos Mesh and how it works. Now let&#x27;s get down to business and show you how to use Chaos Mesh. Note that the chaos testing time may vary depending on the complexity of the application to be tested and the test scheduling rules defined in the CRD.</p><h3>Preparing the environment</h3><p>Chaos Mesh runs on Kubernetes v1.12 or later. Helm, a Kubernetes package management tool, deploys and manages Chaos Mesh. Before you run Chaos Mesh, make sure that Helm is properly installed in the Kubernetes cluster. To set up the environment, do the following:</p><ol><li><p>Make sure you have a Kubernetes cluster. If you do, skip to step 2; otherwise, start one locally using the script provided by Chaos Mesh:</p><pre><code class="language-bash">// install kind
curl -Lo ./kind https://github.com/kubernetes-sigs/kind/releases/download/v0.6.1/kind-$(uname)-amd64
chmod +x ./kind
mv ./kind /some-dir-in-your-PATH/kind

// get script
git clone https://github.com/chaos-mesh/chaos-mesh
cd chaos-mesh
// start cluster
hack/kind-cluster-build.sh
</code></pre><p><strong>Note:</strong> Starting Kubernetes clusters locally affects network-related fault injections.</p></li><li><p>If the Kubernetes cluster is ready, use <a href="https://helm.sh/">Helm</a> and <a href="https://kubernetes.io/docs/reference/kubectl/overview/">Kubectl</a> to deploy Chaos Mesh:</p><pre><code class="language-bash">git clone https://github.com/chaos-mesh/chaos-mesh.git
cd chaos-mesh
// create CRD resource
kubectl apply -f manifests/
// install chaos-mesh
helm install helm/chaos-mesh --name=chaos-mesh --namespace=chaos-testing
</code></pre><p>Wait until all components are installed, and check the installation status using:</p><pre><code class="language-bash">// check chaos-mesh status
kubectl get pods --namespace chaos-testing -l app.kubernetes.io/instance=chaos-mesh
</code></pre><p>If the installation is successful, you can see all pods up and running. Now, time to play.</p><p>You can run Chaos Mesh using a YAML definition or a Kubernetes API.</p></li></ol><h3>Running chaos using a YAML file</h3><p>You can define your own chaos experiments through the YAML file method, which provides a fast, convenient way to conduct chaos experiments after you deploy the application. To run chaos using a YAML file, follow the steps below:</p><p><strong>Note:</strong> For illustration purposes, we use TiDB as our system under test. You can use a target system of your choice, and modify the YAML file accordingly.</p><ol><li><p>Deploy a TiDB cluster named <code>chaos-demo-1</code>. You can use <a href="https://github.com/pingcap/tidb-operator">TiDB Operator</a> to deploy TiDB.</p></li><li><p>Create the YAML file named <code>kill-tikv.yaml</code> and add the following content:</p><pre><code class="language-yml">apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: pod-kill-chaos-demo
  namespace: chaos-testing
spec:
  action: pod-kill
  mode: one
  selector:
    namespaces:
      - chaos-demo-1
    labelSelectors:
      &#x27;app.kubernetes.io/component&#x27;: &#x27;tikv&#x27;
  scheduler:
    cron: &#x27;@every 1m&#x27;
</code></pre></li><li><p>Save the file.</p></li><li><p>To start chaos, <code>kubectl apply -f kill-tikv.yaml</code>.</p></li></ol><p>The following chaos experiment simulates the TiKV Pods being frequently killed in the <code>chaos-demo-1</code> cluster:</p><p><img src="/img/chaos-experiment-running.gif" alt="Chaos experiment running"/></p><div class="caption-center"> Chaos experiment running </div><p>We use a sysbench program to monitor the real-time QPS changes in the TiDB cluster. When errors are injected into the cluster, the QPS show a drastic jitter, which means a specific TiKV Pod has been deleted, and Kubernetes then re-creates a new TiKV Pod.</p><p>For more YAML file examples, see <a href="https://github.com/chaos-mesh/chaos-mesh/tree/master/examples">https://github.com/chaos-mesh/chaos-mesh/tree/master/examples</a>.</p><h3>Running chaos using the Kubernetes API</h3><p>Chaos Mesh uses CRD to define chaos objects, so you can manipulate CRD objects directly through the Kubernetes API. This way, it is very convenient to apply Chaos Mesh to your own applications with customized test scenarios and automated chaos experiments.</p><p>In the <a href="https://github.com/pingcap/tipocket/tree/35206e8483b66f9728b7b14823a10b3e4114e0e3/test-infra">test-infra</a> project, we simulate potential errors in <a href="https://github.com/pingcap/tipocket/blob/35206e8483b66f9728b7b14823a10b3e4114e0e3/test-infra/tests/etcd/nemesis_test.go">etcd</a> clusters on Kubernetes, including nodes restarting, network failure, and file system failure.</p><p>The following is a Chaos Mesh sample script using the Kubernetes API:</p><pre><code>import (
    &quot;context&quot;

 &quot;github.com/chaos-mesh/chaos-mesh/api/v1alpha1&quot;
    &quot;sigs.k8s.io/controller-runtime/pkg/client&quot;
)

func main() {
  ...
  delay := &amp;chaosv1alpha1.NetworkChaos{
  Spec: chaosv1alpha1.NetworkChaosSpec{...},
      }
      k8sClient := client.New(conf, client.Options{ Scheme: scheme.Scheme })
  k8sClient.Create(context.TODO(), delay)
      k8sClient.Delete(context.TODO(), delay)
}
</code></pre><h2>What does the future hold?</h2><p>In this article, we introduced you to Chaos Mesh, our open source cloud-native Chaos Engineering platform. There are still many pieces in progress, with more details to unveil regarding the design, use cases, and development. Stay tuned.</p><p>Open sourcing is just a starting point. In addition to the infrastructure-level chaos experiments introduced in previous sections, we are in the process of supporting a wider range of fault types of finer granularity, such as:</p><ul><li>Injecting errors at the system call and kernel levels with the assistance of eBPF and other tools</li><li>Injecting specific error types into the application function and statement levels by integrating <a href="https://github.com/pingcap/failpoint">failpoint</a>, which will cover scenarios that are otherwise impossible with conventional injection methods</li></ul><p>Moving forward, we will continuously improve the Chaos Mesh Dashboard, so that users can easily see if and how their online businesses are impacted by fault injections. In addition, our roadmap includes an easy-to-use fault orchestration interface. We&#x27;re planning other cool features, such as Chaos Mesh Verifier and Chaos Mesh Cloud.</p><p>If any of these sound interesting to you, join us in building a world class Chaos Engineering platform. May our applications dance in chaos on Kubernetes!</p><p>If you find a bug or think something is missing, feel free to file an <a href="https://github.com/chaos-mesh/chaos-mesh/issues">issue</a>, open a PR, or message us in the #project-chaos-mesh channel in the <a href="https://slack.cncf.io/">CNCF Slack</a> workspace.</p><p>GitHub: <a href="https://github.com/chaos-mesh/chaos-mesh">https://github.com/chaos-mesh/chaos-mesh</a></p>]]></content>
        <author>
            <name>Cwen Yin</name>
            <uri>https://github.com/cwen0</uri>
        </author>
    </entry>
</feed>